{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "\n",
    "\n",
    "## Project 5 - Phase 2 (Altiscale cluster)\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  Hyera Moon    \n",
    "__Week:__   5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"TOC\"></a> \n",
    "\n",
    "1.  [HW Instructions](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW Problems](#3)   \n",
    "       \n",
    "    5.4.  [HW5.4](#5.4)    \n",
    "    5.5.  [HW5.5](#5.5)    \n",
    "    5.6.  [HW5.6](#5.6)    \n",
    "    5.7.  [HW5.7](#5.7)    \n",
    "    5.8.  [HW5.8](#5.8)    \n",
    "    5.9.  [HW5.9](#5.9)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# 1 Instructions\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\">\n",
    "# 2 Useful References\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "* See async and live lectures for this week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\">\n",
    "# 3 HW Problems\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5.4\"></a> \n",
    "# PHASE 2\n",
    "----------\n",
    "\n",
    "# HW 5.4   \n",
    "## Full-scale experiment on Google N-gram data on the CLOUD\n",
    "__ Once you are happy with your test results __ proceed to generating  your results on the Google n-grams dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.0  <a name=\"5.4.0\"></a> Run systems tests on the CLOUD  (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Repeat HW5.3.0 (using the same small data sources that were used in HW5.3.0) on ** the cloud** (e.g., AltaScale / AWS/ SoftLayer/ Azure). Make sure all tests give correct results! Good luck out there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MRJob codes from phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildStripes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "import itertools\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "class MRbuildStripes(MRJob):\n",
    "  \n",
    "  #START SUDENT CODE531_STRIPES\n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper,\n",
    "                reducer = self.reducer\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.stripes = {}\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip().lower()\n",
    "        ngram, count, other = line.split('\\t',2)\n",
    "        count = int(count)\n",
    "        words = ngram.split(' ')\n",
    "        self.stripes = {}\n",
    "                \n",
    "        for subset in itertools.permutations(sorted(words), 2):  #instead of combinations to keep symmetry\n",
    "            if subset[0] == subset[1]:  # in case two same words in a line\n",
    "                continue\n",
    "            elif subset[0] not in self.stripes.keys():\n",
    "                self.stripes[subset[0]] = {}\n",
    "                self.stripes[subset[0]][subset[1]] = count\n",
    "            elif subset[1] not in self.stripes[subset[0]]:\n",
    "                self.stripes[subset[0]][subset[1]] = count\n",
    "            else:\n",
    "                self.stripes[subset[0]][subset[1]] += count\n",
    "\n",
    "        for key in self.stripes.keys():\n",
    "            yield key, self.stripes[key]\n",
    "            \n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        temp_stripes = {}\n",
    "        for value in values:\n",
    "            for word, count in value.items():\n",
    "                temp_stripes[word] = temp_stripes.get(word,0) + count\n",
    "        yield key, temp_stripes\n",
    "  \n",
    "\n",
    "  #END SUDENT CODE531_STRIPES   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRbuildStripes.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting invertedIndex.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np commented since not supported by Hadoop Python version\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.protocol import JSONProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRinvertedIndex(MRJob):\n",
    "    INPUT_PROTOCOL = JSONProtocol\n",
    "\n",
    "  #START SUDENT CODE531_INV_INDEX\n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(\n",
    "                mapper=self.mapper,\n",
    "                reducer=self.reducer\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def mapper(self, key_word, stripes):\n",
    "        words = stripes.keys()\n",
    "        _len = len(words)\n",
    "        for word in words:\n",
    "        # Store the length of the document to use with JACCARD (|A| + |B|)\n",
    "            yield word, (key_word, _len)\n",
    "        \n",
    "    def reducer(self, word, values):        \n",
    "        d = collections.defaultdict(list)\n",
    "        for value in values:\n",
    "            d[word].append(value)\n",
    "        yield word,d[word]\n",
    "\n",
    "  #END SUDENT CODE531_INV_INDEX\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRinvertedIndex.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np  commented since not supported by Hadoop Python version\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRsimilarity(MRJob):\n",
    "  \n",
    "  #START SUDENT CODE531_SIMILARITY\n",
    "    MRJob.SORT_VALUES\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {}\n",
    "        JOBCONF_STEP2 = { \n",
    "                # Must use -r hadoop mode for this sorting to work #\n",
    "                'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "\n",
    "        return [\n",
    "            MRStep(jobconf=JOBCONF_STEP1,\n",
    "                   mapper = self.mapper_pair_sim,\n",
    "                   reducer = self.reducer_pair_sim\n",
    "                  ),\n",
    "            MRStep(jobconf=JOBCONF_STEP2,\n",
    "                  mapper=None,\n",
    "                  reducer=self.reducer_sort)\n",
    "        ]\n",
    "        \n",
    "    def mapper_pair_sim(self, _, line):\n",
    "        line = line.strip()\n",
    "        index,posting = line.split(\"\\t\")\n",
    "        posting = json.loads(posting)\n",
    "        \n",
    "        X = map(lambda x: x[0]+\".\"+str(x[1]) , posting)\n",
    "        \n",
    "        # taking advantage of symetry, output only (a,b), but not (b,a)\n",
    "        for subset in itertools.combinations(sorted(set(X)), 2):\n",
    "            yield subset[0]+\".\"+subset[1], 1\n",
    "        \n",
    "            \n",
    "    def reducer_pair_sim(self,key,values):\n",
    "        word1, word1_len, word2, word2_len = key.split(\".\")\n",
    "        t =sum(values)\n",
    "       \n",
    "        cosine = (1.0/(float(word1_len)**0.5) * 1.0/(float(word2_len)**0.5))*t\n",
    "        jaccard = t / ( int(word1_len) + int(word2_len) - t )\n",
    "        overlap = t / min(int(word1_len), int(word2_len))\n",
    "        dice = 2 * t / ( int(word1_len) + int(word2_len))\n",
    "        avg = (jaccard + cosine + overlap + dice) / 4\n",
    "        \n",
    "        # rounding to 6 decimals\n",
    "        avg = round(avg, 6)\n",
    "        cosine = round(cosine, 6)\n",
    "        jaccard = round(jaccard, 6)\n",
    "        overlap = round(overlap, 6)\n",
    "        dice = round(dice, 6)\n",
    "        \n",
    "        yield avg, (word1+\" - \"+word2, cosine, jaccard, overlap, dice)\n",
    "    \n",
    "    \n",
    "    def reducer_sort(self,key,values):\n",
    "        for value in values:\n",
    "            yield key, value\n",
    "\n",
    "  #END SUDENT CODE531_SIMILARITY\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    MRsimilarity.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x buildStripes.py\n",
    "!chmod a+x invertedIndex.py\n",
    "!chmod a+x similarity.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Systems tests on CLOUD on small datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) build stripes for all the test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: Unknown command\n",
      "Did you mean -rm?  This command begins with a dash.\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.hyeramoon.20170219.222028.820956\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes.hyeramoon.20170219.222028.820956/output...\n",
      "Removing temp directory /tmp/buildStripes.hyeramoon.20170219.222028.820956...\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 1\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs rm --recursive systems_test_stripes_1\n",
    "!python buildStripes.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"for\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"establishing\": 59}\r\n",
      "\"forms\"\t{\"a\": 116, \"of\": 232, \"collection\": 116}\r\n",
      "\"general\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"biography\": 92}\r\n",
      "\"george\"\t{\"a\": 92, \"of\": 92, \"biography\": 92, \"general\": 92}\r\n",
      "\"government\"\t{\"a\": 102, \"case\": 102, \"study\": 102, \"in\": 102}\r\n",
      "\"in\"\t{\"a\": 1201, \"case\": 102, \"government\": 102, \"study\": 102, \"child's\": 1099, \"wales\": 1099, \"christmas\": 1099}\r\n",
      "\"limited\"\t{\"a\": 55, \"case\": 55, \"study\": 55, \"of\": 55}\r\n",
      "\"narrative\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"circumstantial\": 62}\r\n",
      "\"of\"\t{\"a\": 1011, \"case\": 502, \"circumstantial\": 62, \"george\": 92, \"limited\": 55, \"tales\": 123, \"collection\": 355, \"the\": 62, \"forms\": 232, \"female\": 447, \"narrative\": 62, \"fairy\": 123, \"general\": 92, \"study\": 502, \"biography\": 92}\r\n",
      "\"religious\"\t{\"a\": 59, \"bill\": 59, \"for\": 59, \"establishing\": 59}\r\n",
      "\"sea\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"by\": 62}\r\n",
      "\"study\"\t{\"a\": 604, \"case\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"female\": 447, \"in\": 102}\r\n",
      "\"tales\"\t{\"a\": 123, \"of\": 123, \"fairy\": 123, \"collection\": 123}\r\n",
      "\"the\"\t{\"a\": 124, \"city\": 62, \"circumstantial\": 62, \"of\": 62, \"sea\": 62, \"narrative\": 62, \"by\": 62}\r\n",
      "\"wales\"\t{\"a\": 1099, \"in\": 1099, \"christmas\": 1099, \"child's\": 1099}\r\n",
      "\"a\"\t{\"limited\": 55, \"female\": 447, \"general\": 92, \"sea\": 62, \"in\": 1201, \"religious\": 59, \"george\": 92, \"biography\": 92, \"city\": 62, \"for\": 59, \"tales\": 123, \"child's\": 1099, \"forms\": 116, \"wales\": 1099, \"christmas\": 1099, \"government\": 102, \"collection\": 239, \"by\": 62, \"case\": 604, \"circumstantial\": 62, \"fairy\": 123, \"of\": 1011, \"study\": 604, \"bill\": 59, \"establishing\": 59, \"narrative\": 62, \"the\": 124}\r\n",
      "\"bill\"\t{\"a\": 59, \"religious\": 59, \"for\": 59, \"establishing\": 59}\r\n",
      "\"biography\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"general\": 92}\r\n",
      "\"by\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"sea\": 62}\r\n",
      "\"case\"\t{\"a\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"study\": 604, \"female\": 447, \"in\": 102}\r\n",
      "\"child's\"\t{\"a\": 1099, \"wales\": 1099, \"christmas\": 1099, \"in\": 1099}\r\n",
      "\"christmas\"\t{\"a\": 1099, \"wales\": 1099, \"in\": 1099, \"child's\": 1099}\r\n",
      "\"circumstantial\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"narrative\": 62}\r\n",
      "\"city\"\t{\"a\": 62, \"the\": 62, \"by\": 62, \"sea\": 62}\r\n",
      "\"collection\"\t{\"a\": 239, \"forms\": 116, \"fairy\": 123, \"tales\": 123, \"of\": 355}\r\n",
      "\"establishing\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"for\": 59}\r\n",
      "\"fairy\"\t{\"a\": 123, \"of\": 123, \"tales\": 123, \"collection\": 123}\r\n",
      "\"female\"\t{\"a\": 447, \"case\": 447, \"study\": 447, \"of\": 447}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: Unknown command\n",
      "Did you mean -rm?  This command begins with a dash.\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.hyeramoon.20170219.222129.200308\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes.hyeramoon.20170219.222129.200308/output...\n",
      "Removing temp directory /tmp/buildStripes.hyeramoon.20170219.222129.200308...\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 2\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs rm --recursive systems_test_stripes_2\n",
    "!python buildStripes.py -r local atlas-boon-systems-test.txt > systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cava\"\t{\"dipped\": 10, \"boon\": 10}\r\n",
      "\"dipped\"\t{\"atlas\": 15, \"boon\": 10, \"cava\": 10}\r\n",
      "\"atlas\"\t{\"dipped\": 15, \"boon\": 50}\r\n",
      "\"boon\"\t{\"atlas\": 50, \"dipped\": 10, \"cava\": 10}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"DocA\"\t{\"X\":20, \"Y\":30, \"Z\":5}\r\n",
      "\"DocB\"\t{\"X\":100, \"Y\":20}\r\n",
      "\"DocC\"\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\r\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Stripes for systems test 3 (given, no need to build stripes)\n",
    "########################################################################\n",
    "\n",
    "with open(\"systems_test_stripes_3\", \"w\") as f:\n",
    "    f.writelines([\n",
    "        '\"DocA\"\\t{\"X\":20, \"Y\":30, \"Z\":5}\\n',\n",
    "        '\"DocB\"\\t{\"X\":100, \"Y\":20}\\n',  \n",
    "        '\"DocC\"\\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\\n'\n",
    "    ])\n",
    "!cat systems_test_stripes_3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Build Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.hyeramoon.20170219.222223.143120\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.hyeramoon.20170219.222223.143120/output...\n",
      "Removing temp directory /tmp/invertedIndex.hyeramoon.20170219.222223.143120...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_1 > systems_test_index_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.hyeramoon.20170219.222226.587406\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.hyeramoon.20170219.222226.587406/output...\n",
      "Removing temp directory /tmp/invertedIndex.hyeramoon.20170219.222226.587406...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_2 > systems_test_index_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.hyeramoon.20170219.222229.778327\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.hyeramoon.20170219.222229.778327/output...\n",
      "Removing temp directory /tmp/invertedIndex.hyeramoon.20170219.222229.778327...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_3 > systems_test_index_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  1  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
      "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
      "       \"general\" |            a 27 |     biography 4 |        george 4\n",
      "        \"george\" |            a 27 |     biography 4 |       general 4\n",
      "    \"government\" |            a 27 |          case 7 |            in 7\n",
      "            \"in\" |            a 27 |          case 7 |       child's 4\n",
      "       \"limited\" |            a 27 |          case 7 |           of 15\n",
      "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
      "            \"of\" |            a 27 |     biography 4 |          case 7\n",
      "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
      "           \"sea\" |            a 27 |            by 4 |          city 4\n",
      "         \"study\" |            a 27 |          case 7 |        female 4\n",
      "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
      "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
      "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
      "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
      "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
      "     \"biography\" |            a 27 |       general 4 |        george 4\n",
      "            \"by\" |            a 27 |          city 4 |           sea 4\n",
      "          \"case\" |            a 27 |        female 4 |    government 4\n",
      "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
      "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
      "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
      "          \"city\" |            a 27 |            by 4 |           sea 4\n",
      "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
      "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
      "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
      "        \"female\" |            a 27 |          case 7 |           of 15\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  2  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
      "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
      "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
      "          \"cava\" |          boon 3 |        dipped 3 |                \n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  3  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "             \"Z\" |          DocA 3 |          DocC 4 |                \n",
      "             \"M\" |          DocC 4 |                 |                \n",
      "             \"N\" |          DocC 4 |                 |                \n",
      "             \"X\" |          DocA 3 |          DocB 2 |                \n",
      "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Pretty print systems tests for generating Inverted Index\n",
    "##########################################################\n",
    "\n",
    "import json\n",
    "\n",
    "for i in range(1,4):\n",
    "  print \"—\"*100\n",
    "  print \"Systems test \",i,\" - Inverted Index\"\n",
    "  print \"—\"*100  \n",
    "  with open(\"systems_test_index_\"+str(i),\"r\") as f:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "          line = line.strip()\n",
    "          word,stripe = line.split(\"\\t\")\n",
    "          stripe = json.loads(stripe)\n",
    "          stripe.extend([[\"\",\"\"] for _ in xrange(3 - len(stripe))])\n",
    "\n",
    "          print \"{0:>16} |{1:>16} |{2:>16} |{3:>16}\".format(\n",
    "              (word), stripe[0][0]+\" \"+str(stripe[0][1]), stripe[1][0]+\" \"+str(stripe[1][1]), stripe[2][0]+\" \"+str(stripe[2][1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Calculate similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/similarity.hyeramoon.20170219.224117.065301\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224117.065301/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob5883782439861210703.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_5819\n",
      "  Submitted application application_1487024364319_5819\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_5819/\n",
      "  Running job: job_1487024364319_5819\n",
      "  Job job_1487024364319_5819 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_5819 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224117.065301/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3762\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=31512\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3051\n",
      "\t\tFILE: Number of bytes written=394944\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4130\n",
      "\t\tHDFS: Number of bytes written=31512\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10566144\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=19950080\n",
      "\t\tTotal time spent by all map tasks (ms)=6879\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20637\n",
      "\t\tTotal time spent by all reduce tasks (ms)=7793\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=38965\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6879\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=7793\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2830\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=125\n",
      "\t\tInput split bytes=368\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=14528\n",
      "\t\tMap output materialized bytes=4000\n",
      "\t\tMap output records=673\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1878278144\n",
      "\t\tReduce input groups=378\n",
      "\t\tReduce input records=673\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=4000\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1346\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7753641984\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob5775426546298453395.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_5820\n",
      "  Submitted application application_1487024364319_5820\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_5820/\n",
      "  Running job: job_1487024364319_5820\n",
      "  Job job_1487024364319_5820 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_5820 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224117.065301/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=47268\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=31512\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5700\n",
      "\t\tFILE: Number of bytes written=400968\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=47638\n",
      "\t\tHDFS: Number of bytes written=31512\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17762304\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9873920\n",
      "\t\tTotal time spent by all map tasks (ms)=11564\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=34692\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3857\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=19285\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11564\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3857\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2990\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=81\n",
      "\t\tInput split bytes=370\n",
      "\t\tMap input records=378\n",
      "\t\tMap output bytes=31512\n",
      "\t\tMap output materialized bytes=6547\n",
      "\t\tMap output records=378\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1885839360\n",
      "\t\tReduce input groups=34\n",
      "\t\tReduce input records=378\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=6547\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=756\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7772049408\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_1 --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-19 22:42 /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224117.065301/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users      31512 2017-02-19 22:42 /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224117.065301/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224117.065301/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224117.065301/output/part-00000 > systems_test_similarities_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/similarity.hyeramoon.20170219.224638.072782\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224638.072782/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob6518462995055801996.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_5822\n",
      "  Submitted application application_1487024364319_5822\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_5822/\n",
      "  Running job: job_1487024364319_5822\n",
      "  Job job_1487024364319_5822 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_5822 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224638.072782/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=260\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=451\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=105\n",
      "\t\tFILE: Number of bytes written=387206\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=628\n",
      "\t\tHDFS: Number of bytes written=451\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=11151360\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=16355840\n",
      "\t\tTotal time spent by all map tasks (ms)=7260\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21780\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6389\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=31945\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7260\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6389\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2880\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=87\n",
      "\t\tInput split bytes=368\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=156\n",
      "\t\tMap output materialized bytes=158\n",
      "\t\tMap output records=8\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1791524864\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=158\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=16\n",
      "\t\tTotal committed heap usage (bytes)=3710910464\n",
      "\t\tVirtual memory (bytes) snapshot=7742779392\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob3592881194530747660.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_5825\n",
      "  Submitted application application_1487024364319_5825\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_5825/\n",
      "  Running job: job_1487024364319_5825\n",
      "  Job job_1487024364319_5825 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_5825 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224638.072782/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=677\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=451\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=204\n",
      "\t\tFILE: Number of bytes written=389189\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1047\n",
      "\t\tHDFS: Number of bytes written=451\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10177536\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17039360\n",
      "\t\tTotal time spent by all map tasks (ms)=6626\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=19878\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6656\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=33280\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6626\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6656\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2610\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=80\n",
      "\t\tInput split bytes=370\n",
      "\t\tMap input records=6\n",
      "\t\tMap output bytes=451\n",
      "\t\tMap output materialized bytes=264\n",
      "\t\tMap output records=6\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1878257664\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=6\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=264\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=12\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7741673472\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_2 --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-19 22:47 /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224638.072782/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users        451 2017-02-19 22:47 /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224638.072782/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224638.072782/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224638.072782/output/part-00000 > systems_test_similarities_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/similarity.hyeramoon.20170219.224958.724819\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224958.724819/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob7216739956194548758.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_5828\n",
      "  Submitted application application_1487024364319_5828\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_5828/\n",
      "  Running job: job_1487024364319_5828\n",
      "  Job job_1487024364319_5828 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_5828 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224958.724819/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=213\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=328\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67\n",
      "\t\tFILE: Number of bytes written=388065\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=581\n",
      "\t\tHDFS: Number of bytes written=328\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10437120\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=18426880\n",
      "\t\tTotal time spent by all map tasks (ms)=6795\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20385\n",
      "\t\tTotal time spent by all reduce tasks (ms)=7198\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=35990\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6795\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=7198\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2680\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=85\n",
      "\t\tInput split bytes=368\n",
      "\t\tMap input records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=105\n",
      "\t\tMap output records=5\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1877057536\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=105\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=10\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7758417920\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob7990856468221511567.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_5829\n",
      "  Submitted application application_1487024364319_5829\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_5829/\n",
      "  Running job: job_1487024364319_5829\n",
      "  Job job_1487024364319_5829 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_5829 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224958.724819/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=492\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=328\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=226\n",
      "\t\tFILE: Number of bytes written=389200\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=862\n",
      "\t\tHDFS: Number of bytes written=328\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17751552\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=18805760\n",
      "\t\tTotal time spent by all map tasks (ms)=11557\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=34671\n",
      "\t\tTotal time spent by all reduce tasks (ms)=7346\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=36730\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11557\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=7346\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3000\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=92\n",
      "\t\tInput split bytes=370\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=328\n",
      "\t\tMap output materialized bytes=253\n",
      "\t\tMap output records=3\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1882923008\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=253\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=6\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7735623680\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_3 --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-19 22:51 /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224958.724819/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users        328 2017-02-19 22:51 /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224958.724819/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224958.724819/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/similarity.hyeramoon.20170219.224958.724819/output/part-00000 > systems_test_similarities_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  1  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |                       pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       1.000000 |           female - limited |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.868292 |              forms - tales |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.868292 |              fairy - forms |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.830357 |               case - study |       0.857143 |       0.750000 |       0.857143 |       0.857143\n",
      "       0.712500 |            child's - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                  by - city |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                 bill - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 | circumstantial - narrative |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                   by - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        child's - christmas |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |          christmas - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |           bill - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        biography - general |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |         biography - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        bill - establishing |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                 city - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |              fairy - tales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |         establishing - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |           general - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |   establishing - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |            for - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |       government - limited |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        female - government |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.698916 |                     a - of |       0.695666 |       0.500000 |       0.933333 |       0.666667\n",
      "       0.646872 |         collection - tales |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.646872 |         collection - fairy |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.559350 |            government - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                 city - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                female - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |            narrative - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |             female - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |            limited - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                 in - wales |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                  sea - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |               in - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |         government - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |             christmas - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |          case - government |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |             case - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                   by - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |       circumstantial - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |               child's - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |              case - female |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.553861 |     circumstantial - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |          biography - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |             forms - george |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |            forms - limited |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |          forms - narrative |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |            forms - general |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |             female - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.504099 |         collection - forms |       0.516398 |       0.333333 |       0.666667 |       0.500000\n",
      "       0.477970 |            collection - of |       0.461880 |       0.250000 |       0.800000 |       0.400000\n",
      "       0.465201 |                   a - case |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.465201 |                    a - the |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.465201 |                     a - in |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.465201 |                  a - study |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.458333 |          biography - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |   circumstantial - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          biography - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |     christmas - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             by - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |      biography - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        biography - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |     circumstantial - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |      circumstantial - city |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         biography - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |   circumstantial - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |    circumstantial - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 | biography - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |       child's - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |       circumstantial - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        by - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |     circumstantial - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |    circumstantial - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          narrative - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         female - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            fairy - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         government - wales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             female - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            limited - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |           george - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        limited - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         george - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             fairy - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |           city - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          general - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        general - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            general - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          fairy - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |           female - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            female - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            fairy - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            narrative - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             fairy - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             george - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.438276 |                forms - the |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.438276 |              forms - study |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.438276 |               case - forms |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.419343 |circumstantial - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |     biography - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |     collection - narrative |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |        collection - george |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |       collection - limited |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |       collection - general |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |        collection - female |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.410147 |                female - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |             narrative - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |            government - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |                george - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |                 fairy - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |                 of - tales |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |               limited - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |               general - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |        circumstantial - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |             biography - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.389610 |                  case - in |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.389610 |                 in - study |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.386912 |                 of - study |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.386912 |                  case - of |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.384281 |             a - collection |       0.344265 |       0.142857 |       0.800000 |       0.250000\n",
      "       0.365956 |          christmas - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |            biography - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |          biography - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |     circumstantial - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |            child's - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |           biography - case |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               case - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               case - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |           case - narrative |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              case - george |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |             case - general |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               case - fairy |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |      case - circumstantial |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |           case - christmas |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |             case - child's |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               female - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               george - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |             george - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              general - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |            general - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              study - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              limited - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |                tales - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |          narrative - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |                fairy - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              fairy - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              study - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.334842 |              a - religious |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |           a - establishing |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |              a - narrative |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                  a - wales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                a - limited |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                  a - fairy |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |         a - circumstantial |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                   a - bill |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |             a - government |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |              a - christmas |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                  a - tales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                     a - by |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                a - general |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                 a - female |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                 a - george |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                    a - for |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                   a - city |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                a - child's |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                    a - sea |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |              a - biography |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.328008 |                 forms - of |       0.298142 |       0.125000 |       0.666667 |       0.222222\n",
      "       0.317849 |           collection - the |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.317849 |         collection - study |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.317849 |          case - collection |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.287991 |                   of - the |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.287991 |                    in - of |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.273413 |                  a - forms |       0.222222 |       0.071429 |       0.666667 |       0.133333\n",
      "       0.271593 |                    by - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.271593 |                  city - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.271593 |                   of - sea |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.268597 |                forms - sea |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |               city - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |              forms - wales |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |                for - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |       establishing - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |         forms - government |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |          forms - religious |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |          christmas - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |                 by - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |               bill - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |            child's - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.255952 |                 case - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.255952 |                study - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.223214 |          city - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              general - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        limited - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              limited - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                for - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                for - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                  for - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            limited - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             city - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            for - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              for - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          religious - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           for - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               for - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              for - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             female - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            general - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      narrative - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               female - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         female - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        george - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     government - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          narrative - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              city - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              tales - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           city - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                sea - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              fairy - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               city - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                fairy - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          fairy - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         government - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               city - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     government - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         fairy - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         george - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               george - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                fairy - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           government - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       establishing - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            religious - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       establishing - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             city - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         establishing - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   establishing - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     establishing - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  establishing - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      establishing - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     establishing - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             george - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      establishing - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                sea - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       establishing - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          religious - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       general - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        general - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               female - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 city - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              city - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               city - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        city - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     circumstantial - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | circumstantial - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |circumstantial - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       circumstantial - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |circumstantial - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          christmas - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            christmas - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      christmas - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      christmas - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        christmas - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         christmas - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        christmas - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            christmas - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         christmas - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          christmas - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   christmas - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           christmas - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | christmas - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            child's - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              child's - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        child's - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        child's - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          child's - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           child's - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          child's - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              child's - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           child's - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            child's - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     child's - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             child's - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   child's - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 by - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 by - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               by - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            by - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                by - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               by - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                   by - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                by - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 by - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          by - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             by - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               by - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          biography - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            biography - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      biography - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     biography - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            biography - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   biography - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           biography - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      biography - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        biography - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             biography - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               bill - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               bill - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 bill - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           bill - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             bill - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          bill - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              bill - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             bill - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              bill - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               bill - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                bill - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      bill - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           bill - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             bill - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                  bill - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           bill - biography |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             by - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.215666 |                 forms - in |       0.218218 |       0.111111 |       0.333333 |       0.200000\n",
      "       0.205207 |           collection - sea |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |           collection - for |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |     collection - religious |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |  collection - establishing |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |         collection - wales |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |    collection - government |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |       child's - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |     christmas - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |          bill - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |          city - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |            by - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.180200 |                 case - for |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  bill - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |               bill - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 bill - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |             biography - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  by - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                    by - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 by - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                case - city |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |        case - establishing |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |           case - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 case - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |              child's - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |            christmas - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |        circumstantial - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                bill - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                the - wales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                sea - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |            religious - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |          religious - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 in - tales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                   in - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |             in - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |             in - narrative |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |           government - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                george - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |               general - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                for - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                   for - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 fairy - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |         establishing - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |       establishing - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |          establishing - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |               city - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  city - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  for - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.156652 |            collection - in |       0.169031 |       0.090909 |       0.200000 |       0.166667\n",
      "       0.134980 |                   for - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |                 of - wales |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |             of - religious |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |          establishing - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |               child's - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |             christmas - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |                  bill - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.126374 |                   in - the |       0.142857 |       0.076923 |       0.142857 |       0.142857\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  2  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |                       pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       1.000000 |               atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.625000 |              boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
      "       0.389562 |              cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |                boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |             atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |               atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  3  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |                       pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.820791 |                DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
      "       0.553861 |                DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.346722 |                DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Pretty print systems tests FOR ALL TESTS \n",
    "############################################\n",
    "\n",
    "import json\n",
    "for i in range(1,4):\n",
    "  print '—'*110\n",
    "  print \"Systems test \",i,\" - Similarity measures\"\n",
    "  print '—'*110\n",
    "  print \"{0:>15} |{1:>27} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "          \"average\", \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\")\n",
    "  print '-'*110\n",
    "\n",
    "  with open(\"systems_test_similarities_\"+str(i),\"r\") as f:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "          line = line.strip()\n",
    "          avg,stripe = line.split(\"\\t\")\n",
    "          stripe = json.loads(stripe)\n",
    "\n",
    "          print \"{0:>15f} |{1:>27} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "              float(avg), stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.1 <a name=\"5.4.1\"></a>Full-scale experiment: EDA of Google n-grams dataset (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Do some EDA on this dataset using mrjob, e.g., \n",
    "\n",
    "- A. Longest 5-gram (number of characters)\n",
    "- B. Top 10 most frequent words (please use the count information), i.e., unigrams\n",
    "- C. 20 Most/Least densely appearing words (count/pages_count) sorted in decreasing order of relative frequency \n",
    "- D. Distribution of 5-gram sizes (character length).  E.g., count (using the count field) up how many times a 5-gram of 50 characters shows up. Plot the data graphically using a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - A. Longest 5-gram (number of characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting longest5gram.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile longest5gram.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class longest5gram(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.A\n",
    "    \n",
    "    MRJob.SORT_VALUES\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.reduces':'1'\n",
    "        }\n",
    "        return[\n",
    "            MRStep(  \n",
    "                jobconf = JOBCONF_STEP,  # One reducer to find the longest ngram \n",
    "                                         # since only input one line from each mapper\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper,\n",
    "                mapper_final = self.mapper_final,\n",
    "                reducer_init = self.reducer_init,\n",
    "                reducer = self.reducer,\n",
    "                reducer_final = self.reducer_final\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.longest = [\"NA\", 0]\n",
    "    \n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip()\n",
    "        ngram, other = line.split(\"\\t\",1)\n",
    "        char_count = len(str(ngram))  # assuming white space between words counts as character\n",
    "        if char_count > self.longest[1]:\n",
    "            self.longest[1] = char_count\n",
    "            self.longest[0] = ngram    \n",
    "     \n",
    "    \n",
    "    def mapper_final(self):\n",
    "        self.increment_counter('group', 'Num_mapper_calls', 1)\n",
    "        yield self.longest[0], self.longest[1]\n",
    "     \n",
    "    \n",
    "    def reducer_init(self):\n",
    "        self.longest_final = [\"NA\", 0]\n",
    "    \n",
    "    \n",
    "    def reducer(self, ngram, length):\n",
    "        char_count = sum(length)\n",
    "        if char_count > self.longest_final[1]:\n",
    "            self.longest_final[1] = char_count\n",
    "            self.longest_final[0] = ngram\n",
    "            \n",
    "            \n",
    "    def reducer_final(self):\n",
    "        self.increment_counter('group', 'Num_reducer_calls', 1)\n",
    "        yield self.longest_final[0], self.longest_final[1]\n",
    "        \n",
    "        \n",
    "    # END STUDENT CODE 5.4.1.A\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    longest5gram.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x longest5gram.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/longest5gram.hyeramoon.20170220.042755.907411\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042755.907411/files/...\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob7171140693008017713.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6136\n",
      "  Submitted application application_1487024364319_6136\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6136/\n",
      "  Running job: job_1487024364319_6136\n",
      "  Job job_1487024364319_6136 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6136 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042755.907411/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=39\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=99\n",
      "\t\tFILE: Number of bytes written=386870\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1023\n",
      "\t\tHDFS: Number of bytes written=39\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18135552\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8844800\n",
      "\t\tTotal time spent by all map tasks (ms)=11807\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=35421\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3455\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17275\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11807\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3455\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2990\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=105\n",
      "\t\tInput split bytes=460\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=78\n",
      "\t\tMap output materialized bytes=114\n",
      "\t\tMap output records=2\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1756393472\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=1\n",
      "\t\tReduce shuffle bytes=114\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=4\n",
      "\t\tTotal committed heap usage (bytes)=2540175360\n",
      "\t\tVirtual memory (bytes) snapshot=7732596736\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_mapper_calls=2\n",
      "\t\tNum_reducer_calls=1\n"
     ]
    }
   ],
   "source": [
    "!python longest5gram.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 03:03 /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.030239.025648/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users         39 2017-02-20 03:03 /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.030239.025648/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.030239.025648/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A BILL FOR ESTABLISHING RELIGIOUS\"\t33\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.030239.025648/output/part-00000 > \\\n",
    "longest5gram.txt\n",
    "!cat longest5gram.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 alenart hdfs 2156069116 2017-02-19 23:53 /tmp/hw5b/gigantor_file.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp/hw5b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/longest5gram.hyeramoon.20170222.171024.413003\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170222.171024.413003/files/...\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob4774954619501297271.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  Adding a new node: /default-rack/10.251.253.170:50010\n",
      "  Adding a new node: /default-rack/10.251.254.190:50010\n",
      "  Adding a new node: /default-rack/10.251.253.214:50010\n",
      "  Adding a new node: /default-rack/10.251.237.66:50010\n",
      "  Adding a new node: /default-rack/10.251.249.182:50010\n",
      "  number of splits:8\n",
      "  Submitting tokens for job: job_1487024364319_7896\n",
      "  Submitted application application_1487024364319_7896\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7896/\n",
      "  Running job: job_1487024364319_7896\n",
      "  Job job_1487024364319_7896 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7896 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170222.171024.413003/output\n",
      "Counters: 53\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156986620\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=166\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=921\n",
      "\t\tFILE: Number of bytes written=1162254\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156987532\n",
      "\t\tHDFS: Number of bytes written=166\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=27\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=1\n",
      "\t\tKilled map tasks=4\n",
      "\t\tLaunched map tasks=12\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=11\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=857690112\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9308160\n",
      "\t\tTotal time spent by all map tasks (ms)=558392\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=1675176\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3636\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=18180\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=558392\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3636\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=277370\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=4562\n",
      "\t\tInput split bytes=912\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=989\n",
      "\t\tMap output materialized bytes=1146\n",
      "\t\tMap output records=8\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tPhysical memory (bytes) snapshot=6801928192\n",
      "\t\tReduce input groups=8\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=1\n",
      "\t\tReduce shuffle bytes=1146\n",
      "\t\tShuffled Maps =8\n",
      "\t\tSpilled Records=16\n",
      "\t\tTotal committed heap usage (bytes)=13126074368\n",
      "\t\tVirtual memory (bytes) snapshot=20912537600\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_mapper_calls=8\n",
      "\t\tNum_reducer_calls=1\n",
      "\n",
      "real\t2m15.229s\n",
      "user\t0m26.158s\n",
      "sys\t0m1.203s\n"
     ]
    }
   ],
   "source": [
    "!time python longest5gram.py hdfs:///tmp/hw5b/gigantor_file.txt -r hadoop --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 04:30 /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042932.642153/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users        166 2017-02-20 04:30 /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042932.642153/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042932.642153/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AIOPJUMRXUYVASLYHYPSIBEMAPODIKR UFRYDIUUOLBIGASUAURUSREXLISNAYE RNOONDQSRUNSUBUNOUGRABBERYAIRTC UTAHRAPTOREDILEIPMILBDUMMYUVERI SYEVRAHVELOCYALLOSAURUSLINROTSR\"\t159\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042932.642153/output/part-00000 > \\\n",
    "longest5gram.txt\n",
    "!cat longest5gram.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/21 02:57:36 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042932.642153/output' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170220.042932.642153/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Stats: \n",
    "\n",
    "## Longest 5grams MR stats\n",
    "\n",
    "    Altiscale Hadoop\n",
    "    RUNNING for 135s ~= 2 minutes \n",
    "\n",
    "__Step 1:__  \n",
    "\n",
    "    Map tasks = 8\n",
    "    Reduce tasks = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - B. Top 10 most frequent words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mostFrequentWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostFrequentWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class mostFrequentWords(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.B\n",
    "        \n",
    "    def steps(self):\n",
    "        JOBCONF_STEPtest = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.job.reduces':'3'  # just testing with 3 reducers for small dataset - to be deleted for actual dataset\n",
    "        }\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.job.reduces':'1'  # Note: one reducer suffice since each partition from previous MRJob only\n",
    "                                      # emits 10 lines\n",
    "        }\n",
    "        return[\n",
    "            MRStep(\n",
    "                #jobconf = JOBCONF_STEPtest, # just testing many reducers for small dataset - to be deleted for actual dataset\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer_init = self.reducer_init,\n",
    "                reducer = self.reducer,\n",
    "                reducer_final = self.reducer_final\n",
    "            ),\n",
    "            MRStep(\n",
    "                jobconf = JOBCONF_STEP,\n",
    "                reducer_init = self.reducer_top10_init,\n",
    "                reducer = self.reducer_top10,\n",
    "                reducer_final = self.reducer_top10_final\n",
    "            )\n",
    "\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        self.increment_counter('group', 'Num_mapper_calls', 1)\n",
    "        ngram, count, other = line.strip().split('\\t',2)\n",
    "        words = ngram.split(\" \")\n",
    "        count = int(count)\n",
    "        for word in words:\n",
    "            yield str(word).lower(), count\n",
    "           \n",
    "        \n",
    "    def combiner(self,word, counts):\n",
    "        self.increment_counter('group', 'Num_combiner_calls', 1)\n",
    "        yield word, sum(counts)\n",
    "    \n",
    "    \n",
    "    def reducer_init(self):\n",
    "        self.wordcounts_per_partition = [[\"None\", 0]] * 10\n",
    "            \n",
    "                \n",
    "    def reducer(self, word, counts):\n",
    "        count = sum(counts)\n",
    "        index = -1\n",
    "        for i in range(10):\n",
    "            if count > self.wordcounts_per_partition[i][1]:  # note: number in counts in increasing order\n",
    "                index = i  # find where to insert the wordcount in the count list\n",
    "            else:\n",
    "                break\n",
    "        if index != -1:\n",
    "            self.wordcounts_per_partition.insert(index+1, [word, count])\n",
    "            self.wordcounts_per_partition = self.wordcounts_per_partition[1:11]  # take the 10 items with largest count out of 11 items\n",
    "\n",
    "        \n",
    "    def reducer_final(self):\n",
    "        self.increment_counter('group', 'Num_reducer_calls', 1)\n",
    "        \n",
    "        for i in range(9,-1,-1):\n",
    "            yield self.wordcounts_per_partition[i][0], self.wordcounts_per_partition[i][1]  # top 10 most frequent words \n",
    "                                                                                            # per partition\n",
    "    \n",
    "        \n",
    "    def reducer_top10_init(self):\n",
    "        self.wordcounts_total = [[\"None\", 0]] * 10\n",
    "    \n",
    "    \n",
    "    def reducer_top10(self, word, counts):\n",
    "        count = sum(counts)\n",
    "        index = -1\n",
    "        for i in range(10):\n",
    "            if count > self.wordcounts_total[i][1]:  # note: number in counts in increasing order\n",
    "                index = i  # find where to insert the wordcount in the count list\n",
    "            else:\n",
    "                break\n",
    "        if index != -1:\n",
    "            self.wordcounts_total.insert(index+1, [word, count])\n",
    "            self.wordcounts_total = self.wordcounts_total[1:11]  # take the 10 items with largest count out of 11 items\n",
    "            \n",
    "            \n",
    "    def reducer_top10_final(self):\n",
    "        self.increment_counter('group', 'Num_reducer2_calls', 1)\n",
    "        \n",
    "        for i in range(9,-1,-1):\n",
    "            yield self.wordcounts_total[i][0], self.wordcounts_total[i][1]  # top 10 most frequent words \n",
    "    \n",
    "    \n",
    "    # END STUDENT CODE 5.4.1.B\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    mostFrequentWords.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x mostFrequentWords.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/mostFrequentWords.hyeramoon.20170220.043728.816288\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob9051497411254894967.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6146\n",
      "  Submitted application application_1487024364319_6146\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6146/\n",
      "  Running job: job_1487024364319_6146\n",
      "  Job job_1487024364319_6146 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6146 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/step-output/0000\n",
      "Counters: 53\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=127\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=430\n",
      "\t\tFILE: Number of bytes written=390380\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1033\n",
      "\t\tHDFS: Number of bytes written=127\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=20582400\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15549440\n",
      "\t\tTotal time spent by all map tasks (ms)=13400\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=40200\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6074\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=30370\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13400\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6074\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3050\n",
      "\t\tCombine input records=50\n",
      "\t\tCombine output records=31\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=89\n",
      "\t\tInput split bytes=470\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=552\n",
      "\t\tMap output materialized bytes=458\n",
      "\t\tMap output records=50\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1881993216\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=31\n",
      "\t\tReduce output records=10\n",
      "\t\tReduce shuffle bytes=458\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=62\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7736229888\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_combiner_calls=31\n",
      "\t\tNum_mapper_calls=10\n",
      "\t\tNum_reducer_calls=1\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob9112914186024731625.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6147\n",
      "  Submitted application application_1487024364319_6147\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6147/\n",
      "  Running job: job_1487024364319_6147\n",
      "  Job job_1487024364319_6147 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6147 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=191\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=127\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=166\n",
      "\t\tFILE: Number of bytes written=388400\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=575\n",
      "\t\tHDFS: Number of bytes written=127\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18508800\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15592960\n",
      "\t\tTotal time spent by all map tasks (ms)=12050\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=36150\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6091\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=30455\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12050\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6091\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2980\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=96\n",
      "\t\tInput split bytes=384\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=127\n",
      "\t\tMap output materialized bytes=177\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1797951488\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tReduce shuffle bytes=177\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=3981967360\n",
      "\t\tVirtual memory (bytes) snapshot=7762006016\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_reducer2_calls=1\n"
     ]
    }
   ],
   "source": [
    "!python mostFrequentWords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "--no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 04:38 /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/output/_SUCCESS\n",
      "-rw-r--r--   3 hyeramoon users        127 2017-02-20 04:38 /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/output/part-00000\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t2217\r\n",
      "\"in\"\t1201\r\n",
      "\"child's\"\t1099\r\n",
      "\"christmas\"\t1099\r\n",
      "\"wales\"\t1099\r\n",
      "\"of\"\t1011\r\n",
      "\"case\"\t604\r\n",
      "\"study\"\t604\r\n",
      "\"female\"\t447\r\n",
      "\"collection\"\t239\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/output/part-00000 > \\\n",
    "mostFrequentWords_test.txt\n",
    "!cat mostFrequentWords_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/21 02:59:26 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/output' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.043728.816288/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/mostFrequentWords.hyeramoon.20170222.171738.832016\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170222.171738.832016/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob5101050960391884442.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  Adding a new node: /default-rack/10.251.253.170:50010\n",
      "  Adding a new node: /default-rack/10.251.254.190:50010\n",
      "  Adding a new node: /default-rack/10.251.253.214:50010\n",
      "  Adding a new node: /default-rack/10.251.237.66:50010\n",
      "  Adding a new node: /default-rack/10.251.249.182:50010\n",
      "  number of splits:8\n",
      "  Submitting tokens for job: job_1487024364319_7901\n",
      "  Submitted application application_1487024364319_7901\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7901/\n",
      "  Running job: job_1487024364319_7901\n",
      "  Job job_1487024364319_7901 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7901 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170222.171738.832016/step-output/0000\n",
      "Counters: 52\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156986620\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=159\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=29035209\n",
      "\t\tFILE: Number of bytes written=41288053\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156987532\n",
      "\t\tHDFS: Number of bytes written=159\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=27\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=8\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=8\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18256300032\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=64401920\n",
      "\t\tTotal time spent by all map tasks (ms)=11885612\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=35656836\n",
      "\t\tTotal time spent by all reduce tasks (ms)=25157\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=125785\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11885612\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=25157\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=12532100\n",
      "\t\tCombine input records=295296974\n",
      "\t\tCombine output records=2877833\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=38492\n",
      "\t\tInput split bytes=912\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=3136729760\n",
      "\t\tMap output materialized bytes=11085338\n",
      "\t\tMap output records=293411330\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tPhysical memory (bytes) snapshot=6073036800\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=992189\n",
      "\t\tReduce output records=10\n",
      "\t\tReduce shuffle bytes=11085338\n",
      "\t\tShuffled Maps =8\n",
      "\t\tSpilled Records=3870022\n",
      "\t\tTotal committed heap usage (bytes)=13796638720\n",
      "\t\tVirtual memory (bytes) snapshot=20898160640\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_combiner_calls=2877833\n",
      "\t\tNum_mapper_calls=58682266\n",
      "\t\tNum_reducer_calls=1\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob777733665254607979.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_7929\n",
      "  Submitted application application_1487024364319_7929\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7929/\n",
      "  Running job: job_1487024364319_7929\n",
      "  Job job_1487024364319_7929 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7929 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170222.171738.832016/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=239\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=159\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=201\n",
      "\t\tFILE: Number of bytes written=388941\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=623\n",
      "\t\tHDFS: Number of bytes written=159\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18422784\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15226880\n",
      "\t\tTotal time spent by all map tasks (ms)=11994\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=35982\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5948\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29740\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11994\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5948\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2710\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=70\n",
      "\t\tInput split bytes=384\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=159\n",
      "\t\tMap output materialized bytes=211\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1879248896\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tReduce shuffle bytes=211\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7705169920\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_reducer2_calls=1\n",
      "\n",
      "real\t27m25.340s\n",
      "user\t0m36.685s\n",
      "sys\t0m1.626s\n"
     ]
    }
   ],
   "source": [
    "!time python mostFrequentWords.py -r hadoop hdfs:///tmp/hw5b/gigantor_file.txt --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 05:00 /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.044101.148817/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users        159 2017-02-20 05:00 /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170220.044101.148817/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170222.171738.832016/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\"\t5490815394\r\n",
      "\"of\"\t3698583299\r\n",
      "\"to\"\t2227866570\r\n",
      "\"in\"\t1421312776\r\n",
      "\"a\"\t1361123022\r\n",
      "\"and\"\t1149577477\r\n",
      "\"that\"\t802921147\r\n",
      "\"is\"\t758328796\r\n",
      "\"be\"\t688707130\r\n",
      "\"as\"\t492170314\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170222.171738.832016/output/part-00000 > \\\n",
    "mostFrequentWords.txt\n",
    "!cat mostFrequentWords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/22 17:48:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/longest5gram.hyeramoon.20170222.171024.413003' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n",
      "17/02/22 17:48:17 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/mostFrequentWords.hyeramoon.20170222.171738.832016' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words MR stats\n",
    "    \n",
    "    Altiscale Hadoop\n",
    "    RUNNING for 1645s ~= 27 minutes \n",
    "    \n",
    "__Step 1:__   \n",
    "  \n",
    "    Launched map tasks=8  \n",
    "    Launched reduce tasks=1   \n",
    "\n",
    "__Step 2:__  \n",
    "    Launched map tasks=2 \n",
    "    Launched reduce tasks=1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - C. 20 Most/Least densely appearing words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mostLeastDenseWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostLeastDenseWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import re\n",
    "#import numpy as np\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class mostLeastDenseWords(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.C\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.reduce.tasks': 3  # just testing with 3 reducers for small dataset - to be deleted for actual dataset\n",
    "        }\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k2,2 -k1,1',\n",
    "            'mapred.reduce.tasks': 1  # Note: one reducer suffice since each partition from previous MRJob only\n",
    "                                      # emits 40 lines (20 top and 20 worst)\n",
    "        }\n",
    "        return[\n",
    "            MRStep(\n",
    "                #jobconf = JOBCONF_STEP1, # just testing with 3 reducers dor small dataset - to be deleted for actual dataset\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer_init = self.reducer_init,\n",
    "                reducer = self.reducer,\n",
    "                reducer_final = self.reducer_final\n",
    "            )\n",
    "            ,\n",
    "            MRStep(\n",
    "                jobconf = JOBCONF_STEP,\n",
    "                reducer_init = self.reducer_topworst20_init,\n",
    "                reducer = self.reducer_topworst20,\n",
    "                reducer_final = self.reducer_topworst20_final\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        self.increment_counter('group', 'Num_mapper_calls', 1)\n",
    "        ngram, count, page_count, book_count = line.strip().split('\\t')\n",
    "        count = int(count)\n",
    "        page_count = int(page_count)\n",
    "        words = ngram.split(\" \")\n",
    "        for word in words:\n",
    "            yield word.lower(), [count, page_count]\n",
    "       \n",
    "    \n",
    "    def combiner(self, word, counts):\n",
    "        count = 0\n",
    "        page_count = 0\n",
    "        for item in counts:\n",
    "            count += item[0]\n",
    "            page_count += item[1]\n",
    "        yield word, [count, page_count]\n",
    "      \n",
    "    \n",
    "    def reducer_init(self):\n",
    "        self.top20_per_partition = [[\"None\", 0.0]] * 20\n",
    "        self.worst20_per_partition = [[\"None\", 100.0]] * 20\n",
    "    \n",
    "    \n",
    "    def reducer(self, word, values):\n",
    "        total_count = 0\n",
    "        total_page_count = 0\n",
    "        for value in values:\n",
    "            total_count += value[0]\n",
    "            total_page_count += value[1]\n",
    "        frequency = float(total_count)/float(total_page_count)\n",
    "        \n",
    "        index = -1\n",
    "        for i in range(20):\n",
    "            if frequency > self.top20_per_partition[i][1]:  # note: density in increasing order\n",
    "                index = i  # find where to insert the density in the count list\n",
    "            else:\n",
    "                break\n",
    "        if index != -1:\n",
    "            self.top20_per_partition.insert(index+1, [word, frequency])\n",
    "            self.top20_per_partition = self.top20_per_partition[1:21]  # take the 20 items with \n",
    "                                                                       # highest density out of 21 items\n",
    "        \n",
    "        index = -1\n",
    "        for i in range(19,-1,-1):\n",
    "            if frequency <= self.worst20_per_partition[i][1]:  # note: density in increasing order\n",
    "                                                               # note2: <= so that for words with same frequency,\n",
    "                                                               # the words are sorted in decreasing alpha order\n",
    "                index = i  # find where to insert the density in the list\n",
    "            else:\n",
    "                break\n",
    "        if index != -1:\n",
    "            self.worst20_per_partition.insert(index, [word, frequency])\n",
    "            self.worst20_per_partition = self.worst20_per_partition[0:20]  # take the 20 items with\n",
    "                                                                           # lowest density out of 21 items\n",
    "        \n",
    "    def reducer_final(self):\n",
    "        self.increment_counter('group', 'Num_reducer_calls', 1)\n",
    "        \n",
    "        for i in range(19,-1,-1):\n",
    "            yield \"top\", (self.top20_per_partition[i][0], self.top20_per_partition[i][1])  # top 20 most dense words per partition\n",
    "            \n",
    "        for i in range(20):\n",
    "            yield \"worst\", (self.worst20_per_partition[i][0], self.worst20_per_partition[i][1])  # top 20 least dense words per partition\n",
    "            \n",
    "        \n",
    "    def reducer_topworst20_init(self):\n",
    "        self.top20_total = []\n",
    "        self.worst20_total = []\n",
    "    \n",
    "    \n",
    "    def reducer_topworst20(self, key, values):\n",
    "        for value in values:\n",
    "            word = value[0]\n",
    "            frequency = value[1]\n",
    "        \n",
    "            if key == \"top\":\n",
    "                if word != \"None\":\n",
    "                    self.top20_total.append([word, frequency])\n",
    "                \n",
    "            if key == \"worst\":\n",
    "                if word != \"None\":\n",
    "                    self.worst20_total.append([word, frequency])\n",
    "            \n",
    "            \n",
    "    def reducer_topworst20_final(self):\n",
    "        self.increment_counter('group', 'Num_reducer2_calls', 1)\n",
    "        \n",
    "        self.top20 = sorted(sorted(self.top20_total, key = lambda x : x[0]), key = lambda x : x[1], reverse = True)[0:20]\n",
    "        self.worst20 = sorted(sorted(self.worst20_total, key = lambda x: x[0], reverse =True), key = lambda x: x[1])[0:20]\n",
    "        \n",
    "        # 20 most dense words\n",
    "        for i in range(20):\n",
    "            yield \"Most dense word #\"+str(i+1)+\":\", (self.top20[i][0], self.top20[i][1])    \n",
    "        \n",
    "        # 20 least dense words\n",
    "        for i in range(20):\n",
    "            yield \"Least dense word #\"+str(i+1)+\":\", (self.worst20[i][0], self.worst20[i][1])\n",
    "        \n",
    "        \n",
    "    # END STUDENT CODE 5.4.1.C\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    mostLeastDenseWords.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x mostLeastDenseWords.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/mostLeastDenseWords.hyeramoon.20170220.175958.522437\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.175958.522437/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob8345571854754624931.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6405\n",
      "  Submitted application application_1487024364319_6405\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6405/\n",
      "  Running job: job_1487024364319_6405\n",
      "  Job job_1487024364319_6405 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6405 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.175958.522437/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1297\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=551\n",
      "\t\tFILE: Number of bytes written=390245\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1037\n",
      "\t\tHDFS: Number of bytes written=1297\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18980352\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15559680\n",
      "\t\tTotal time spent by all map tasks (ms)=12357\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=37071\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6078\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=30390\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12357\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6078\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3280\n",
      "\t\tCombine input records=50\n",
      "\t\tCombine output records=31\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=138\n",
      "\t\tInput split bytes=474\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=882\n",
      "\t\tMap output materialized bytes=581\n",
      "\t\tMap output records=50\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1806577664\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=31\n",
      "\t\tReduce output records=40\n",
      "\t\tReduce shuffle bytes=581\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=62\n",
      "\t\tTotal committed heap usage (bytes)=3981967360\n",
      "\t\tVirtual memory (bytes) snapshot=7705182208\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_mapper_calls=10\n",
      "\t\tNum_reducer_calls=1\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.2:\n",
      "The have been translated as follows\n",
      " mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob3493822568326448134.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6406\n",
      "  Submitted application application_1487024364319_6406\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6406/\n",
      "  Running job: job_1487024364319_6406\n",
      "  Job job_1487024364319_6406 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6406 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.175958.522437/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1946\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1939\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=673\n",
      "\t\tFILE: Number of bytes written=390618\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2334\n",
      "\t\tHDFS: Number of bytes written=1939\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=20654592\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=20771840\n",
      "\t\tTotal time spent by all map tasks (ms)=13447\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=40341\n",
      "\t\tTotal time spent by all reduce tasks (ms)=8114\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=40570\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13447\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=8114\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3260\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=96\n",
      "\t\tInput split bytes=388\n",
      "\t\tMap input records=40\n",
      "\t\tMap output bytes=1297\n",
      "\t\tMap output materialized bytes=837\n",
      "\t\tMap output records=40\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1882222592\n",
      "\t\tReduce input groups=40\n",
      "\t\tReduce input records=40\n",
      "\t\tReduce output records=40\n",
      "\t\tReduce shuffle bytes=837\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=80\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7756214272\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_reducer2_calls=1\n"
     ]
    }
   ],
   "source": [
    "!python mostLeastDenseWords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "--no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 18:01 /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.175958.522437/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users       1939 2017-02-20 18:01 /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.175958.522437/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.175958.522437/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Most dense word #1:\"\t[\"forms\", 1.1262135922330097]\r\n",
      "\"Most dense word #2:\"\t[\"collection\", 1.0863636363636364]\r\n",
      "\"Most dense word #3:\"\t[\"fairy\", 1.0512820512820513]\r\n",
      "\"Most dense word #4:\"\t[\"tales\", 1.0512820512820513]\r\n",
      "\"Most dense word #5:\"\t[\"child's\", 1.0358152686145146]\r\n",
      "\"Most dense word #6:\"\t[\"christmas\", 1.0358152686145146]\r\n",
      "\"Most dense word #7:\"\t[\"wales\", 1.0358152686145146]\r\n",
      "\"Most dense word #8:\"\t[\"of\", 1.0348004094165815]\r\n",
      "\"Most dense word #9:\"\t[\"by\", 1.0333333333333334]\r\n",
      "\"Most dense word #10:\"\t[\"city\", 1.0333333333333334]\r\n",
      "\"Most dense word #11:\"\t[\"sea\", 1.0333333333333334]\r\n",
      "\"Most dense word #12:\"\t[\"in\", 1.0326741186586414]\r\n",
      "\"Most dense word #13:\"\t[\"a\", 1.0282931354359925]\r\n",
      "\"Most dense word #14:\"\t[\"biography\", 1.0222222222222221]\r\n",
      "\"Most dense word #15:\"\t[\"general\", 1.0222222222222221]\r\n",
      "\"Most dense word #16:\"\t[\"george\", 1.0222222222222221]\r\n",
      "\"Most dense word #17:\"\t[\"the\", 1.0163934426229508]\r\n",
      "\"Most dense word #18:\"\t[\"bill\", 1.0]\r\n",
      "\"Most dense word #19:\"\t[\"case\", 1.0]\r\n",
      "\"Most dense word #20:\"\t[\"circumstantial\", 1.0]\r\n",
      "\"Least dense word #1:\"\t[\"study\", 1.0]\r\n",
      "\"Least dense word #2:\"\t[\"religious\", 1.0]\r\n",
      "\"Least dense word #3:\"\t[\"narrative\", 1.0]\r\n",
      "\"Least dense word #4:\"\t[\"limited\", 1.0]\r\n",
      "\"Least dense word #5:\"\t[\"government\", 1.0]\r\n",
      "\"Least dense word #6:\"\t[\"for\", 1.0]\r\n",
      "\"Least dense word #7:\"\t[\"female\", 1.0]\r\n",
      "\"Least dense word #8:\"\t[\"establishing\", 1.0]\r\n",
      "\"Least dense word #9:\"\t[\"circumstantial\", 1.0]\r\n",
      "\"Least dense word #10:\"\t[\"case\", 1.0]\r\n",
      "\"Least dense word #11:\"\t[\"bill\", 1.0]\r\n",
      "\"Least dense word #12:\"\t[\"the\", 1.0163934426229508]\r\n",
      "\"Least dense word #13:\"\t[\"george\", 1.0222222222222221]\r\n",
      "\"Least dense word #14:\"\t[\"general\", 1.0222222222222221]\r\n",
      "\"Least dense word #15:\"\t[\"biography\", 1.0222222222222221]\r\n",
      "\"Least dense word #16:\"\t[\"a\", 1.0282931354359925]\r\n",
      "\"Least dense word #17:\"\t[\"in\", 1.0326741186586414]\r\n",
      "\"Least dense word #18:\"\t[\"sea\", 1.0333333333333334]\r\n",
      "\"Least dense word #19:\"\t[\"city\", 1.0333333333333334]\r\n",
      "\"Least dense word #20:\"\t[\"by\", 1.0333333333333334]\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.175958.522437/output/part-00000 \\\n",
    "> mostLeastDenseWords_mini.txt\n",
    "!cat mostLeastDenseWords_mini.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/mostLeastDenseWords.hyeramoon.20170222.174852.077612\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170222.174852.077612/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob3826745850845511144.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  Adding a new node: /default-rack/10.251.254.190:50010\n",
      "  Adding a new node: /default-rack/10.251.253.170:50010\n",
      "  Adding a new node: /default-rack/10.251.253.214:50010\n",
      "  Adding a new node: /default-rack/10.251.249.182:50010\n",
      "  Adding a new node: /default-rack/10.251.237.66:50010\n",
      "  number of splits:8\n",
      "  Submitting tokens for job: job_1487024364319_7938\n",
      "  Submitted application application_1487024364319_7938\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7938/\n",
      "  Running job: job_1487024364319_7938\n",
      "  Job job_1487024364319_7938 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7938 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170222.174852.077612/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156986620\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1279\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=41327237\n",
      "\t\tFILE: Number of bytes written=57625570\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156987532\n",
      "\t\tHDFS: Number of bytes written=1279\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=27\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=8\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=8\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=29434951680\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=122462720\n",
      "\t\tTotal time spent by all map tasks (ms)=19163380\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=57490140\n",
      "\t\tTotal time spent by all reduce tasks (ms)=47837\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=239185\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=19163380\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=47837\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=20563890\n",
      "\t\tCombine input records=295358675\n",
      "\t\tCombine output records=2939534\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=34787\n",
      "\t\tInput split bytes=912\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=4997096500\n",
      "\t\tMap output materialized bytes=15130557\n",
      "\t\tMap output records=293411330\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tPhysical memory (bytes) snapshot=5988753408\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=992189\n",
      "\t\tReduce output records=40\n",
      "\t\tReduce shuffle bytes=15130557\n",
      "\t\tShuffled Maps =8\n",
      "\t\tSpilled Records=3931723\n",
      "\t\tTotal committed heap usage (bytes)=13733724160\n",
      "\t\tVirtual memory (bytes) snapshot=20948013056\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_mapper_calls=58682266\n",
      "\t\tNum_reducer_calls=1\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.2:\n",
      "The have been translated as follows\n",
      " mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob5518688540140885046.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_7993\n",
      "  Submitted application application_1487024364319_7993\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7993/\n",
      "  Running job: job_1487024364319_7993\n",
      "  Job job_1487024364319_7993 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7993 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170222.174852.077612/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1919\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1921\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=935\n",
      "\t\tFILE: Number of bytes written=390967\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2307\n",
      "\t\tHDFS: Number of bytes written=1921\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=33696768\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14661120\n",
      "\t\tTotal time spent by all map tasks (ms)=21938\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=65814\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5727\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=28635\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=21938\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5727\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2820\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=100\n",
      "\t\tInput split bytes=388\n",
      "\t\tMap input records=40\n",
      "\t\tMap output bytes=1279\n",
      "\t\tMap output materialized bytes=924\n",
      "\t\tMap output records=40\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1885978624\n",
      "\t\tReduce input groups=38\n",
      "\t\tReduce input records=40\n",
      "\t\tReduce output records=40\n",
      "\t\tReduce shuffle bytes=924\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=80\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7784550400\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_reducer2_calls=1\n",
      "\n",
      "real\t43m20.982s\n",
      "user\t0m38.118s\n",
      "sys\t0m1.781s\n"
     ]
    }
   ],
   "source": [
    "!time python mostLeastDenseWords.py -r hadoop hdfs:///tmp/hw5b/gigantor_file.txt --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 18:19 /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.180420.764908/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users       1921 2017-02-20 18:19 /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170220.180420.764908/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170222.174852.077612/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Most dense word #1:\"\t[\"xxxx\", 11.557291666666666]\r\n",
      "\"Most dense word #2:\"\t[\"blah\", 8.0741599073001158]\r\n",
      "\"Most dense word #3:\"\t[\"nnn\", 7.5333333333333332]\r\n",
      "\"Most dense word #4:\"\t[\"na\", 6.2017491314244637]\r\n",
      "\"Most dense word #5:\"\t[\"oooooooooooooooo\", 4.921875]\r\n",
      "\"Most dense word #6:\"\t[\"nd\", 4.8543057272352703]\r\n",
      "\"Most dense word #7:\"\t[\"llll\", 4.5116279069767442]\r\n",
      "\"Most dense word #8:\"\t[\"oooooo\", 4.169650013358269]\r\n",
      "\"Most dense word #9:\"\t[\"ooooo\", 3.8586371934672128]\r\n",
      "\"Most dense word #10:\"\t[\"lillelu\", 3.7624521072796937]\r\n",
      "\"Most dense word #11:\"\t[\"madarassy\", 3.5769230769230771]\r\n",
      "\"Most dense word #12:\"\t[\"pfeffermann\", 3.5769230769230771]\r\n",
      "\"Most dense word #13:\"\t[\"meteoritical\", 3.5600000000000001]\r\n",
      "\"Most dense word #14:\"\t[\"xxxxxxxx\", 3.5]\r\n",
      "\"Most dense word #15:\"\t[\"beep\", 3.2290388548057258]\r\n",
      "\"Most dense word #16:\"\t[\"latha\", 3.1886792452830188]\r\n",
      "\"Most dense word #17:\"\t[\"iyengar\", 2.9191176470588234]\r\n",
      "\"Most dense word #18:\"\t[\"counterfeiteth\", 2.8250000000000002]\r\n",
      "\"Most dense word #19:\"\t[\"nonmorular\", 2.8198198198198199]\r\n",
      "\"Most dense word #20:\"\t[\"nonsquamous\", 2.8198198198198199]\r\n",
      "\"Least dense word #1:\"\t[\"zymosis\", 1.0]\r\n",
      "\"Least dense word #2:\"\t[\"zymosan\", 1.0]\r\n",
      "\"Least dense word #3:\"\t[\"zymophore\", 1.0]\r\n",
      "\"Least dense word #4:\"\t[\"zymogens\", 1.0]\r\n",
      "\"Least dense word #5:\"\t[\"zymelman\", 1.0]\r\n",
      "\"Least dense word #6:\"\t[\"zylindrischen\", 1.0]\r\n",
      "\"Least dense word #7:\"\t[\"zygosity\", 1.0]\r\n",
      "\"Least dense word #8:\"\t[\"zygomaticotemporal\", 1.0]\r\n",
      "\"Least dense word #9:\"\t[\"zygomaticofacial\", 1.0]\r\n",
      "\"Least dense word #10:\"\t[\"zygmunt\", 1.0]\r\n",
      "\"Least dense word #11:\"\t[\"zydom\", 1.0]\r\n",
      "\"Least dense word #12:\"\t[\"zydeco\", 1.0]\r\n",
      "\"Least dense word #13:\"\t[\"zxcvframeqasfuc\", 1.0]\r\n",
      "\"Least dense word #14:\"\t[\"zx\", 1.0]\r\n",
      "\"Least dense word #15:\"\t[\"zwyn\", 1.0]\r\n",
      "\"Least dense word #16:\"\t[\"zwt\", 1.0]\r\n",
      "\"Least dense word #17:\"\t[\"zwitterionic\", 1.0]\r\n",
      "\"Least dense word #18:\"\t[\"zwischenstaatlicher\", 1.0]\r\n",
      "\"Least dense word #19:\"\t[\"zwirnen\", 1.0]\r\n",
      "\"Least dense word #20:\"\t[\"zwingst\", 1.0]\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170222.174852.077612/output/part-00000 \\\n",
    "> mostLeastDenseWords.txt\n",
    "!cat mostLeastDenseWords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/22 18:33:47 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/mostLeastDenseWords.hyeramoon.20170222.174852.077612' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word density MR stats\n",
    "\n",
    "    Altiscale Hadoop\n",
    "    RUNNING for 2601s  ~= 43 minutes\n",
    "    \n",
    "__Step 1:__ \n",
    "\n",
    "          \n",
    "    Launched map tasks=8   \n",
    "    Launched reduce tasks=1    \n",
    "\n",
    "__Step 2:__  \n",
    "  \n",
    "    Launched map tasks=2   \n",
    "    Launched reduce tasks=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - D. Distribution of 5-gram sizes (character length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting distribution.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile distribution.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "class distribution(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.D\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1nr', # need this order to plot histogram correctly\n",
    "            'mapreduce.job.reduces':'1'\n",
    "        }\n",
    "        return[\n",
    "            MRStep(\n",
    "                jobconf = JOBCONF_STEP,\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer = self.reducer\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        self.increment_counter('group', 'Num_mapper_calls', 1)\n",
    "        # Assuming input is from the outputs in A.Longest 5-gram exercise\n",
    "        ngram, other = line.strip().split(\"\\t\",1)\n",
    "        length = len(str(ngram))\n",
    "        yield length, 1\n",
    "        \n",
    "    def combiner(self, length, counts):\n",
    "        self.increment_counter('group', 'Num_combiners_calls', 1)\n",
    "        yield length, sum(counts)\n",
    "        \n",
    "    def reducer(self, length, counts):\n",
    "        self.increment_counter('group', 'Num_reducer_calls', 1)\n",
    "        yield length, sum(counts)\n",
    "        \n",
    "    \n",
    "    # END STUDENT CODE 5.4.1.D\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    distribution.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x distribution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/distribution.hyeramoon.20170220.192046.696489\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.2:\n",
      "The have been translated as follows\n",
      " mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob8292910842847240510.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6455\n",
      "  Submitted application application_1487024364319_6455\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6455/\n",
      "  Running job: job_1487024364319_6455\n",
      "  Job job_1487024364319_6455 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6455 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/output\n",
      "Counters: 53\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=45\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=65\n",
      "\t\tFILE: Number of bytes written=389032\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1023\n",
      "\t\tHDFS: Number of bytes written=45\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=20769792\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11256320\n",
      "\t\tTotal time spent by all map tasks (ms)=13522\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=40566\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4397\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=21985\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13522\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4397\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3950\n",
      "\t\tCombine input records=10\n",
      "\t\tCombine output records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=107\n",
      "\t\tInput split bytes=460\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=50\n",
      "\t\tMap output materialized bytes=90\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1707347968\n",
      "\t\tReduce input groups=9\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=9\n",
      "\t\tReduce shuffle bytes=90\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=2474115072\n",
      "\t\tVirtual memory (bytes) snapshot=7728947200\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_combiners_calls=10\n",
      "\t\tNum_mapper_calls=10\n",
      "\t\tNum_reducer_calls=9\n"
     ]
    }
   ],
   "source": [
    "!python distribution.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "--no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 19:21 /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users         45 2017-02-20 19:21 /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/output/part-00000 > \\\n",
    "distribution_mini.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/21 03:01:57 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/output' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192046.696489/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9cAAAG0CAYAAAA4iNT0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f8c3b8990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "results_A = []\n",
    "for line in open(\"distribution_mini.txt\").readlines():\n",
    "    line = line.strip()\n",
    "    X,Y = line.split(\"\\t\")\n",
    "    results_A.append([int(X),int(Y)])\n",
    "\n",
    "items = (np.array(results_A)[::-1].T)\n",
    "fig = pl.figure(figsize=(17,7))\n",
    "ax = pl.subplot(111)\n",
    "width=0.8\n",
    "ax.bar(range(len(items[0])), items[1], width=width)\n",
    "ax.set_xticks(np.arange(len(items[0])) + width/2)\n",
    "ax.set_xticklabels(items[0], rotation=90)\n",
    "\n",
    "\n",
    "\n",
    "pl.title(\"Distributions of 5 Gram lengths - small dataset\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/distribution.hyeramoon.20170222.183514.143641\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170222.183514.143641/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.2:\n",
      "The have been translated as follows\n",
      " mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob8019259597801222589.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  Adding a new node: /default-rack/10.251.253.214:50010\n",
      "  Adding a new node: /default-rack/10.251.253.170:50010\n",
      "  Adding a new node: /default-rack/10.251.254.190:50010\n",
      "  Adding a new node: /default-rack/10.251.249.182:50010\n",
      "  Adding a new node: /default-rack/10.251.237.66:50010\n",
      "  number of splits:8\n",
      "  Submitting tokens for job: job_1487024364319_7996\n",
      "  Submitted application application_1487024364319_7996\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7996/\n",
      "  Running job: job_1487024364319_7996\n",
      "  Job job_1487024364319_7996 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7996 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170222.183514.143641/output\n",
      "Counters: 52\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156986620\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=624\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2892\n",
      "\t\tFILE: Number of bytes written=1177238\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156987532\n",
      "\t\tHDFS: Number of bytes written=624\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=27\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=8\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=8\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=5954780160\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8524800\n",
      "\t\tTotal time spent by all map tasks (ms)=3876810\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=11630430\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3330\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16650\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3876810\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3330\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=4028230\n",
      "\t\tCombine input records=58682266\n",
      "\t\tCombine output records=495\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=21715\n",
      "\t\tInput split bytes=912\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=293411210\n",
      "\t\tMap output materialized bytes=4401\n",
      "\t\tMap output records=58682266\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tPhysical memory (bytes) snapshot=6956277760\n",
      "\t\tReduce input groups=80\n",
      "\t\tReduce input records=495\n",
      "\t\tReduce output records=80\n",
      "\t\tReduce shuffle bytes=4401\n",
      "\t\tShuffled Maps =8\n",
      "\t\tSpilled Records=990\n",
      "\t\tTotal committed heap usage (bytes)=14796455936\n",
      "\t\tVirtual memory (bytes) snapshot=20927528960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_combiners_calls=495\n",
      "\t\tNum_mapper_calls=58682266\n",
      "\t\tNum_reducer_calls=80\n",
      "\n",
      "real\t8m55.872s\n",
      "user\t0m27.049s\n",
      "sys\t0m1.290s\n"
     ]
    }
   ],
   "source": [
    "!time python distribution.py -r hadoop hdfs:///tmp/hw5b/gigantor_file.txt --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 19:30 /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192401.813338/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users        624 2017-02-20 19:30 /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170220.192401.813338/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170222.183514.143641/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170222.183514.143641/output/part-00000 > \\\n",
    "distribution.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/22 18:51:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/distribution.hyeramoon.20170222.183514.143641' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution MRJob stats\n",
    "\n",
    "    Altiscale Hadoop  \n",
    "\n",
    "    RUNNING for 536s ~= 9 minutes  \n",
    "    Launched map tasks=8  \n",
    "    Launched reduce tasks=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/MAAAG7CAYAAACPaMWLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAQs/LTauAt8mHZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f8c398dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "results_A = []\n",
    "for line in open(\"distribution.txt\").readlines():\n",
    "    line = line.strip()\n",
    "    X,Y = line.split(\"\\t\")\n",
    "    results_A.append([int(X),int(Y)])\n",
    "\n",
    "items = (np.array(results_A)[::-1].T)\n",
    "fig = pl.figure(figsize=(17,7))\n",
    "ax = pl.subplot(111)\n",
    "width=0.8\n",
    "ax.bar(range(len(items[0])), items[1], width=width)\n",
    "ax.set_xticks(np.arange(len(items[0])) + width/2)\n",
    "ax.set_xticklabels(items[0], rotation=90)\n",
    "\n",
    "\n",
    "\n",
    "pl.title(\"Distributions of 5 Gram lengths\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.5  <a name=\"5.5\"></a> Synonym detection over 2Gig of Data with extra Preprocessing steps (HW5.3 plus some preprocessing)   (Phase 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "For the remainder of this assignment please feel free to eliminate stop words from your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> from nltk.corpus import stopwords\n",
    " stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: A large subset of the Google n-grams dataset as was described above\n",
    "\n",
    "For each HW 5.4 -5.5.1 Please unit test and system test your code with respect \n",
    "to SYSTEMS TEST DATASET and show the results. \n",
    "Please compute the expected answer by hand and show your hand calculations for the \n",
    "SYSTEMS TEST DATASET. Then show the results you get with your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment we will focus on developing methods for detecting synonyms, using the Google 5-grams dataset. At a high level:\n",
    "\n",
    "\n",
    "1. remove stopwords\n",
    "2. get 10,0000 most frequent\n",
    "3. get 1000 (9001-10000) features\n",
    "3. build stripes\n",
    "\n",
    "To accomplish this you must script two main tasks using MRJob:\n",
    "\n",
    "\n",
    "__TASK (1)__ Build stripes for the most frequent 10,000 words using cooccurence information based on\n",
    "the words ranked from 9001,-10,000 as a basis/vocabulary (drop stopword-like terms),\n",
    "and output to a file in your bucket on s3 (bigram analysis, though the words are non-contiguous).\n",
    "\n",
    "\n",
    "__TASK (2)__ Using two (symmetric) comparison methods of your choice \n",
    "(e.g., correlations, distances, similarities), pairwise compare \n",
    "all stripes (vectors), and output to a file in your bucket on s3.\n",
    "\n",
    "#### Design notes for TASK (1)\n",
    "For this task you will be able to modify the pattern we used in HW 3.2\n",
    "(feel free to use the solution as reference). To total the word counts \n",
    "across the 5-grams, output the support from the mappers using the total \n",
    "order inversion pattern:\n",
    "\n",
    "<*word,count>\n",
    "\n",
    "to ensure that the support arrives before the cooccurrences.\n",
    "\n",
    "In addition to ensuring the determination of the total word counts,\n",
    "the mapper must also output co-occurrence counts for the pairs of\n",
    "words inside of each 5-gram. Treat these words as a basket,\n",
    "as we have in HW 3, but count all stripes or pairs in both orders,\n",
    "i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for TASK (2).\n",
    "\n",
    "#### Design notes for _TASK (2)_\n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    "- Jaccard\n",
    "- Cosine similarity\n",
    "- Spearman correlation\n",
    "- Euclidean distance\n",
    "- Taxicab (Manhattan) distance\n",
    "- Shortest path graph distance (a graph, because our data is symmetric!)\n",
    "- Pearson correlation\n",
    "- Kendall correlation\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to\n",
    "parallelize than others, and do not perform more associations than is necessary, \n",
    "since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. \n",
    "\n",
    "Please report the size of the cluster used and the amount of time it takes to run for the index construction task and for the synonym calculation task. How many pairs need to be processed (HINT: use the posting list length to calculate directly)? Report your  Cluster configuration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example MR stats: (report times!)\n",
    "    took ~11 minutes on 5 m3.xlarge nodes\n",
    "    Data-local map tasks=188\n",
    "\tLaunched map tasks=190\n",
    "\tLaunched reduce tasks=15\n",
    "\tOther local map tasks=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE 5.5\n",
    "# ADD OR REMOVE CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: build file with 10,000 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mostFrequentWords10k.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostFrequentWords10k.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class mostFrequentWords10k(MRJob):\n",
    "    \n",
    "    n = 10000\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.job.reduces':'1'  # Note: one reducer suffice since each partition from previous MRJob only\n",
    "                                      # emits n lines\n",
    "        }\n",
    "        return[\n",
    "            MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer_init = self.reducer_init,\n",
    "                reducer = self.reducer,\n",
    "                reducer_final = self.reducer_final\n",
    "            ),\n",
    "            MRStep(\n",
    "                jobconf = JOBCONF_STEP,\n",
    "                reducer_init = self.reducer_top_init,\n",
    "                reducer = self.reducer_top,\n",
    "                reducer_final = self.reducer_top_final\n",
    "            )\n",
    "\n",
    "        ]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "                        'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "                        'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "                        'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "                        'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "                        'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "                        'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "                        'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "                        'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "                        'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "                        'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "                        'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        self.increment_counter('group', 'Num_mapper_calls', 1)\n",
    "        ngram, count, other = line.strip().split('\\t',2)\n",
    "        words = ngram.split(\" \")\n",
    "        count = int(count)\n",
    "        for word in words:\n",
    "            if word.lower() not in self.stopwords:\n",
    "                yield str(word).lower(), count\n",
    "           \n",
    "        \n",
    "    def combiner(self,word, counts):\n",
    "        self.increment_counter('group', 'Num_combiner_calls', 1)\n",
    "        yield word, sum(counts)\n",
    "    \n",
    "    \n",
    "    def reducer_init(self):\n",
    "        self.wordcounts_per_partition = [[\"None\", 0]] * self.n\n",
    "            \n",
    "                \n",
    "    def reducer(self, word, counts):\n",
    "        count = sum(counts)\n",
    "        index = -1\n",
    "        for i in range(self.n):\n",
    "            if count > self.wordcounts_per_partition[i][1]:  # note: number in counts in increasing order\n",
    "                index = i  # find where to insert the wordcount in the count list\n",
    "            else:\n",
    "                break\n",
    "        if index != -1:\n",
    "            self.wordcounts_per_partition.insert(index+1, [word, count])\n",
    "            self.wordcounts_per_partition = self.wordcounts_per_partition[1:self.n+1]  # take the 10 items with largest count out of 11 items\n",
    "\n",
    "        \n",
    "    def reducer_final(self):\n",
    "        self.increment_counter('group', 'Num_reducer_calls', 1)\n",
    "        \n",
    "        for i in range(self.n-1,-1,-1):\n",
    "            yield self.wordcounts_per_partition[i][0], self.wordcounts_per_partition[i][1]  # most frequent words \n",
    "                                                                                            # per partition\n",
    "    \n",
    "        \n",
    "    def reducer_top_init(self):\n",
    "        self.wordcounts_total = [[\"None\", 0]] * self.n\n",
    "    \n",
    "    \n",
    "    def reducer_top(self, word, counts):\n",
    "        count = sum(counts)\n",
    "        index = -1\n",
    "        for i in range(self.n):\n",
    "            if count > self.wordcounts_total[i][1]:  # note: number in counts in increasing order\n",
    "                index = i  # find where to insert the wordcount in the count list\n",
    "            else:\n",
    "                break\n",
    "        if index != -1:\n",
    "            self.wordcounts_total.insert(index+1, [word, count])\n",
    "            self.wordcounts_total = self.wordcounts_total[1:self.n+1]  # take n items with largest count out of n+1 items\n",
    "            \n",
    "            \n",
    "    def reducer_top_final(self):\n",
    "        self.increment_counter('group', 'Num_reducer2_calls', 1)\n",
    "        \n",
    "        for i in range(self.n-1,-1,-1):\n",
    "            yield self.wordcounts_total[i][0], self.wordcounts_total[i][1]  # top most frequent words \n",
    "    \n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    mostFrequentWords10k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x mostFrequentWords10k.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/mostFrequentWords10k.hyeramoon.20170220.215018.097815\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob9056197482831977807.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  Adding a new node: /default-rack/10.251.254.190:50010\n",
      "  Adding a new node: /default-rack/10.251.253.170:50010\n",
      "  Adding a new node: /default-rack/10.251.253.214:50010\n",
      "  Adding a new node: /default-rack/10.251.249.182:50010\n",
      "  Adding a new node: /default-rack/10.251.237.66:50010\n",
      "  number of splits:8\n",
      "  Submitting tokens for job: job_1487024364319_6597\n",
      "  Submitted application application_1487024364319_6597\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6597/\n",
      "  Running job: job_1487024364319_6597\n",
      "  Job job_1487024364319_6597 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6597 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/step-output/0000\n",
      "Counters: 52\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156986620\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=176976\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=24954607\n",
      "\t\tFILE: Number of bytes written=39852627\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156987532\n",
      "\t\tHDFS: Number of bytes written=176976\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=27\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=8\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=8\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8545999872\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=330242560\n",
      "\t\tTotal time spent by all map tasks (ms)=5563802\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16691406\n",
      "\t\tTotal time spent by all reduce tasks (ms)=129001\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=645005\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5563802\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=129001\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=6880740\n",
      "\t\tCombine input records=128240235\n",
      "\t\tCombine output records=1309760\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=18038\n",
      "\t\tInput split bytes=912\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=1627405167\n",
      "\t\tMap output materialized bytes=13730109\n",
      "\t\tMap output records=128240235\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tPhysical memory (bytes) snapshot=6093320192\n",
      "\t\tReduce input groups=269212\n",
      "\t\tReduce input records=1309760\n",
      "\t\tReduce output records=10000\n",
      "\t\tReduce shuffle bytes=13730109\n",
      "\t\tShuffled Maps =8\n",
      "\t\tSpilled Records=3929280\n",
      "\t\tTotal committed heap usage (bytes)=13817610240\n",
      "\t\tVirtual memory (bytes) snapshot=20897206272\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_combiner_calls=1309760\n",
      "\t\tNum_mapper_calls=58682266\n",
      "\t\tNum_reducer_calls=1\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob6253623130592458644.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6605\n",
      "  Submitted application application_1487024364319_6605\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6605/\n",
      "  Running job: job_1487024364319_6605\n",
      "  Job job_1487024364319_6605 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6605 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=219560\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=176976\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=137291\n",
      "\t\tFILE: Number of bytes written=664923\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=219950\n",
      "\t\tHDFS: Number of bytes written=176976\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18307584\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=57431040\n",
      "\t\tTotal time spent by all map tasks (ms)=11919\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=35757\n",
      "\t\tTotal time spent by all reduce tasks (ms)=22434\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=112170\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11919\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=22434\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=16890\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=109\n",
      "\t\tInput split bytes=390\n",
      "\t\tMap input records=10000\n",
      "\t\tMap output bytes=176976\n",
      "\t\tMap output materialized bytes=138966\n",
      "\t\tMap output records=10000\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1901850624\n",
      "\t\tReduce input groups=10000\n",
      "\t\tReduce input records=10000\n",
      "\t\tReduce output records=10000\n",
      "\t\tReduce shuffle bytes=138966\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20000\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7721111552\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tgroup\n",
      "\t\tNum_reducer2_calls=1\n"
     ]
    }
   ],
   "source": [
    "!python mostFrequentWords10k.py -r hadoop hdfs:///tmp/hw5b/gigantor_file.txt --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 22:05 /user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users     176976 2017-02-20 22:05 /user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/output/part-00000 \\\n",
    "> top10k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/21 03:03:46 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/output' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/mostFrequentWords10k.hyeramoon.20170220.215018.097815/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"one\"\t180195771\n",
      "\"would\"\t139313915\n",
      "\"time\"\t126853684\n",
      "\"may\"\t108486904\n",
      "\"part\"\t79528921\n",
      "\"constituting\"\t133165\n",
      "\"foramen\"\t133131\n",
      "\"laboratories\"\t133058\n",
      "\"analyst\"\t133044\n",
      "\"atlas\"\t132983\n"
     ]
    }
   ],
   "source": [
    "!head -5 top10k.txt\n",
    "!tail -5 top10k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildStripes10k.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes10k.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "import itertools\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "class MRbuildStripes10k(MRJob):\n",
    "  \n",
    "    \n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper,\n",
    "                reducer = self.reducer\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.stripes = {}\n",
    "        self.top10k = []\n",
    "        #with open(\"TEST10k.txt\", \"r\") as top10file: # for small dataset test\n",
    "        with open(\"top10k.txt\", \"r\") as top10file:  #for actual dataset\n",
    "            for line in top10file:\n",
    "                line = line.strip()\n",
    "                word, count = line.split('\\t')\n",
    "                word = word.strip(\"\\\"\")\n",
    "                self.top10k.append(word)\n",
    "        #self.basis1k = self.top10k[7:10]  # for for small dataset test\n",
    "        self.basis1k = self.top10k[9001:10000]  #for actual dataset\n",
    "        self.top10k = set(self.top10k)  # to speed up the search of words in this list\n",
    "        self.basis1k = set(self.basis1k)  # to speed up the search of words in this list\n",
    "        \n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip().lower()\n",
    "        ngram, count, other = line.split('\\t',2)\n",
    "        count = int(count)\n",
    "        words = ngram.split(' ')\n",
    "        words = [word for word in words if word in self.top10k]\n",
    "        self.stripes = {}\n",
    "                \n",
    "        for subset in itertools.permutations(sorted(words), 2):  #instead of combinations to keep symmetry\n",
    "            if subset[1] in self.basis1k:\n",
    "                if subset[0] == subset[1]:  # in case two same words in a line\n",
    "                    continue\n",
    "                elif subset[0] not in self.stripes.keys():\n",
    "                    self.stripes[subset[0]] = {}\n",
    "                    self.stripes[subset[0]][subset[1]] = count\n",
    "                elif subset[1] not in self.stripes[subset[0]]:\n",
    "                    self.stripes[subset[0]][subset[1]] = count\n",
    "                else:\n",
    "                    self.stripes[subset[0]][subset[1]] += count\n",
    "\n",
    "        for key in self.stripes.keys():\n",
    "            yield key, self.stripes[key]\n",
    "    \n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        temp_stripes = {}\n",
    "        for value in values:\n",
    "            for word, count in value.items():\n",
    "                temp_stripes[word] = temp_stripes.get(word,0) + count\n",
    "        yield key, temp_stripes\n",
    "  \n",
    "\n",
    "  #END SUDENT CODE531_STRIPES   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRbuildStripes10k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x buildStripes10k.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/buildStripes10k.hyeramoon.20170220.230939.850969\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.230939.850969/files/...\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob2466389826870904997.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  Adding a new node: /default-rack/10.251.253.170:50010\n",
      "  Adding a new node: /default-rack/10.251.253.214:50010\n",
      "  Adding a new node: /default-rack/10.251.254.190:50010\n",
      "  Adding a new node: /default-rack/10.251.237.66:50010\n",
      "  Adding a new node: /default-rack/10.251.249.182:50010\n",
      "  number of splits:8\n",
      "  Submitting tokens for job: job_1487024364319_6668\n",
      "  Submitted application application_1487024364319_6668\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6668/\n",
      "  Running job: job_1487024364319_6668\n",
      "  Job job_1487024364319_6668 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6668 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.230939.850969/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156986620\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=9284147\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=16047034\n",
      "\t\tFILE: Number of bytes written=36989700\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156987532\n",
      "\t\tHDFS: Number of bytes written=9284147\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=27\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=8\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=8\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=825134592\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=390883840\n",
      "\t\tTotal time spent by all map tasks (ms)=537197\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=1611591\n",
      "\t\tTotal time spent by all reduce tasks (ms)=152689\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=763445\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=537197\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=152689\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=652990\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=2633\n",
      "\t\tInput split bytes=912\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=42483621\n",
      "\t\tMap output materialized bytes=19774944\n",
      "\t\tMap output records=1602753\n",
      "\t\tMerged Map outputs=8\n",
      "\t\tPhysical memory (bytes) snapshot=6764707840\n",
      "\t\tReduce input groups=9993\n",
      "\t\tReduce input records=1602753\n",
      "\t\tReduce output records=9993\n",
      "\t\tReduce shuffle bytes=19774944\n",
      "\t\tShuffled Maps =8\n",
      "\t\tSpilled Records=3205506\n",
      "\t\tTotal committed heap usage (bytes)=14374404096\n",
      "\t\tVirtual memory (bytes) snapshot=20960079872\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n"
     ]
    }
   ],
   "source": [
    "!python buildStripes10k.py -r hadoop hdfs:///tmp/hw5b/gigantor_file.txt --file top10k.txt --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 23:13 /user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.230939.850969/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users    9284147 2017-02-20 23:13 /user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.230939.850969/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.230939.850969/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ab\"\t{\"binary\": 76, \"chord\": 1006, \"parallels\": 89, \"subscribed\": 44, \"conveying\": 273, \"residential\": 77, \"consul\": 48, \"amplifier\": 91, \"ce\": 58, \"narratives\": 89, \"terminals\": 141, \"wires\": 51, \"est\": 256, \"qui\": 1445, \"lever\": 77}\r\n",
      "\"abandon\"\t{\"misfortunes\": 46, \"inducing\": 277, \"unconstitutional\": 55, \"pursuits\": 117, \"athenians\": 68, \"dearest\": 110, \"logically\": 46, \"worldly\": 46, \"habitation\": 50, \"illusions\": 200, \"forts\": 53, \"holdings\": 40, \"resolving\": 113, \"commandment\": 62, \"glowing\": 138, \"peru\": 124, \"defenders\": 45, \"francs\": 185, \"renounce\": 46, \"collateral\": 57, \"oblige\": 217, \"warranted\": 89, \"spoil\": 51, \"discouraged\": 74, \"vastly\": 49, \"herds\": 74, \"unwillingness\": 212, \"vietnamese\": 52, \"persuading\": 158, \"honestly\": 70, \"careless\": 181, \"silly\": 74, \"sinner\": 55}\r\n",
      "\"abandoned\"\t{\"alexandria\": 98, \"travellers\": 71, \"humiliation\": 46, \"tents\": 101, \"metaphysical\": 58, \"forts\": 51, \"pursuits\": 56, \"athenians\": 90, \"traitor\": 132, \"enumeration\": 61, \"habitation\": 61, \"anarchy\": 41, \"restless\": 63, \"similarly\": 48, \"damp\": 75, \"occupants\": 83, \"nova\": 42, \"hue\": 64, \"mate\": 108, \"defenders\": 129, \"judicious\": 56, \"sinners\": 52, \"officially\": 64, \"fide\": 45, \"lutheran\": 42, \"metropolis\": 66, \"relic\": 46, \"housed\": 63, \"cart\": 58, \"questioning\": 45, \"domains\": 41, \"licence\": 59, \"ordinances\": 42, \"cunning\": 40, \"forfeited\": 47, \"arduous\": 51, \"detroit\": 43, \"exhaustion\": 46, \"natures\": 41, \"barren\": 46, \"conqueror\": 139, \"intolerable\": 79, \"silently\": 45, \"sinner\": 88}\r\n",
      "\"abandonment\"\t{\"wept\": 47, \"sherman\": 42, \"forts\": 145, \"hasty\": 76, \"wholesale\": 146, \"conditional\": 92, \"tacit\": 171, \"masculine\": 102}\r\n",
      "\"abbey\"\t{\"warrior\": 182, \"milton\": 81, \"crowns\": 64, \"illuminated\": 45, \"solemnity\": 124, \"roofs\": 206, \"lodging\": 54, \"precincts\": 72, \"antiquities\": 173, \"nova\": 56, \"twin\": 65, \"canons\": 190, \"inmates\": 121, \"secrecy\": 61, \"domains\": 125, \"conqueror\": 49, \"sensibility\": 168, \"vault\": 129, \"coronation\": 276, \"dame\": 195}\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.230939.850969/output/part-00000 > \\\n",
    "stripes.txt\n",
    "!head -5 stripes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing invertedIndex10k.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex10k.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np commented since not supported by Hadoop Python version\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.protocol import JSONProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRinvertedIndex10k(MRJob):\n",
    "    INPUT_PROTOCOL = JSONProtocol\n",
    "\n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(\n",
    "                mapper=self.mapper,\n",
    "                reducer=self.reducer\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def mapper(self, key_word, stripes):\n",
    "        words = stripes.keys()\n",
    "        _len = len(words)\n",
    "        for word in words:\n",
    "        # Store the length of the document to use with JACCARD (|A| + |B|)\n",
    "            yield word, (key_word, _len)\n",
    "\n",
    "        \n",
    "    def reducer(self, word, values):        \n",
    "        d = collections.defaultdict(list)\n",
    "        for value in values:\n",
    "            d[word].append(value)\n",
    "        yield word, d[word]\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRinvertedIndex10k.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x invertedIndex10k.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/invertedIndex10k.hyeramoon.20170220.234727.351327\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/invertedIndex10k.hyeramoon.20170220.234727.351327/files/...\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob22980440023588590.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1487024364319_6697\n",
      "  Submitted application application_1487024364319_6697\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_6697/\n",
      "  Running job: job_1487024364319_6697\n",
      "  Job job_1487024364319_6697 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_6697 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/invertedIndex10k.hyeramoon.20170220.234727.351327/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=9360666\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=9467513\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6590634\n",
      "\t\tFILE: Number of bytes written=13389830\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=9361024\n",
      "\t\tHDFS: Number of bytes written=9467513\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=39911424\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=109798400\n",
      "\t\tTotal time spent by all map tasks (ms)=25984\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=77952\n",
      "\t\tTotal time spent by all reduce tasks (ms)=42890\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=214450\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=25984\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=42890\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=59660\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=222\n",
      "\t\tInput split bytes=358\n",
      "\t\tMap input records=9993\n",
      "\t\tMap output bytes=14999071\n",
      "\t\tMap output materialized bytes=6411099\n",
      "\t\tMap output records=554402\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1878401024\n",
      "\t\tReduce input groups=999\n",
      "\t\tReduce input records=554402\n",
      "\t\tReduce output records=999\n",
      "\t\tReduce shuffle bytes=6411099\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1108804\n",
      "\t\tTotal committed heap usage (bytes)=5200936960\n",
      "\t\tVirtual memory (bytes) snapshot=7751421952\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex10k.py -r hadoop \\\n",
    "hdfs:///user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.230939.850969/output/part-00000 \\\n",
    "    --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/21 03:08:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/buildStripes10k.hyeramoon.20170220.224220.435157/output' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "# buildStripe outputs not needed anymore since used in inverted index\n",
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/buildStripes10k*/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-20 23:48 /user/hyeramoon/tmp/mrjob/invertedIndex10k.hyeramoon.20170220.234727.351327/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users    9467513 2017-02-20 23:48 /user/hyeramoon/tmp/mrjob/invertedIndex10k.hyeramoon.20170220.234727.351327/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/invertedIndex10k.hyeramoon.20170220.234727.351327/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/invertedIndex10k.hyeramoon.20170220.234727.351327/output/part-00000 > \\\n",
    "invertedindex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity10k.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity10k.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np  commented since not supported by Hadoop Python version\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRsimilarity10k(MRJob):\n",
    "  \n",
    "    MRJob.SORT_VALUES\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "            'mapreduce.job.maps': 100,\n",
    "            'mapreduce.job.reduces' : 50     \n",
    "        }\n",
    "        JOBCONF_STEP2 = { \n",
    "                # Must use -r hadoop mode for this sorting to work #\n",
    "                'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "                'mapreduce.job.reduces' : 1\n",
    "        }\n",
    "\n",
    "        return [\n",
    "            MRStep(jobconf=JOBCONF_STEP1,\n",
    "                   mapper = self.mapper_pair_sim,\n",
    "                   reducer = self.reducer_pair_sim\n",
    "                  ),\n",
    "            MRStep(jobconf=JOBCONF_STEP2,\n",
    "                  mapper=None,\n",
    "                  reducer=self.reducer_sort)\n",
    "        ]\n",
    "        \n",
    "    def mapper_pair_sim(self, _, line):\n",
    "        line = line.strip()\n",
    "        index,posting = line.split(\"\\t\")\n",
    "        posting = json.loads(posting)\n",
    "        \n",
    "        X = map(lambda x: x[0]+\".\"+str(x[1]) , posting)\n",
    "        \n",
    "        # taking advantage of symetry, output only (a,b), but not (b,a)\n",
    "        for subset in itertools.combinations(sorted(set(X)), 2):\n",
    "            yield subset[0]+\".\"+subset[1], 1\n",
    "        \n",
    "            \n",
    "    def reducer_pair_sim(self,key,values):\n",
    "        word1, word1_len, word2, word2_len = key.split(\".\")\n",
    "        t =sum(values)\n",
    "       \n",
    "        cosine = (1.0/(float(word1_len)**0.5) * 1.0/(float(word2_len)**0.5))*t\n",
    "        jaccard = t / ( int(word1_len) + int(word2_len) - t )\n",
    "        overlap = t / min(int(word1_len), int(word2_len))\n",
    "        dice = 2 * t / ( int(word1_len) + int(word2_len))\n",
    "        avg = (jaccard + cosine + overlap + dice) / 4\n",
    "        #avg = (jaccard + cosine) / 2\n",
    "        \n",
    "        # rounding to 6 decimals\n",
    "        #avg = round(avg, 6)\n",
    "        #cosine = round(cosine, 6)\n",
    "        #jaccard = round(jaccard, 6)\n",
    "        #overlap = round(overlap, 6)\n",
    "        #dice = round(dice, 6)\n",
    "        \n",
    "        yield cosine, (word1+\" - \"+word2, jaccard, overlap, dice, avg)\n",
    "    \n",
    "    \n",
    "    def reducer_sort(self,key,values):\n",
    "        for value in values:\n",
    "            yield key, value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRsimilarity10k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "drwxr-xr-x   - hyeramoon users          0 2017-02-21 17:05 /user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170221.153348.042047\r\n",
      "drwxr-xr-x   - hyeramoon users          0 2017-02-21 22:03 /user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170221.172913.560367\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/02/21 15:32:51 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170221.043818.424550' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n",
      "17/02/21 15:32:52 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170221.050131.587630' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n",
      "17/02/21 15:32:52 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170221.052601.929587' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n",
      "17/02/21 15:32:52 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170221.052625.807982' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/hyeramoon/.Trash/Current\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/hyeramoon/tmp/mrjob/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x similarity10k.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar\n",
      "Creating temp directory /tmp/similarity10k.hyeramoon.20170222.015519.504577\n",
      "Copying local files to hdfs:///user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170222.015519.504577/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob2730643151149131944.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:100\n",
      "  Submitting tokens for job: job_1487024364319_7421\n",
      "  Submitted application application_1487024364319_7421\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7421/\n",
      "  Running job: job_1487024364319_7421\n",
      "  Job job_1487024364319_7421 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 1%\n",
      "   map 100% reduce 4%\n",
      "   map 100% reduce 7%\n",
      "   map 100% reduce 9%\n",
      "   map 100% reduce 12%\n",
      "   map 100% reduce 16%\n",
      "   map 100% reduce 19%\n",
      "   map 100% reduce 21%\n",
      "   map 100% reduce 22%\n",
      "   map 100% reduce 26%\n",
      "   map 100% reduce 27%\n",
      "   map 100% reduce 31%\n",
      "   map 100% reduce 34%\n",
      "   map 100% reduce 38%\n",
      "   map 100% reduce 40%\n",
      "   map 100% reduce 44%\n",
      "   map 100% reduce 48%\n",
      "   map 100% reduce 50%\n",
      "   map 100% reduce 55%\n",
      "   map 100% reduce 57%\n",
      "   map 100% reduce 59%\n",
      "   map 100% reduce 60%\n",
      "   map 100% reduce 64%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7421 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170222.015519.504577/step-output/0000\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=13045399\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3669467414\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=606816993\n",
      "\t\tFILE: Number of bytes written=2477708962\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=13063799\n",
      "\t\tHDFS: Number of bytes written=3669467414\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=450\n",
      "\t\tHDFS: Number of write operations=100\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=1\n",
      "\t\tLaunched map tasks=100\n",
      "\t\tLaunched reduce tasks=50\n",
      "\t\tRack-local map tasks=99\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=13944685056\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=26064414720\n",
      "\t\tTotal time spent by all map tasks (ms)=9078571\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=27235713\n",
      "\t\tTotal time spent by all reduce tasks (ms)=10181412\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=50907060\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=9078571\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=10181412\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=11792330\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=47181\n",
      "\t\tInput split bytes=18400\n",
      "\t\tMap input records=999\n",
      "\t\tMap output bytes=4292324614\n",
      "\t\tMap output materialized bytes=1851374889\n",
      "\t\tMap output records=164409464\n",
      "\t\tMerged Map outputs=5000\n",
      "\t\tPhysical memory (bytes) snapshot=105037357056\n",
      "\t\tReduce input groups=28801666\n",
      "\t\tReduce input records=164409464\n",
      "\t\tReduce output records=28801666\n",
      "\t\tReduce shuffle bytes=1851374889\n",
      "\t\tShuffled Maps =5000\n",
      "\t\tSpilled Records=328818928\n",
      "\t\tTotal committed heap usage (bytes)=259364749312\n",
      "\t\tVirtual memory (bytes) snapshot=387088633856\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob2303743003873574582.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 50\n",
      "  number of splits:50\n",
      "  Submitting tokens for job: job_1487024364319_7429\n",
      "  Submitted application application_1487024364319_7429\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1487024364319_7429/\n",
      "  Running job: job_1487024364319_7429\n",
      "  Job job_1487024364319_7429 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 17%\n",
      "   map 100% reduce 24%\n",
      "   map 100% reduce 27%\n",
      "   map 100% reduce 33%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1487024364319_7429 completed successfully\n",
      "  Output directory: hdfs:///user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170222.015519.504577/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3669467414\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3669467414\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=811679827\n",
      "\t\tFILE: Number of bytes written=1972530234\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3669476814\n",
      "\t\tHDFS: Number of bytes written=3669467414\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=153\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=13\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=51\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=38\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=2058577920\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=19827607040\n",
      "\t\tTotal time spent by all map tasks (ms)=1340220\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4020660\n",
      "\t\tTotal time spent by all reduce tasks (ms)=7745159\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=38725795\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=1340220\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=7745159\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=5567500\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=82722\n",
      "\t\tInput split bytes=9400\n",
      "\t\tMap input records=28801666\n",
      "\t\tMap output bytes=3669467414\n",
      "\t\tMap output materialized bytes=1154260887\n",
      "\t\tMap output records=28801666\n",
      "\t\tMerged Map outputs=50\n",
      "\t\tPhysical memory (bytes) snapshot=43456233472\n",
      "\t\tReduce input groups=772239\n",
      "\t\tReduce input records=28801666\n",
      "\t\tReduce output records=28801666\n",
      "\t\tReduce shuffle bytes=1154260887\n",
      "\t\tShuffled Maps =50\n",
      "\t\tSpilled Records=57603332\n",
      "\t\tTotal committed heap usage (bytes)=48402792448\n",
      "\t\tVirtual memory (bytes) snapshot=113380220928\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n"
     ]
    }
   ],
   "source": [
    "#trying 4 measures run\n",
    "!python similarity10k.py -r hadoop invertedindex.txt --no-output --cleanup NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 hyeramoon users          0 2017-02-22 04:12 /user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170222.015519.504577/output/_SUCCESS\r\n",
      "-rw-r--r--   3 hyeramoon users 3669467414 2017-02-22 04:12 /user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170222.015519.504577/output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170222.015519.504577/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/hyeramoon/tmp/mrjob/similarity10k.hyeramoon.20170222.015519.504577/output/part-00000 > \\\n",
    "similarity10k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95062310152124585\t[\"may - one\", 0.90533736153071498, 0.97505422993492408, 0.95031712473572938, 0.94533295443065357]\r\n",
      "0.94337186406186457\t[\"one - time\", 0.8913705583756345, 0.98320268756998885, 0.94256575415995703, 0.94012771604186129]\r\n",
      "0.93201683578479955\t[\"one - well\", 0.87109768378650554, 0.97409909909909909, 0.93110871905274484, 0.92708058443078722]\r\n",
      "0.92060442486666916\t[\"may - well\", 0.85261003070624364, 0.93806306306306309, 0.92044198895027629, 0.90792987689656302]\r\n",
      "0.91567278999093071\t[\"first - one\", 0.84077079107505071, 0.9810650887573964, 0.91349862258953163, 0.91275182310322744]\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 similarity10k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head -1000 similarity10k.txt > similarity10ksmall.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "sortedSims = []\n",
    "with open('similarity10ksmall.txt', 'r') as simfile:\n",
    "    for line in simfile:\n",
    "        key, stripe = line.strip().split('\\t',1)\n",
    "        stripe =json.loads(stripe)\n",
    "        sortedSims.append([stripe[0], key, stripe[1], stripe[2], stripe[3], stripe[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tail -1000 similarity10k.txt > similarity10ksmall_bottom.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "sortedSimsbottom = []\n",
    "with open('similarity10ksmall_bottom.txt', 'r') as simfile:\n",
    "    for line in simfile:\n",
    "        key, stripe = line.strip().split('\\t',1)\n",
    "        stripe =json.loads(stripe)\n",
    "        sortedSims.append([stripe[0], key, stripe[1], stripe[2], stripe[3], stripe[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT CODE 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "                     may - one |       0.950623 |       0.905337 |       0.975054 |       0.950317 |       0.945333\n",
      "                    one - time |       0.943372 |       0.891371 |       0.983203 |       0.942566 |       0.940128\n",
      "                    one - well |       0.932017 |       0.871098 |       0.974099 |       0.931109 |       0.927081\n",
      "                    may - well |       0.920604 |       0.852610 |       0.938063 |       0.920442 |       0.907930\n",
      "                   first - one |       0.915673 |       0.840771 |       0.981065 |       0.913499 |       0.912752\n",
      "                   one - would |       0.915633 |       0.840447 |       0.983353 |       0.913308 |       0.913185\n",
      "                    may - time |       0.908105 |       0.831483 |       0.922732 |       0.907989 |       0.892577\n",
      "                    one - part |       0.905584 |       0.823232 |       0.976048 |       0.903047 |       0.901978\n",
      "                  time - would |       0.896597 |       0.811912 |       0.923900 |       0.896194 |       0.882151\n",
      "                   may - would |       0.896011 |       0.810062 |       0.938169 |       0.895065 |       0.884827\n",
      "                    made - one |       0.893480 |       0.801418 |       0.978960 |       0.889764 |       0.890906\n",
      "                   great - one |       0.891703 |       0.797970 |       0.981273 |       0.887634 |       0.889645\n",
      "                  first - time |       0.889868 |       0.801036 |       0.914793 |       0.889528 |       0.873806\n",
      "                    one - upon |       0.889434 |       0.794326 |       0.978777 |       0.885375 |       0.886978\n",
      "                   time - well |       0.889391 |       0.800809 |       0.891892 |       0.889388 |       0.867870\n",
      "                   first - may |       0.883692 |       0.790274 |       0.923077 |       0.882852 |       0.869974\n",
      "                    may - part |       0.878710 |       0.781947 |       0.923353 |       0.877632 |       0.865411\n",
      "                  great - time |       0.876145 |       0.777545 |       0.925094 |       0.874852 |       0.863409\n",
      "                    must - one |       0.875397 |       0.769777 |       0.979355 |       0.869914 |       0.873611\n",
      "                   part - well |       0.874471 |       0.776289 |       0.901796 |       0.874057 |       0.856653\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "           arrival - essential |       0.008122 |       0.004032 |       0.009434 |       0.008032 |       0.007405\n",
      "             desert - function |       0.008106 |       0.003096 |       0.017544 |       0.006173 |       0.008730\n",
      "           fundamental - stood |       0.008105 |       0.003846 |       0.011364 |       0.007663 |       0.007744\n",
      "              patients - plain |       0.008103 |       0.003953 |       0.010309 |       0.007874 |       0.007560\n",
      "                changes - fort |       0.008097 |       0.003257 |       0.016129 |       0.006494 |       0.008494\n",
      "                  layer - wife |       0.008066 |       0.003759 |       0.011905 |       0.007491 |       0.007805\n",
      "                got - multiple |       0.008056 |       0.003378 |       0.014925 |       0.006734 |       0.008273\n",
      "               five - sympathy |       0.008049 |       0.003401 |       0.014706 |       0.006780 |       0.008234\n",
      "           love - proportional |       0.008019 |       0.002933 |       0.018519 |       0.005848 |       0.008829\n",
      "            got - implications |       0.007996 |       0.003367 |       0.014706 |       0.006711 |       0.008195\n",
      "           population - window |       0.007970 |       0.003891 |       0.010101 |       0.007752 |       0.007429\n",
      "          implications - round |       0.007928 |       0.003322 |       0.014706 |       0.006623 |       0.008145\n",
      "               came - proteins |       0.007916 |       0.002041 |       0.028571 |       0.004073 |       0.010650\n",
      "                factors - hear |       0.007852 |       0.003876 |       0.009434 |       0.007722 |       0.007221\n",
      "                 let - therapy |       0.007658 |       0.002976 |       0.016129 |       0.005935 |       0.008175\n",
      "                  came - tumor |       0.007499 |       0.002024 |       0.025641 |       0.004040 |       0.009801\n",
      "                  ever - tumor |       0.007466 |       0.002008 |       0.025641 |       0.004008 |       0.009781\n",
      "                cardiac - took |       0.007400 |       0.002262 |       0.021739 |       0.004515 |       0.008979\n",
      "               relation - snow |       0.006767 |       0.002625 |       0.014286 |       0.005236 |       0.007228\n",
      "                region - write |       0.006661 |       0.003247 |       0.008475 |       0.006472 |       0.006214\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
    "(From the entire data set)\n",
    "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "                   cons - pros |       0.894427 |       0.800000 |       1.000000 |       0.888889 |       0.895829\n",
    "            forties - twenties |       0.816497 |       0.666667 |       1.000000 |       0.800000 |       0.820791\n",
    "                    own - time |       0.809510 |       0.670563 |       0.921168 |       0.802799 |       0.801010\n",
    "                 little - time |       0.784197 |       0.630621 |       0.926101 |       0.773473 |       0.778598\n",
    "                  found - time |       0.783434 |       0.636364 |       0.883788 |       0.777778 |       0.770341\n",
    "                 nova - scotia |       0.774597 |       0.600000 |       1.000000 |       0.750000 |       0.781149\n",
    "                   hong - kong |       0.769800 |       0.615385 |       0.888889 |       0.761905 |       0.758995\n",
    "                   life - time |       0.769666 |       0.608789 |       0.925081 |       0.756829 |       0.765091\n",
    "                  time - world |       0.755476 |       0.585049 |       0.937500 |       0.738209 |       0.754058\n",
    "                  means - time |       0.752181 |       0.587117 |       0.902597 |       0.739854 |       0.745437\n",
    "                   form - time |       0.749943 |       0.588418 |       0.876733 |       0.740885 |       0.738995\n",
    "       infarction - myocardial |       0.748331 |       0.560000 |       1.000000 |       0.717949 |       0.756570\n",
    "                 people - time |       0.745788 |       0.573577 |       0.923875 |       0.729010 |       0.743063\n",
    "                 angeles - los |       0.745499 |       0.586207 |       0.850000 |       0.739130 |       0.730209\n",
    "                  little - own |       0.739343 |       0.585834 |       0.767296 |       0.738834 |       0.707827\n",
    "                    life - own |       0.737053 |       0.582217 |       0.778502 |       0.735951 |       0.708430\n",
    "          anterior - posterior |       0.733388 |       0.576471 |       0.790323 |       0.731343 |       0.707881\n",
    "                  power - time |       0.719611 |       0.533623 |       0.933586 |       0.695898 |       0.720680\n",
    "              dearly - install |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
    "                   found - own |       0.704802 |       0.544134 |       0.710949 |       0.704776 |       0.666165\n",
    "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "           arrival - essential |       0.008258 |       0.004098 |       0.009615 |       0.008163 |       0.007534\n",
    "         governments - surface |       0.008251 |       0.003534 |       0.014706 |       0.007042 |       0.008383\n",
    "                king - lesions |       0.008178 |       0.003106 |       0.017857 |       0.006192 |       0.008833\n",
    "              clinical - stood |       0.008178 |       0.003831 |       0.011905 |       0.007634 |       0.007887\n",
    "               till - validity |       0.008172 |       0.003367 |       0.015625 |       0.006711 |       0.008469\n",
    "            evidence - started |       0.008159 |       0.003802 |       0.012048 |       0.007576 |       0.007896\n",
    "               forces - record |       0.008152 |       0.003876 |       0.011364 |       0.007722 |       0.007778\n",
    "               primary - stone |       0.008146 |       0.004065 |       0.009091 |       0.008097 |       0.007350\n",
    "             beneath - federal |       0.008134 |       0.004082 |       0.008403 |       0.008130 |       0.007187\n",
    "                factors - rose |       0.008113 |       0.004032 |       0.009346 |       0.008032 |       0.007381\n",
    "           evening - functions |       0.008069 |       0.004049 |       0.008333 |       0.008065 |       0.007129\n",
    "                   bone - told |       0.008061 |       0.003704 |       0.012346 |       0.007380 |       0.007873\n",
    "             building - occurs |       0.008002 |       0.003891 |       0.010309 |       0.007752 |       0.007489\n",
    "                 company - fig |       0.007913 |       0.003257 |       0.015152 |       0.006494 |       0.008204\n",
    "               chronic - north |       0.007803 |       0.003268 |       0.014493 |       0.006515 |       0.008020\n",
    "             evaluation - king |       0.007650 |       0.003030 |       0.015625 |       0.006042 |       0.008087\n",
    "             resulting - stood |       0.007650 |       0.003663 |       0.010417 |       0.007299 |       0.007257\n",
    "                 agent - round |       0.007515 |       0.003289 |       0.012821 |       0.006557 |       0.007546\n",
    "         afterwards - analysis |       0.007387 |       0.003521 |       0.010204 |       0.007018 |       0.007032\n",
    "            posterior - spirit |       0.007156 |       0.002660 |       0.016129 |       0.005305 |       0.007812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.6  <a name=\"5.6\"></a> Evaluation of synonyms that your discovered\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "\n",
    "In this part of the assignment you will evaluate the success of you synonym detector (developed in response to HW5.4).\n",
    "Take the top 1,000 closest/most similar/correlative pairs of words as determined by your measure in HW5.4, and use the synonyms function in the accompanying python code:\n",
    "\n",
    "nltk_synonyms.py\n",
    "\n",
    "Note: This will require installing the python nltk package:\n",
    "\n",
    "http://www.nltk.org/install.html\n",
    "\n",
    "and downloading its data with nltk.download().\n",
    "\n",
    "For each (word1,word2) pair, check to see if word1 is in the list, \n",
    "synonyms(word2), and vice-versa. If one of the two is a synonym of the other, \n",
    "then consider this pair a 'hit', and then report the precision, recall, and F1 measure  of \n",
    "your detector across your 1,000 best guesses. Report the macro averages of these measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate performance measures:\n",
    "$$Precision (P) = \\frac{TP}{TP + FP} $$  \n",
    "$$Recall (R) = \\frac{TP}{TP + FN} $$  \n",
    "$$F1 = \\frac{2 * ( precision * recall )}{precision + recall}$$\n",
    "\n",
    "\n",
    "We calculate Precision by counting the number of hits and dividing by the number of occurances in our top1000 (opportunities)   \n",
    "We calculate Recall by counting the number of hits, and dividing by the number of synonyms in wordnet (syns)\n",
    "\n",
    "\n",
    "Other diagnostic measures not implemented here:  https://en.wikipedia.org/wiki/F1_score#Diagnostic_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Number of Hits: 9 out of top 1000\n",
      "Number of words without synonyms: 237\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Precision\t0.00439994397663\n",
      "Recall\t\t0.0195671602481\n",
      "F1\t\t0.00494592473319\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Words without synonyms:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] could\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] hong\n",
      "[] kong\n",
      "[] could\n",
      "[] could\n",
      "[] could\n",
      "[] without\n",
      "[] could\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] without\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] without\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] without\n",
      "[] could\n",
      "[] could\n",
      "[] would\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] without\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] angeles\n",
      "[] los\n",
      "[] upon\n",
      "[] upon\n",
      "[] upon\n",
      "[] upon\n",
      "[] without\n",
      "[] upon\n",
      "[] without\n",
      "[] would\n",
      "[] upon\n",
      "[] upon\n",
      "[] without\n",
      "[] without\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] could\n",
      "[] upon\n",
      "[] francisco\n",
      "[] san\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] could\n",
      "[] without\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] could\n",
      "[] could\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] without\n",
      "[] would\n",
      "[] shall\n",
      "[] would\n",
      "[] without\n",
      "[] could\n",
      "[] would\n",
      "[] shall\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] would\n",
      "[] shall\n",
      "[] upon\n",
      "[] shall\n",
      "[] per\n",
      "[] would\n",
      "[] would\n",
      "[] without\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] without\n",
      "[] shall\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] without\n",
      "[] could\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] without\n",
      "[] without\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] among\n",
      "[] could\n",
      "[] could\n",
      "[] shall\n",
      "[] would\n",
      "[] without\n",
      "[] upon\n",
      "[] would\n",
      "[] shall\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] without\n",
      "[] without\n",
      "[] upon\n",
      "[] without\n",
      "[] without\n",
      "[] shall\n",
      "[] shall\n",
      "[] upon\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] shall\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] upon\n",
      "[] shall\n",
      "[] shall\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] without\n",
      "[] could\n",
      "[] shall\n",
      "[] could\n",
      "[] could\n",
      "[] among\n",
      "[] would\n",
      "[] upon\n",
      "[] without\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] among\n",
      "[] would\n",
      "[] among\n",
      "[] upon\n",
      "[] upon\n",
      "[] upon\n",
      "[] upon\n",
      "[] shall\n",
      "[] upon\n",
      "[] without\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] among\n",
      "[] without\n",
      "[] would\n",
      "[] could\n",
      "[] among\n",
      "[] without\n",
      "[] upon\n",
      "[] among\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] without\n",
      "[] shall\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] could\n",
      "[] would\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] would\n",
      "[] shall\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n"
     ]
    }
   ],
   "source": [
    "''' Performance measures '''\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "hits = []\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "TOTAL = 0\n",
    "flag = False # so we don't double count, but at the same time don't miss hits\n",
    "\n",
    "top1000sims = []\n",
    "with open(\"similarity10ksmall.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        #avg,lisst = line.split(\"\\t\")\n",
    "        cosine,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        #lisst.append(avg)\n",
    "        lisst.append(cosine)\n",
    "        top1000sims.append(lisst)\n",
    "    \n",
    "\n",
    "measures = {}\n",
    "not_in_wordnet = []\n",
    "\n",
    "for line in top1000sims:\n",
    "    TOTAL += 1\n",
    "\n",
    "    pair = line[0]\n",
    "    words = pair.split(\" - \")\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in measures:\n",
    "            measures[word] = {\"syns\":0,\"opps\": 0,\"hits\":0}\n",
    "        measures[word][\"opps\"] += 1 \n",
    "    \n",
    "    syns0 = synonyms(words[0])\n",
    "    measures[words[1]][\"syns\"] = len(syns0)\n",
    "    if len(syns0) == 0:\n",
    "        not_in_wordnet.append(words[0])\n",
    "        \n",
    "    if words[1] in syns0:\n",
    "        TP += 1\n",
    "        hits.append(line)\n",
    "        flag = True\n",
    "        measures[words[1]][\"hits\"] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    syns1 = synonyms(words[1]) \n",
    "    measures[words[0]][\"syns\"] = len(syns1)\n",
    "    if len(syns1) == 0:\n",
    "        not_in_wordnet.append(words[1])\n",
    "\n",
    "    if words[0] in syns1:\n",
    "        if flag == False:\n",
    "            TP += 1\n",
    "            hits.append(line)\n",
    "            measures[words[0]][\"hits\"] += 1\n",
    "            \n",
    "    flag = False    \n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for key in measures:\n",
    "    p,r,f = 0,0,0\n",
    "    if measures[key][\"hits\"] > 0 and measures[key][\"syns\"] > 0:\n",
    "        p = measures[key][\"hits\"]/measures[key][\"opps\"]\n",
    "        r = measures[key][\"hits\"]/measures[key][\"syns\"]\n",
    "        f = 2 * (p*r)/(p+r)\n",
    "    \n",
    "    # For calculating measures, only take into account words that have synonyms in wordnet\n",
    "    if measures[key][\"syns\"] > 0:\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f)\n",
    "\n",
    "    \n",
    "# Take the mean of each measure    \n",
    "print \"—\"*110    \n",
    "print \"Number of Hits:\",TP, \"out of top\",TOTAL\n",
    "print \"Number of words without synonyms:\",len(not_in_wordnet)\n",
    "print \"—\"*110 \n",
    "print \"Precision\\t\", np.mean(precision)\n",
    "print \"Recall\\t\\t\", np.mean(recall)\n",
    "print \"F1\\t\\t\", np.mean(f1)\n",
    "print \"—\"*110  \n",
    "\n",
    "print \"Words without synonyms:\"\n",
    "print \"-\"*100\n",
    "\n",
    "for word in not_in_wordnet:\n",
    "    print synonyms(word),word\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Number of Hits: 31 out of top 1000\n",
    "Number of words without synonyms: 67\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Precision\t0.0280214404967\n",
    "Recall\t\t0.0178598869579\n",
    "F1\t\t0.013965517619\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Words without synonyms:\n",
    "----------------------------------------------------------------------------------------------------\n",
    "[] scotia\n",
    "[] hong\n",
    "[] kong\n",
    "[] angeles\n",
    "[] los\n",
    "[] nor\n",
    "[] themselves\n",
    "[] \n",
    "......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "511px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
