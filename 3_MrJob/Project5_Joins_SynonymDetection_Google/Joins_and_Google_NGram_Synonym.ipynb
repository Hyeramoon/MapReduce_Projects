{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "\n",
    "\n",
    "## Project 5\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  Hyera Moon   \n",
    "__Week:__   5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"TOC\"></a> \n",
    "\n",
    "1.  [HW Intructions](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW Problems](#3)   \n",
    "1.  [HW Introduction](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW  Problems](#3)   \n",
    "    5.0.  [HW5.0](#5.0)   \n",
    "    5.1.  [HW5.1](#5.1)   \n",
    "    5.2.  [HW5.2](#5.2)   \n",
    "    5.3.  [HW5.3](#5.3)    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# 1 Instructions\n",
    "[Back to Table of Contents](#TOC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "<a name=\"2\">\n",
    "# 2 Useful References\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "* See async and live lectures for this week\n",
    "\n",
    "<a name=\"3\">\n",
    "# HW Problems\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.0  data warehouse; star schema<a name=\"5.0\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "- What is a data warehouse? What is a Star schema? When is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A data warehouse is a central repository of integrated data from a wide range of sources within a company/enterprise. It stores current and historical data and forms a foundation for business intelligence (e.g. create analytical reports) and data science. Typically it stores relational data but increasingly semi-structured data and unstructured data are also being stored in the data warehouse.\n",
    "\n",
    "In data warehousing, a Star schema is a simple style of data mart schema: it organizes the data into facts and dimensions and optimizes querying of large datsets. The star schema consists of one or more fact tables referencing any number of dimensions table. In fact, the fact table holds foreign keys which are the primary key of each associated dimension table. Thus, each fact is surrounded with its associated dimensions and this results in a star shape looking diagram.\n",
    "Also the fact table contains one numeric measure thus typically, there will be one fact table and star schema for each measure table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.1 Databases: 3NF; denormalized <a name=\"5.1\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "- In the database world What is 3NF? Does machine learning use data in 3NF? If so why? \n",
    "- In what form does ML consume data?\n",
    "- Why would one use log files that are denormalized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3NF stands for third normal form and it is the third step of a database normalization process designed to reduce the duplication of data. It is designed to improve database processing while minimizing storage costs and thus, it is used for OLTP since its applications are characterized by a high volume of small transactions (large storage needed) in real time (fast processing needed).\n",
    "\n",
    "Machine learning does not use data in 3NF but uses denormalized data instead. Unlike normalized data, denormalized data is typically used for OLAP and data science to get the full picture (e.g. extract historical data that has accumulated over a long period of time). In a normalized model, the related data are stored in separate tables to remove any redundant data and to group those related data will require a join operation. In constrast, the denormalization process add these redundant data where it will help the most via adding extra attributes or new tables. In other words, it will try to improve the read performance of a database by adding redundant copies of data or by grouping data. Machine learning which needs to carry out large numbers of read operations, needs the joined data, that is, the denormalized data.\n",
    "\n",
    "We would use log files that are denormalized when we need to maintain history of changes in the log files, for example in OLAP. This can be done by denormalization process by adding a table containing the history of these changes. This will help to query the log files more easily and faster than with normalized files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.2  Memory-backed map-side<a name=\"5.2\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Using MRJob, implement a hashside join (memory-backed map-side) for left, right and inner joins. Use the following tables for this HW and join based on the country code (third column of the transactions table and the second column of the Countries table:\n",
    "\n",
    "<PRE>\n",
    "transactions.dat\n",
    "Alice Bob|$10|US\n",
    "Sam Sneed|$1|CA\n",
    "Jon Sneed|$20|CA\n",
    "Arnold Wesise|$400|UK\n",
    "Henry Bob|$2|US\n",
    "Yo Yo Ma|$2|CA\n",
    "Jon York|$44|CA\n",
    "Alex Ball|$5|UK\n",
    "Jim Davis|$66|JA\n",
    "\n",
    "Countries.dat\n",
    "United States|US\n",
    "Canada|CA\n",
    "United Kingdom|UK\n",
    "Italy|IT\n",
    "\n",
    "</PRE>\n",
    "\n",
    "Justify which table you chose as the Left table in this hashside join.\n",
    "\n",
    "Please report the number of rows resulting from:\n",
    "\n",
    "- (1) Left joining Table Left with Table Right\n",
    "- (2) Right joining Table Left with Table Right\n",
    "- (3) Inner joining Table Left with Table Right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller table Countries.dat should be the one to be loaded into memory (in memory hash) to fit into memory and broadcasted to all nodes and mappers. The left table should be the table that will be loaded into memory, in this case, the smaller table Countries.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transactions.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile transactions.dat\n",
    "Alice Bob|$10|US\n",
    "Sam Sneed|$1|CA\n",
    "Jon Sneed|$20|CA\n",
    "Arnold Wesise|$400|UK\n",
    "Henry Bob|$2|US\n",
    "Yo Yo Ma|$2|CA\n",
    "Jon York|$44|CA\n",
    "Alex Ball|$5|UK\n",
    "Jim Davis|$66|JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Countries.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile Countries.dat\n",
    "United States|US\n",
    "Canada|CA\n",
    "United Kingdom|UK\n",
    "Italy|IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rightjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rightjoin.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "class rightjoin(MRJob):\n",
    "    ''' Assuming left table is Countries.dat(in-memory) and right table is transactions.dat\n",
    "    '''\n",
    "    \n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(mapper_init = self.mapper_init,\n",
    "                   mapper = self.mapper)\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.countries ={}  # dictionary with key = country code and value = country name\n",
    "        with open(\"Countries.dat\", \"r\") as countryfile:\n",
    "            for line in countryfile:\n",
    "                line = line.strip()\n",
    "                name, code = line.split('|')\n",
    "                self.countries[code] = name\n",
    "\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        customer, amount, countryID  = line.split('|')\n",
    "        countryname = self.countries.get(countryID, \"None\")\n",
    "        yield customer, (amount, countryID, countryname)\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rightjoin.run()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x rightjoin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right join (assuming Countries.dat is the left table and transactions.dat is the right table)\n",
      "      Alice Bob |            $10 |             US |  United States\n",
      "      Sam Sneed |             $1 |             CA |         Canada\n",
      "      Jon Sneed |            $20 |             CA |         Canada\n",
      "  Arnold Wesise |           $400 |             UK | United Kingdom\n",
      "      Henry Bob |             $2 |             US |  United States\n",
      "       Yo Yo Ma |             $2 |             CA |         Canada\n",
      "       Jon York |            $44 |             CA |         Canada\n",
      "      Alex Ball |             $5 |             UK | United Kingdom\n",
      "      Jim Davis |            $66 |             JA |           None\n",
      "\n",
      "There are 9 rows\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rightjoin import rightjoin\n",
    "mr_job = rightjoin(args=['transactions.dat','--file=Countries.dat'])\n",
    "\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    count = 0\n",
    "    print \"Right join (assuming Countries.dat is the left table and transactions.dat is the right table)\"\n",
    "    for line in runner.stream_output():\n",
    "        key, value = mr_job.parse_output_line(line)\n",
    "        print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(key, value[0], value[1], value[2])\n",
    "        count = count + 1\n",
    "        \n",
    "print \"\"\n",
    "print \"There are %s rows\" %(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting innerjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile innerjoin.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "class innerjoin(MRJob):\n",
    "    ''' Assuming left table is Countries.dat(in-memory) and right table is transactions.dat\n",
    "    '''\n",
    "    \n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(mapper_init = self.mapper_init,\n",
    "                   mapper = self.mapper)\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.countries ={}  # dictionary with key = country code and value = country name\n",
    "        with open(\"Countries.dat\", \"r\") as countryfile:\n",
    "            for line in countryfile:\n",
    "                line = line.strip()\n",
    "                name, code = line.split('|')\n",
    "                self.countries[code] = name\n",
    "\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        customer, amount, countryID  = line.split('|')\n",
    "        countryname = self.countries.get(countryID, \"None\")\n",
    "        if countryname != \"None\":\n",
    "            yield customer, (amount, countryID, countryname)\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    innerjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x innerjoin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner join\n",
      "      Alice Bob |            $10 |             US |  United States\n",
      "      Sam Sneed |             $1 |             CA |         Canada\n",
      "      Jon Sneed |            $20 |             CA |         Canada\n",
      "  Arnold Wesise |           $400 |             UK | United Kingdom\n",
      "      Henry Bob |             $2 |             US |  United States\n",
      "       Yo Yo Ma |             $2 |             CA |         Canada\n",
      "       Jon York |            $44 |             CA |         Canada\n",
      "      Alex Ball |             $5 |             UK | United Kingdom\n",
      "\n",
      "There are 8 rows\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from innerjoin import innerjoin\n",
    "mr_job = innerjoin(args=['transactions.dat','--file=Countries.dat'])\n",
    "\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    count = 0\n",
    "    print \"Inner join\"\n",
    "    for line in runner.stream_output():\n",
    "        key, value = mr_job.parse_output_line(line)\n",
    "        print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(key, value[0], value[1], value[2])\n",
    "        count = count + 1\n",
    "        \n",
    "print \"\"\n",
    "print \"There are %s rows\" %(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting leftjoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile leftjoin.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "class leftjoin(MRJob):\n",
    "    ''' Assuming left table is Countries.dat(in-memory) and right table is transactions.dat\n",
    "    '''\n",
    "\n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(mapper_init = self.mapper_init,\n",
    "                   mapper = self.mapper,\n",
    "                   reducer = self.reducer\n",
    "                  )\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.countries ={}  # dictionary with key = country code and value = country name\n",
    "        with open(\"Countries.dat\", \"r\") as countryfile:\n",
    "            for line in countryfile:\n",
    "                line = line.strip()\n",
    "                name, code = line.split('|')\n",
    "                self.countries[code] = name\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        customer, amount, countryID  = line.split('|')\n",
    "        for code in self.countries.keys():\n",
    "            if code == countryID:\n",
    "                yield code, (self.countries[code], customer, amount)\n",
    "            else:\n",
    "                yield code, (self.countries[code], \"None\", \"None\")\n",
    "                \n",
    "    \n",
    "    def reducer(self, key, values):\n",
    "        code = key  # all values grouped by country code\n",
    "        customer_in_countriesFile = False\n",
    "        for value in values:\n",
    "            if value[1] != \"None\":\n",
    "                customer_in_countriesFile = True\n",
    "                yield value[1], (value[2], code, value[0])\n",
    "        if customer_in_countriesFile == False:\n",
    "            yield \"None\", (\"None\", code, value[0])\n",
    "    \n",
    "   \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    leftjoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x leftjoin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left join (assuming Countries.dat is the left table and transactions.dat is the right table)\n",
      "      Jon Sneed |            $20 |             CA |         Canada\n",
      "       Jon York |            $44 |             CA |         Canada\n",
      "      Sam Sneed |             $1 |             CA |         Canada\n",
      "       Yo Yo Ma |             $2 |             CA |         Canada\n",
      "           None |           None |             IT |          Italy\n",
      "      Alex Ball |             $5 |             UK | United Kingdom\n",
      "  Arnold Wesise |           $400 |             UK | United Kingdom\n",
      "      Alice Bob |            $10 |             US |  United States\n",
      "      Henry Bob |             $2 |             US |  United States\n",
      "\n",
      "There are 9 rows\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from leftjoin import leftjoin\n",
    "mr_job = leftjoin(args=['transactions.dat','--file=Countries.dat'])\n",
    "#mr_job = leftjoin(args=['transactions.dat','Countries.dat'])\n",
    "\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    count = 0\n",
    "    print \"Left join (assuming Countries.dat is the left table and transactions.dat is the right table)\"\n",
    "    for line in runner.stream_output():\n",
    "        key, value = mr_job.parse_output_line(line)\n",
    "        print \"{0:>15} |{1:>15} |{2:>15} |{3:>15}\".format(key, value[0], value[1], value[2])\n",
    "        count = count + 1\n",
    "        \n",
    "print \"\"\n",
    "print \"There are %s rows\" %(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.2.1 (OPTIONAL) Almost stateless reducer-side join  <a name=\"5.2.1\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "The following MRJob code, implements a reduce-side join for an inner join. The reducer is almost stateless, i.e., uses as little memory as possible. Use the tables from HW5.2 for this HW and join based on the country code (third column of the transactions table and the second column of the Countries table perform. Perform  an left, right, inner joins using the code provided below and report the number of rows resulting from:\n",
    "\n",
    "- (1) Left joining Table Left with Table Right\n",
    "- (2) Right joining Table Left with Table Right\n",
    "- (3) Inner joining Table Left with Table Right\n",
    "\n",
    "Again make smart decisions about which table should be the left table (i.e., crosscheck the code). \n",
    "\n",
    "__Some notes on the code__ \n",
    "Here, the mapper receives its set of input splits either from the transaction table or from the countries table and makes the appropriate transformations: splitting the line into fields, and emitting a key/value. The key is the join key - in this case, the country code field of both sets of records. The mapper knows which file and type of record it is receiving based on the length of the fields. The records it emits contain the join field as the key, which acts as the partitioning key; We use the SORT_VALUES option, which ensures the values are sorted as well. Then, we employ a trick to ensure that for each join key, country records are seen always before transaction records. We achieve this by adding an arbitrary key to the front of the value: 'A' for countries, 'B' for customers. This makes countries sort before customers for each and every join/partition key. After that trick, the join is simply a matter of storing countries ('A' records) and crossing this array with each customer record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRJoin(MRJob):\n",
    "\n",
    "  # Performs secondary sort\n",
    "  SORT_VALUES = True\n",
    "\n",
    "  def mapper(self, _, line):\n",
    "    splits = line.rstrip(\"\\n\").split(\"|\")\n",
    "\n",
    "    if len(splits) == 2: # country data\n",
    "      symbol = 'A' # make country sort before transaction data\n",
    "      country2digit = splits[1]\n",
    "      yield country2digit, [symbol, splits]\n",
    "    else: # person data\n",
    "      symbol = 'B'\n",
    "      country2digit = splits[2]\n",
    "      yield country2digit, [symbol, splits]\n",
    "\n",
    "  def reducer(self, key, values):\n",
    "    countries = [] # should come first, as they are sorted on artificia key 'A'\n",
    "    for value in values:\n",
    "      if value[0] == 'A':\n",
    "        countries.append(value)\n",
    "      if value[0] == 'B':\n",
    "        for country in countries:\n",
    "          yield key, country[1:] + value[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  MRJoin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Pairwise similarity  - PHASE 1 <a name=\"5.3\"></a>\n",
    "\n",
    "In this part of the assignment we will focus on developing methods for detecting synonyms, using the Google 5-grams dataset. To accomplish this you must script two main tasks using MRJob:\n",
    "\n",
    "\n",
    "#### (1) Using the systems tests data sets, write mrjob code to build the stripes\n",
    "#### (2) Write mrjob code to build an inverted index from the stripes\n",
    "#### (3) Using two (symmetric) comparison methods of your choice (e.g., correlations, distances, similarities), pairwise compare all stripes (vectors), and output to a file.   \n",
    "\n",
    "__==Design notes for (1)== __  \n",
    "For this task you will be able to modify the pattern we used in HW 3.2 (feel free to use the solution as reference). To total the word counts across the n-grams, output the support from the mappers using the total order inversion pattern:\n",
    "\n",
    "<*word,count>   \n",
    "\n",
    "to ensure that the support arrives before the cooccurrences.   \n",
    "\n",
    "In addition to ensuring the determination of the total word counts, the mapper must also output co-occurrence counts for the pairs of words inside of each n-gram. Treat these words as a basket, as we have in HW 3, but count all stripes or pairs in both orders, i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for (2).\n",
    "\n",
    "__==Design notes for (3)==__   \n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    " - Jaccard\n",
    " - Cosine similarity\n",
    " - Spearman correlation\n",
    " - Euclidean distance\n",
    " - Taxicab (Manhattan) distance\n",
    " - Shortest path graph distance (a graph, because our data is symmetric!)\n",
    " - Pearson correlation\n",
    " - Kendall correlation\n",
    " ...\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to parallelize than others, and do not perform more associations than is necessary, since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildStripes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "import itertools\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "class MRbuildStripes(MRJob):\n",
    "  \n",
    "  #START SUDENT CODE531_STRIPES\n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper,\n",
    "                reducer = self.reducer\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.stripes = {}\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip().lower()\n",
    "        ngram, count, other = line.split('\\t',2)\n",
    "        count = int(count)\n",
    "        words = ngram.split(' ')\n",
    "        self.stripes = {}\n",
    "                \n",
    "        for subset in itertools.permutations(sorted(words), 2):  #instead of combinations to keep symmetry\n",
    "            if subset[0] == subset[1]:  # in case two same words in a line\n",
    "                continue\n",
    "            elif subset[0] not in self.stripes.keys():\n",
    "                self.stripes[subset[0]] = {}\n",
    "                self.stripes[subset[0]][subset[1]] = count\n",
    "            elif subset[1] not in self.stripes[subset[0]]:\n",
    "                self.stripes[subset[0]][subset[1]] = count\n",
    "            else:\n",
    "                self.stripes[subset[0]][subset[1]] += count\n",
    "\n",
    "        for key in self.stripes.keys():\n",
    "            yield key, self.stripes[key]\n",
    "            \n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        temp_stripes = {}\n",
    "        for value in values:\n",
    "            for word, count in value.items():\n",
    "                temp_stripes[word] = temp_stripes.get(word,0) + count\n",
    "        yield key, temp_stripes\n",
    "  \n",
    "\n",
    "  #END SUDENT CODE531_STRIPES   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRbuildStripes.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x buildStripes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting invertedIndex.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np commented since not supported by Hadoop Python version\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.protocol import JSONProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRinvertedIndex(MRJob):\n",
    "    INPUT_PROTOCOL = JSONProtocol\n",
    "\n",
    "  #START SUDENT CODE531_INV_INDEX\n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(\n",
    "                mapper=self.mapper,\n",
    "                reducer=self.reducer\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def mapper(self, key_word, stripes):\n",
    "        words = stripes.keys()\n",
    "        _len = len(words)\n",
    "        for word in words:\n",
    "        # Store the length of the document to use with JACCARD (|A| + |B|)\n",
    "            yield word, (key_word, _len)\n",
    "        \n",
    "    def reducer(self, word, values):        \n",
    "        d = collections.defaultdict(list)\n",
    "        for value in values:\n",
    "            d[word].append(value)\n",
    "        yield word,d[word]\n",
    "\n",
    "  #END SUDENT CODE531_INV_INDEX\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRinvertedIndex.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x invertedIndex.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np  commented since not supported by Hadoop Python version\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRsimilarity(MRJob):\n",
    "  \n",
    "  #START SUDENT CODE531_SIMILARITY\n",
    "    MRJob.SORT_VALUES\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {}\n",
    "        JOBCONF_STEP2 = { \n",
    "                # Must use -r hadoop mode for this sorting to work #\n",
    "                'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "\n",
    "        return [\n",
    "            MRStep(jobconf=JOBCONF_STEP1,\n",
    "                   mapper = self.mapper_pair_sim,\n",
    "                   reducer = self.reducer_pair_sim\n",
    "                  ),\n",
    "            MRStep(jobconf=JOBCONF_STEP2,\n",
    "                  mapper=None,\n",
    "                  reducer=self.reducer_sort)\n",
    "        ]\n",
    "        \n",
    "    def mapper_pair_sim(self, _, line):\n",
    "        line = line.strip()\n",
    "        index,posting = line.split(\"\\t\")\n",
    "        posting = json.loads(posting)\n",
    "        \n",
    "        X = map(lambda x: x[0]+\".\"+str(x[1]) , posting)\n",
    "        \n",
    "        # taking advantage of symetry, output only (a,b), but not (b,a)\n",
    "        for subset in itertools.combinations(sorted(set(X)), 2):\n",
    "            yield subset[0]+\".\"+subset[1], 1\n",
    "        \n",
    "            \n",
    "    def reducer_pair_sim(self,key,values):\n",
    "        word1, word1_len, word2, word2_len = key.split(\".\")\n",
    "        t =sum(values)\n",
    "       \n",
    "        cosine = (1.0/(float(word1_len)**0.5) * 1.0/(float(word2_len)**0.5))*t\n",
    "        jaccard = t / ( int(word1_len) + int(word2_len) - t )\n",
    "        overlap = t / min(int(word1_len), int(word2_len))\n",
    "        dice = 2 * t / ( int(word1_len) + int(word2_len))\n",
    "        avg = (jaccard + cosine + overlap + dice) / 4\n",
    "        \n",
    "        # rounding to 6 decimals\n",
    "        avg = round(avg, 6)\n",
    "        cosine = round(cosine, 6)\n",
    "        jaccard = round(jaccard, 6)\n",
    "        overlap = round(overlap, 6)\n",
    "        dice = round(dice, 6)\n",
    "        \n",
    "        yield avg, (word1+\" - \"+word2, cosine, jaccard, overlap, dice)\n",
    "    \n",
    "    \n",
    "    def reducer_sort(self,key,values):\n",
    "        for value in values:\n",
    "            yield key, value\n",
    "\n",
    "  #END SUDENT CODE531_SIMILARITY\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    MRsimilarity.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x similarity.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW5.3.1   Run Systems tests locally on small datasets (PHASE1) <a name=\"5.3.1\"></a>  \n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Complete 5.3 and systems test using the below test datasets. Phase 2 will focus on the entire Ngram dataset.\n",
    "\n",
    "To help you through these tasks please verify that your code gives the results below (for stripes, inverted index, and pairwise similarities).\n",
    "\n",
    "Test datasets:\n",
    "\n",
    "* googlebooks-eng-all-5gram-20090715-0-filtered.txt [see below]\n",
    "* atlas-boon-test [see below]\n",
    "* stripe-docs-test [see below]\n",
    "\n",
    "\n",
    "A large subset of the Google n-grams dataset\n",
    "\n",
    "https://aws.amazon.com/datasets/google-books-ngrams/\n",
    "\n",
    "which we have placed in a bucket/folder on Dropbox and on s3:\n",
    "\n",
    "https://www.dropbox.com/sh/tmqpc4o0xswhkvz/AACUifrl6wrMrlK6a3X3lZ9Ea?dl=0 \n",
    "\n",
    "s3://filtered-5grams/\n",
    "\n",
    "In particular, this bucket contains (~200) files (10Meg each) in the format:\n",
    "\n",
    "\t(ngram) \\t (count) \\t (pages_count) \\t (books_count)\n",
    "\n",
    "The next cell shows the first 10 lines of the googlebooks-eng-all-5gram-20090715-0-filtered.txt file.\n",
    "\n",
    "\n",
    "__DISCLAIMER__: Each record is already a 5-gram. In real life, we would calculate the stripes cooccurrence data from the raw text by windowing over the raw text and not from the 5-gram preprocessed data (as we are doing here).  Calculatating pairs on this 5-gram is a little corrupt as we will be double counting cooccurences. Having said that this exercise can still pull out some simialr terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: unit/systems first-10-lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "A BILL FOR ESTABLISHING RELIGIOUS\t59\t59\t54\n",
    "A Biography of General George\t92\t90\t74\n",
    "A Case Study in Government\t102\t102\t78\n",
    "A Case Study of Female\t447\t447\t327\n",
    "A Case Study of Limited\t55\t55\t43\n",
    "A Child's Christmas in Wales\t1099\t1061\t866\n",
    "A Circumstantial Narrative of the\t62\t62\t50\n",
    "A City by the Sea\t62\t60\t49\n",
    "A Collection of Fairy Tales\t123\t117\t80\n",
    "A Collection of Forms of\t116\t103\t82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: unit/systems atlas-boon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing atlas-boon-systems-test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile atlas-boon-systems-test.txt\n",
    "atlas boon\t50\t50\t50\n",
    "boon cava dipped\t10\t10\t10\n",
    "atlas dipped\t15\t15\t15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: unit/systems stripe-docs-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three terms, A,B,C and their corresponding stripe-docs of co-occurring terms\n",
    "\n",
    "- DocA {X:20, Y:30, Z:5}\n",
    "- DocB {X:100, Y:20}\n",
    "- DocC {M:5, N:20, Z:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) build stripes for all the test data sets - run the commands and insure that your output matches the output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: Unknown command\n",
      "Did you mean -rm?  This command begins with a dash.\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.root.20170211.235301.697009\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes.root.20170211.235301.697009/output...\n",
      "Removing temp directory /tmp/buildStripes.root.20170211.235301.697009...\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 1\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs rm --recursive systems_test_stripes_1\n",
    "!python buildStripes.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t{\"limited\": 55, \"female\": 447, \"general\": 92, \"sea\": 62, \"in\": 1201, \"religious\": 59, \"george\": 92, \"biography\": 92, \"city\": 62, \"for\": 59, \"tales\": 123, \"child's\": 1099, \"forms\": 116, \"wales\": 1099, \"christmas\": 1099, \"government\": 102, \"collection\": 239, \"by\": 62, \"case\": 604, \"circumstantial\": 62, \"fairy\": 123, \"of\": 1011, \"study\": 604, \"bill\": 59, \"establishing\": 59, \"narrative\": 62, \"the\": 124}\r\n",
      "\"bill\"\t{\"a\": 59, \"religious\": 59, \"for\": 59, \"establishing\": 59}\r\n",
      "\"biography\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"general\": 92}\r\n",
      "\"by\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"sea\": 62}\r\n",
      "\"case\"\t{\"a\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"study\": 604, \"female\": 447, \"in\": 102}\r\n",
      "\"child's\"\t{\"a\": 1099, \"wales\": 1099, \"christmas\": 1099, \"in\": 1099}\r\n",
      "\"christmas\"\t{\"a\": 1099, \"wales\": 1099, \"in\": 1099, \"child's\": 1099}\r\n",
      "\"circumstantial\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"narrative\": 62}\r\n",
      "\"city\"\t{\"a\": 62, \"the\": 62, \"by\": 62, \"sea\": 62}\r\n",
      "\"collection\"\t{\"a\": 239, \"forms\": 116, \"fairy\": 123, \"tales\": 123, \"of\": 355}\r\n",
      "\"establishing\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"for\": 59}\r\n",
      "\"fairy\"\t{\"a\": 123, \"of\": 123, \"tales\": 123, \"collection\": 123}\r\n",
      "\"female\"\t{\"a\": 447, \"case\": 447, \"study\": 447, \"of\": 447}\r\n",
      "\"for\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"establishing\": 59}\r\n",
      "\"forms\"\t{\"a\": 116, \"of\": 232, \"collection\": 116}\r\n",
      "\"general\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"biography\": 92}\r\n",
      "\"george\"\t{\"a\": 92, \"of\": 92, \"biography\": 92, \"general\": 92}\r\n",
      "\"government\"\t{\"a\": 102, \"case\": 102, \"study\": 102, \"in\": 102}\r\n",
      "\"in\"\t{\"a\": 1201, \"case\": 102, \"government\": 102, \"study\": 102, \"child's\": 1099, \"wales\": 1099, \"christmas\": 1099}\r\n",
      "\"limited\"\t{\"a\": 55, \"case\": 55, \"study\": 55, \"of\": 55}\r\n",
      "\"narrative\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"circumstantial\": 62}\r\n",
      "\"of\"\t{\"a\": 1011, \"case\": 502, \"circumstantial\": 62, \"george\": 92, \"limited\": 55, \"tales\": 123, \"collection\": 355, \"the\": 62, \"forms\": 232, \"female\": 447, \"narrative\": 62, \"fairy\": 123, \"general\": 92, \"study\": 502, \"biography\": 92}\r\n",
      "\"religious\"\t{\"a\": 59, \"bill\": 59, \"for\": 59, \"establishing\": 59}\r\n",
      "\"sea\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"by\": 62}\r\n",
      "\"study\"\t{\"a\": 604, \"case\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"female\": 447, \"in\": 102}\r\n",
      "\"tales\"\t{\"a\": 123, \"of\": 123, \"fairy\": 123, \"collection\": 123}\r\n",
      "\"the\"\t{\"a\": 124, \"city\": 62, \"circumstantial\": 62, \"of\": 62, \"sea\": 62, \"narrative\": 62, \"by\": 62}\r\n",
      "\"wales\"\t{\"a\": 1099, \"in\": 1099, \"christmas\": 1099, \"child's\": 1099}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\"a\"\t{\"limited\": 55, \"sea\": 62, \"general\": 92, \"female\": 447, \"in\": 1201, \"religious\": 59, \"george\": 92, \"biography\": 92, \"city\": 62, \"for\": 59, \"tales\": 123, \"child's\": 1099, \"forms\": 116, \"wales\": 1099, \"christmas\": 1099, \"government\": 102, \"collection\": 239, \"by\": 62, \"case\": 604, \"circumstantial\": 62, \"fairy\": 123, \"of\": 1011, \"study\": 604, \"bill\": 59, \"establishing\": 59, \"narrative\": 62, \"the\": 124}\n",
    "\"bill\"\t{\"a\": 59, \"religious\": 59, \"for\": 59, \"establishing\": 59}\n",
    "\"biography\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"general\": 92}\n",
    "\"by\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"sea\": 62}\n",
    "\"case\"\t{\"a\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"study\": 604, \"female\": 447, \"in\": 102}\n",
    "\"child's\"\t{\"a\": 1099, \"wales\": 1099, \"christmas\": 1099, \"in\": 1099}\n",
    "\"christmas\"\t{\"a\": 1099, \"wales\": 1099, \"in\": 1099, \"child's\": 1099}\n",
    "\"circumstantial\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"narrative\": 62}\n",
    "\"city\"\t{\"a\": 62, \"the\": 62, \"by\": 62, \"sea\": 62}\n",
    "\"collection\"\t{\"a\": 239, \"of\": 355, \"fairy\": 123, \"tales\": 123, \"forms\": 116}\n",
    "\"establishing\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"for\": 59}\n",
    "\"fairy\"\t{\"a\": 123, \"of\": 123, \"tales\": 123, \"collection\": 123}\n",
    "\"female\"\t{\"a\": 447, \"case\": 447, \"study\": 447, \"of\": 447}\n",
    "\"for\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"establishing\": 59}\n",
    "\"forms\"\t{\"a\": 116, \"of\": 232, \"collection\": 116}\n",
    "\"general\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"biography\": 92}\n",
    "\"george\"\t{\"a\": 92, \"of\": 92, \"biography\": 92, \"general\": 92}\n",
    "\"government\"\t{\"a\": 102, \"case\": 102, \"study\": 102, \"in\": 102}\n",
    "\"in\"\t{\"a\": 1201, \"case\": 102, \"government\": 102, \"study\": 102, \"child's\": 1099, \"wales\": 1099, \"christmas\": 1099}\n",
    "\"limited\"\t{\"a\": 55, \"case\": 55, \"study\": 55, \"of\": 55}\n",
    "\"narrative\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"circumstantial\": 62}\n",
    "\"of\"\t{\"a\": 1127, \"case\": 502, \"circumstantial\": 62, \"george\": 92, \"limited\": 55, \"tales\": 123, \"collection\": 471, \"general\": 92, \"forms\": 348, \"female\": 447, \"narrative\": 62, \"study\": 502, \"fairy\": 123, \"the\": 62, \"biography\": 92}\n",
    "\"religious\"\t{\"a\": 59, \"bill\": 59, \"for\": 59, \"establishing\": 59}\n",
    "\"sea\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"by\": 62}\n",
    "\"study\"\t{\"a\": 604, \"case\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"female\": 447, \"in\": 102}\n",
    "\"tales\"\t{\"a\": 123, \"of\": 123, \"fairy\": 123, \"collection\": 123}\n",
    "\"the\"\t{\"a\": 124, \"city\": 62, \"circumstantial\": 62, \"of\": 62, \"sea\": 62, \"narrative\": 62, \"by\": 62}\n",
    "\"wales\"\t{\"a\": 1099, \"in\": 1099, \"christmas\": 1099, \"child's\": 1099}\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: Unknown command\n",
      "Did you mean -rm?  This command begins with a dash.\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.root.20170211.235636.185095\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes.root.20170211.235636.185095/output...\n",
      "Removing temp directory /tmp/buildStripes.root.20170211.235636.185095...\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 2\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs rm --recursive systems_test_stripes_2\n",
    "!python buildStripes.py -r local atlas-boon-systems-test.txt > systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"atlas\"\t{\"dipped\": 15, \"boon\": 50}\r\n",
      "\"boon\"\t{\"atlas\": 50, \"dipped\": 10, \"cava\": 10}\r\n",
      "\"cava\"\t{\"dipped\": 10, \"boon\": 10}\r\n",
      "\"dipped\"\t{\"atlas\": 15, \"boon\": 10, \"cava\": 10}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<pre>\n",
    "\"atlas\"   {\"dipped\": 15, \"boon\": 50}   \n",
    "\"boon\"    {\"atlas\": 50, \"dipped\": 10, \"cava\": 10}   \n",
    "\"cava\"    {\"dipped\": 10, \"boon\": 10} \n",
    "\"dipped\"  {\"atlas\": 15, \"boon\": 10, \"cava\": 10}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"DocA\"\t{\"X\":20, \"Y\":30, \"Z\":5}\r\n",
      "\"DocB\"\t{\"X\":100, \"Y\":20}\r\n",
      "\"DocC\"\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\r\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Stripes for systems test 3 (given, no need to build stripes)\n",
    "########################################################################\n",
    "\n",
    "with open(\"systems_test_stripes_3\", \"w\") as f:\n",
    "    f.writelines([\n",
    "        '\"DocA\"\\t{\"X\":20, \"Y\":30, \"Z\":5}\\n',\n",
    "        '\"DocB\"\\t{\"X\":100, \"Y\":20}\\n',  \n",
    "        '\"DocC\"\\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\\n'\n",
    "    ])\n",
    "!cat systems_test_stripes_3   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Build Inverted Index - run the commands and insure that your output matches the output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.root.20170211.235658.196230\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.root.20170211.235658.196230/output...\n",
      "Removing temp directory /tmp/invertedIndex.root.20170211.235658.196230...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_1 > systems_test_index_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.root.20170211.235707.378783\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.root.20170211.235707.378783/output...\n",
      "Removing temp directory /tmp/invertedIndex.root.20170211.235707.378783...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_2 > systems_test_index_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.root.20170211.235711.141870\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.root.20170211.235711.141870/output...\n",
      "Removing temp directory /tmp/invertedIndex.root.20170211.235711.141870...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_3 > systems_test_index_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  1  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
      "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
      "     \"biography\" |            a 27 |       general 4 |        george 4\n",
      "            \"by\" |            a 27 |          city 4 |           sea 4\n",
      "          \"case\" |            a 27 |        female 4 |    government 4\n",
      "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
      "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
      "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
      "          \"city\" |            a 27 |            by 4 |           sea 4\n",
      "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
      "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
      "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
      "        \"female\" |            a 27 |          case 7 |           of 15\n",
      "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
      "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
      "       \"general\" |            a 27 |     biography 4 |        george 4\n",
      "        \"george\" |            a 27 |     biography 4 |       general 4\n",
      "    \"government\" |            a 27 |          case 7 |            in 7\n",
      "            \"in\" |            a 27 |          case 7 |       child's 4\n",
      "       \"limited\" |            a 27 |          case 7 |           of 15\n",
      "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
      "            \"of\" |            a 27 |     biography 4 |          case 7\n",
      "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
      "           \"sea\" |            a 27 |            by 4 |          city 4\n",
      "         \"study\" |            a 27 |          case 7 |        female 4\n",
      "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
      "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
      "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  2  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
      "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
      "          \"cava\" |          boon 3 |        dipped 3 |                \n",
      "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  3  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "             \"M\" |          DocC 4 |                 |                \n",
      "             \"N\" |          DocC 4 |                 |                \n",
      "             \"X\" |          DocA 3 |          DocB 2 |                \n",
      "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n",
      "             \"Z\" |          DocA 3 |          DocC 4 |                \n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Pretty print systems tests for generating Inverted Index\n",
    "##########################################################\n",
    "\n",
    "import json\n",
    "\n",
    "for i in range(1,4):\n",
    "  print \"—\"*100\n",
    "  print \"Systems test \",i,\" - Inverted Index\"\n",
    "  print \"—\"*100  \n",
    "  with open(\"systems_test_index_\"+str(i),\"r\") as f:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "          line = line.strip()\n",
    "          word,stripe = line.split(\"\\t\")\n",
    "          stripe = json.loads(stripe)\n",
    "          stripe.extend([[\"\",\"\"] for _ in xrange(3 - len(stripe))])\n",
    "\n",
    "          print \"{0:>16} |{1:>16} |{2:>16} |{3:>16}\".format(\n",
    "              (word), stripe[0][0]+\" \"+str(stripe[0][1]), stripe[1][0]+\" \"+str(stripe[1][1]), stripe[2][0]+\" \"+str(stripe[2][1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Systems test  1  - Inverted Index\n",
    "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
    "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
    "     \"biography\" |            a 27 |       general 4 |        george 4\n",
    "            \"by\" |            a 27 |          city 4 |           sea 4\n",
    "          \"case\" |            a 27 |        female 4 |    government 4\n",
    "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
    "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
    "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
    "          \"city\" |            a 27 |            by 4 |           sea 4\n",
    "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
    "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
    "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
    "        \"female\" |            a 27 |          case 7 |           of 15\n",
    "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
    "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
    "       \"general\" |            a 27 |     biography 4 |        george 4\n",
    "        \"george\" |            a 27 |     biography 4 |       general 4\n",
    "    \"government\" |            a 27 |          case 7 |            in 7\n",
    "            \"in\" |            a 27 |          case 7 |       child's 4\n",
    "       \"limited\" |            a 27 |          case 7 |           of 15\n",
    "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
    "            \"of\" |            a 27 |     biography 4 |          case 7\n",
    "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
    "           \"sea\" |            a 27 |            by 4 |          city 4\n",
    "         \"study\" |            a 27 |          case 7 |        female 4\n",
    "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
    "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
    "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
    "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Systems test  2  - Inverted Index\n",
    "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
    "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
    "          \"cava\" |          boon 3 |        dipped 3 |                \n",
    "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
    "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Systems test  3  - Inverted Index\n",
    "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "             \"M\" |          DocC 4 |                 |                \n",
    "             \"N\" |          DocC 4 |                 |                \n",
    "             \"X\" |          DocA 3 |          DocB 2 |                \n",
    "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n",
    "             \"Z\" |          DocA 3 |          DocC 4 |                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Calculate similarities - run the commands and insure that your output matches the output below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: you must run in hadoop mode to generate sorted similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/similarity.root.20170212.012901.423879\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/similarity.root.20170212.012901.423879/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob8660531504806535883.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0221\n",
      "  Submitted application application_1485626579957_0221\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0221/\n",
      "  Running job: job_1485626579957_0221\n",
      "  Job job_1485626579957_0221 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0221 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity.root.20170212.012901.423879/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3762\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=31512\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15880\n",
      "\t\tFILE: Number of bytes written=394042\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4100\n",
      "\t\tHDFS: Number of bytes written=31512\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=9423872\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=3937280\n",
      "\t\tTotal time spent by all map tasks (ms)=9203\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=9203\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3845\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3845\n",
      "\t\tTotal vcore-seconds taken by all map tasks=9203\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3845\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2180\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=164\n",
      "\t\tInput split bytes=338\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=14528\n",
      "\t\tMap output materialized bytes=15886\n",
      "\t\tMap output records=673\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=744476672\n",
      "\t\tReduce input groups=378\n",
      "\t\tReduce input records=673\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=15886\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1346\n",
      "\t\tTotal committed heap usage (bytes)=671088640\n",
      "\t\tVirtual memory (bytes) snapshot=4695048192\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob250583902755768554.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0222\n",
      "  Submitted application application_1485626579957_0222\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0222/\n",
      "  Running job: job_1485626579957_0222\n",
      "  Job job_1485626579957_0222 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0222 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity.root.20170212.012901.423879/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=35608\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=31512\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=32274\n",
      "\t\tFILE: Number of bytes written=427655\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=35948\n",
      "\t\tHDFS: Number of bytes written=31512\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=9593856\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=3553280\n",
      "\t\tTotal time spent by all map tasks (ms)=9369\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=9369\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3470\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3470\n",
      "\t\tTotal vcore-seconds taken by all map tasks=9369\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3470\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2050\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=132\n",
      "\t\tInput split bytes=340\n",
      "\t\tMap input records=378\n",
      "\t\tMap output bytes=31512\n",
      "\t\tMap output materialized bytes=32280\n",
      "\t\tMap output records=378\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=761233408\n",
      "\t\tReduce input groups=34\n",
      "\t\tReduce input records=378\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=32280\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=756\n",
      "\t\tTotal committed heap usage (bytes)=737673216\n",
      "\t\tVirtual memory (bytes) snapshot=4697190400\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/similarity.root.20170212.012901.423879/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/similarity.root.20170212.012901.423879...\n",
      "Removing temp directory /tmp/similarity.root.20170212.012901.423879...\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_1 > systems_test_similarities_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/similarity.root.20170212.014634.928830\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014634.928830/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob6612064399317853092.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0225\n",
      "  Submitted application application_1485626579957_0225\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0225/\n",
      "  Running job: job_1485626579957_0225\n",
      "  Job job_1485626579957_0225 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0225 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014634.928830/step-output/0000\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=260\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=451\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=178\n",
      "\t\tFILE: Number of bytes written=362638\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=598\n",
      "\t\tHDFS: Number of bytes written=451\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=9717760\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=3319808\n",
      "\t\tTotal time spent by all map tasks (ms)=9490\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=9490\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3242\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3242\n",
      "\t\tTotal vcore-seconds taken by all map tasks=9490\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3242\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1830\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=150\n",
      "\t\tInput split bytes=338\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=156\n",
      "\t\tMap output materialized bytes=184\n",
      "\t\tMap output records=8\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=769802240\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=184\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=16\n",
      "\t\tTotal committed heap usage (bytes)=736624640\n",
      "\t\tVirtual memory (bytes) snapshot=4696858624\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob823129817071108337.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0226\n",
      "  Submitted application application_1485626579957_0226\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0226/\n",
      "  Running job: job_1485626579957_0226\n",
      "  Job job_1485626579957_0226 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0226 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014634.928830/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=677\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=451\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=469\n",
      "\t\tFILE: Number of bytes written=364045\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1017\n",
      "\t\tHDFS: Number of bytes written=451\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=14245888\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4480000\n",
      "\t\tTotal time spent by all map tasks (ms)=13912\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=13912\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4375\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4375\n",
      "\t\tTotal vcore-seconds taken by all map tasks=13912\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4375\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2530\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=174\n",
      "\t\tInput split bytes=340\n",
      "\t\tMap input records=6\n",
      "\t\tMap output bytes=451\n",
      "\t\tMap output materialized bytes=475\n",
      "\t\tMap output records=6\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=731418624\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=6\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=475\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=12\n",
      "\t\tTotal committed heap usage (bytes)=671088640\n",
      "\t\tVirtual memory (bytes) snapshot=4669353984\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014634.928830/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014634.928830...\n",
      "Removing temp directory /tmp/similarity.root.20170212.014634.928830...\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_2 > systems_test_similarities_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/similarity.root.20170212.014448.786003\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014448.786003/files/...\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob8063775513243738256.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0223\n",
      "  Submitted application application_1485626579957_0223\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0223/\n",
      "  Running job: job_1485626579957_0223\n",
      "  Job job_1485626579957_0223 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0223 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014448.786003/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=213\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=328\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=106\n",
      "\t\tFILE: Number of bytes written=362494\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=551\n",
      "\t\tHDFS: Number of bytes written=328\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=13697024\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4471808\n",
      "\t\tTotal time spent by all map tasks (ms)=13376\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=13376\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4367\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4367\n",
      "\t\tTotal vcore-seconds taken by all map tasks=13376\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4367\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2290\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=205\n",
      "\t\tInput split bytes=338\n",
      "\t\tMap input records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=112\n",
      "\t\tMap output records=5\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=717275136\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=112\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=10\n",
      "\t\tTotal committed heap usage (bytes)=671088640\n",
      "\t\tVirtual memory (bytes) snapshot=4691308544\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob5954883734405900340.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0224\n",
      "  Submitted application application_1485626579957_0224\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0224/\n",
      "  Running job: job_1485626579957_0224\n",
      "  Job job_1485626579957_0224 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0224 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014448.786003/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=492\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=328\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=340\n",
      "\t\tFILE: Number of bytes written=363790\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=832\n",
      "\t\tHDFS: Number of bytes written=328\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=8868864\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=3741696\n",
      "\t\tTotal time spent by all map tasks (ms)=8661\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=8661\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3654\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3654\n",
      "\t\tTotal vcore-seconds taken by all map tasks=8661\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3654\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2020\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=123\n",
      "\t\tInput split bytes=340\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=328\n",
      "\t\tMap output materialized bytes=346\n",
      "\t\tMap output records=3\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=765054976\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=346\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=6\n",
      "\t\tTotal committed heap usage (bytes)=736624640\n",
      "\t\tVirtual memory (bytes) snapshot=4684644352\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014448.786003/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/similarity.root.20170212.014448.786003...\n",
      "Removing temp directory /tmp/similarity.root.20170212.014448.786003...\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_3 > systems_test_similarities_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  1  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |                       pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       1.000000 |           female - limited |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.868292 |              forms - tales |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.868292 |              fairy - forms |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.830357 |               case - study |       0.857143 |       0.750000 |       0.857143 |       0.857143\n",
      "       0.712500 |            child's - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                  by - city |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                 bill - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 | circumstantial - narrative |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                   by - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        child's - christmas |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |          christmas - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |           bill - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        biography - general |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |         biography - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        bill - establishing |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |                 city - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |              fairy - tales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |         establishing - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |           general - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |   establishing - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |            for - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |       government - limited |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |        female - government |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.698916 |                     a - of |       0.695666 |       0.500000 |       0.933333 |       0.666667\n",
      "       0.646872 |         collection - tales |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.646872 |         collection - fairy |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.559350 |            government - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                 city - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                female - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |            narrative - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |             female - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |            limited - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                 in - wales |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                  sea - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |               in - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |         government - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |             christmas - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |          case - government |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |             case - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |                   by - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |       circumstantial - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |               child's - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.559350 |              case - female |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.553861 |     circumstantial - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |          biography - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |             forms - george |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |            forms - limited |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |          forms - narrative |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |            forms - general |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |             female - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.504099 |         collection - forms |       0.516398 |       0.333333 |       0.666667 |       0.500000\n",
      "       0.477970 |            collection - of |       0.461880 |       0.250000 |       0.800000 |       0.400000\n",
      "       0.465201 |                   a - case |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.465201 |                    a - the |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.465201 |                     a - in |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.465201 |                  a - study |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.458333 |          biography - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |   circumstantial - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          biography - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |     christmas - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             by - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |      biography - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        biography - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |     circumstantial - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |      circumstantial - city |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         biography - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |   circumstantial - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |    circumstantial - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 | biography - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |       child's - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |       circumstantial - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        by - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |     circumstantial - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |    circumstantial - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          narrative - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         female - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            fairy - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         government - wales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             female - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            limited - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |           george - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        limited - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |         george - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             fairy - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |           city - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          general - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |        general - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            general - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |          fairy - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |           female - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            female - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            fairy - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |            narrative - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             fairy - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |             george - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.438276 |                forms - the |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.438276 |              forms - study |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.438276 |               case - forms |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.419343 |circumstantial - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |     biography - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |     collection - narrative |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |        collection - george |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |       collection - limited |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |       collection - general |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |        collection - female |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.410147 |                female - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |             narrative - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |            government - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |                george - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |                 fairy - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |                 of - tales |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |               limited - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |               general - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |        circumstantial - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.410147 |             biography - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.389610 |                  case - in |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.389610 |                 in - study |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.386912 |                 of - study |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.386912 |                  case - of |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.384281 |             a - collection |       0.344265 |       0.142857 |       0.800000 |       0.250000\n",
      "       0.365956 |          christmas - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |            biography - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |          biography - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |     circumstantial - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |            child's - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |           biography - case |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               case - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               case - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |           case - narrative |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              case - george |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |             case - general |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               case - fairy |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |      case - circumstantial |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |           case - christmas |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |             case - child's |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               female - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |               george - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |             george - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              general - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |            general - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              study - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              limited - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |                tales - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |          narrative - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |                fairy - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              fairy - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |              study - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.334842 |              a - religious |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |           a - establishing |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |              a - narrative |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                  a - wales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                a - limited |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                  a - fairy |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |         a - circumstantial |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                   a - bill |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |             a - government |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |              a - christmas |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                  a - tales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                     a - by |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                a - general |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                 a - female |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                 a - george |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                    a - for |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                   a - city |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                a - child's |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |                    a - sea |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |              a - biography |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.328008 |                 forms - of |       0.298142 |       0.125000 |       0.666667 |       0.222222\n",
      "       0.317849 |           collection - the |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.317849 |         collection - study |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.317849 |          case - collection |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.287991 |                   of - the |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.287991 |                    in - of |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.273413 |                  a - forms |       0.222222 |       0.071429 |       0.666667 |       0.133333\n",
      "       0.271593 |                    by - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.271593 |                  city - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.271593 |                   of - sea |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.268597 |                forms - sea |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |               city - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |              forms - wales |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |                for - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |       establishing - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |         forms - government |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |          forms - religious |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |          christmas - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |                 by - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |               bill - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |            child's - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.255952 |                 case - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.255952 |                study - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.223214 |          city - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              general - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        limited - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              limited - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                for - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                for - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                  for - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            limited - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             city - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            for - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              for - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          religious - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           for - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               for - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              for - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             female - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            general - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      narrative - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               female - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         female - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        george - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     government - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          narrative - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              city - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              tales - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           city - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                sea - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              fairy - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               city - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                fairy - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          fairy - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         government - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               city - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     government - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         fairy - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         george - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               george - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                fairy - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           government - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       establishing - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            religious - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       establishing - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             city - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         establishing - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   establishing - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     establishing - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  establishing - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      establishing - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     establishing - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             george - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      establishing - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                sea - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       establishing - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          religious - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       general - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        general - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               female - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 city - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              city - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               city - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        city - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     circumstantial - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | circumstantial - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |circumstantial - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       circumstantial - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |circumstantial - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          christmas - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            christmas - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      christmas - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      christmas - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        christmas - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         christmas - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        christmas - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            christmas - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |         christmas - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          christmas - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   christmas - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           christmas - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | christmas - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            child's - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              child's - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        child's - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        child's - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          child's - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           child's - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          child's - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              child's - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           child's - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            child's - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     child's - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             child's - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   child's - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 by - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 by - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               by - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            by - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                by - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               by - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                   by - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                by - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 by - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          by - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             by - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               by - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          biography - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            biography - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      biography - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     biography - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |            biography - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   biography - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           biography - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      biography - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |        biography - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             biography - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               bill - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               bill - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                 bill - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           bill - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             bill - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |          bill - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              bill - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             bill - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |              bill - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |               bill - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                bill - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      bill - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           bill - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             bill - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |                  bill - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |           bill - biography |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |             by - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.215666 |                 forms - in |       0.218218 |       0.111111 |       0.333333 |       0.200000\n",
      "       0.205207 |           collection - sea |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |           collection - for |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |     collection - religious |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |  collection - establishing |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |         collection - wales |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |    collection - government |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |       child's - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |     christmas - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |          bill - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |          city - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |            by - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.180200 |                 case - for |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  bill - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |               bill - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 bill - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |             biography - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  by - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                    by - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 by - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                case - city |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |        case - establishing |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |           case - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 case - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |              child's - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |            christmas - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |        circumstantial - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                bill - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                the - wales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                sea - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |            religious - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |          religious - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 in - tales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                   in - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |             in - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |             in - narrative |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |           government - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                george - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |               general - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                for - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                   for - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                 fairy - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |         establishing - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |       establishing - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |          establishing - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |               city - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  city - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |                  for - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.156652 |            collection - in |       0.169031 |       0.090909 |       0.200000 |       0.166667\n",
      "       0.134980 |                   for - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |                 of - wales |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |             of - religious |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |          establishing - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |               child's - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |             christmas - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.134980 |                  bill - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.126374 |                   in - the |       0.142857 |       0.076923 |       0.142857 |       0.142857\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  2  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |                       pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       1.000000 |               atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.625000 |              boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
      "       0.389562 |              cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |                boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |             atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |               atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  3  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |                       pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.820791 |                DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
      "       0.553861 |                DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.346722 |                DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Pretty print systems tests FOR ALL TESTS - NOT USED - SEE BELOW\n",
    "############################################\n",
    "\n",
    "import json\n",
    "for i in range(1,4):\n",
    "  print '—'*110\n",
    "  print \"Systems test \",i,\" - Similarity measures\"\n",
    "  print '—'*110\n",
    "  print \"{0:>15} |{1:>27} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "          \"average\", \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\")\n",
    "  print '-'*110\n",
    "\n",
    "  with open(\"systems_test_similarities_\"+str(i),\"r\") as f:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "          line = line.strip()\n",
    "          avg,stripe = line.split(\"\\t\")\n",
    "          stripe = json.loads(stripe)\n",
    "\n",
    "          print \"{0:>15f} |{1:>27} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "              float(avg), stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Similairity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Systems test  3  - Similarity measures\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "       0.741582 |    DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
    "       0.488675 |    DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
    "       0.276777 |    DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Systems test  2  - Similarity measures\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "       1.000000 |   atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
    "       0.625000 |  boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
    "       0.389562 |  cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "       0.389562 |    boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "       0.389562 | atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "       0.389562 |   atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Systems test  1  - Similarity measures\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "       0.096639 |      bill - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
    "       0.096639 |   child's - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
    "       0.096639 | christmas - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
    "       0.096639 |establishing - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
    "       0.096639 |       for - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
    "       0.096639 | of - religious |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
    "       0.096639 |     of - wales |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
    "       0.120879 |       in - the |       0.142857 |       0.076923 |       0.142857 |       0.142857\n",
    "       0.142202 |collection - in |       0.169031 |       0.090909 |       0.200000 |       0.166667\n",
    "       0.142328 |      a - forms |       0.222222 |       0.071429 |       0.666667 |       0.133333\n",
    "       0.156933 |    bill - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
    "      ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# === END OF PHASE 1 ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
