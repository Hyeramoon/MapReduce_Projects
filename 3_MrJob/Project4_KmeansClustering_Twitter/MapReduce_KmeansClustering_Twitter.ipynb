{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/**********************************************************************************************\n",
       "Known Mathjax Issue with Chrome - a rounding issue adds a border to the right of mathjax markup\n",
       "https://github.com/mathjax/MathJax/issues/1300\n",
       "A quick hack to fix this based on stackoverflow discussions: \n",
       "http://stackoverflow.com/questions/34277967/chrome-rendering-mathjax-equations-with-a-trailing-vertical-line\n",
       "**********************************************************************************************/\n",
       "\n",
       "$('.math>span').css(\"border-left-color\",\"transparent\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "/**********************************************************************************************\n",
    "Known Mathjax Issue with Chrome - a rounding issue adds a border to the right of mathjax markup\n",
    "https://github.com/mathjax/MathJax/issues/1300\n",
    "A quick hack to fix this based on stackoverflow discussions: \n",
    "http://stackoverflow.com/questions/34277967/chrome-rendering-mathjax-equations-with-a-trailing-vertical-line\n",
    "**********************************************************************************************/\n",
    "\n",
    "$('.math>span').css(\"border-left-color\",\"transparent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "\n",
    "\n",
    "## Project 4\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  Hyera Moon     \n",
    "__Week:__   4\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"TOC\"></a> \n",
    "\n",
    "1.  [HW Intructions](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW Problems](#3)   \n",
    "1.  [HW Introduction](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW  Problems](#3)   \n",
    "    1.0.  [HW4.0](#1.0)   \n",
    "    1.0.  [HW4.1](#1.1)   \n",
    "    1.2.  [HW4.2](#1.2)   \n",
    "    1.3.  [HW4.3](#1.3)    \n",
    "    1.4.  [HW4.4](#1.4)    \n",
    "    1.5.  [HW4.5](#1.5)    \n",
    "    1.6.  [HW4.6](#1.6)    \n",
    "    1.7.  [HW4.7](#1.7)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# 1 Instructions\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\">\n",
    "# 2 Useful References\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "* See async lecture and live lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\">\n",
    "# HW Problems\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.0  <a name=\"1.0\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "What is MrJob? How is it different to Hadoop MapReduce? \n",
    "What are the mapper_init, mapper_final(), combiner_final(), reducer_final() methods? When are they called?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "MrJob is a Python package that helps to write and run Hadoop streaming jobs. It differs from the Hadoop MapReduce in several ways:\n",
    "- Multisteps: not all computations can be done in one step in Hadoop MapReduce but MrJob can produce multisteps job  \n",
    "- MrJob can be tested on local machine but also can be run in Hadoop mode. In local mode, can be run very fast at \"Python speed\"\n",
    "- MrJob keeps all MapReduce code for one job in a single class\n",
    "- With MrJob, it is easy to switch input and output formats (single line of code needed)\n",
    "- MrJob is very simple and easy to install\n",
    "\n",
    "The methods in the question above:  \n",
    "- **mapper_init()**: mapper_init() method is called at the beginning of the mapper task. It is to define an action to run before the mapper processes any input. It is frequently used to initialize mapper-specific helper structures.  \n",
    "- **mapper_final()**: mapper_final() method is called at end of the mapper task and emits the outputs of the mapper task.  It is used to define an action to run after the mapper reaches the end of input. Note that when using the mapper_final() method, the mapper() method does not yield any final outputs (except some internal data within the mapper phase to be used by the mapper_final) but the mapper_final() method will be emitting the final mapper task outputs. This is usually to optimize the mapper task outputs by emitting a smaller set of outputs than the mapper would have output (like an in-memory combiner). In other words, it can be used to store a total in an instance variable, and output it after reading all input data.\n",
    "- **combiner_final()**: same concept as mapper_final() but for combiner task  \n",
    "- **reducer_final()**: same concept as mapper_final() but for reducer task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.1  <a name=\"1.1\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "What is serialization in the context of MrJob or Hadoop? \n",
    "When it used in these frameworks? \n",
    "What is the default serialization mode for input and outputs for MrJob? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0 1389k    0 14200    0     0  69918      0  0:00:20 --:--:--  0:00:20 70297\r",
      " 62 1389k   62  867k    0     0   723k      0  0:00:01  0:00:01 --:--:--  725k\r",
      "100 1389k  100 1389k    0     0   881k      0  0:00:01  0:00:01 --:--:--  882k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -L http://archive.ics.uci.edu/ml/machine-learning-databases/anonymous/anonymous-msweb.data -o anonymous-msweb.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Serialization:\n",
    "\n",
    "1) What is serialization in the context of MrJob or Hadoop?  \n",
    "Serialization is the process of turning structured objects into a byte stream that can be transmitted, stored and reconstructed later in a different computer environment, if needed. Deserialization is the reverse process of serialization. In the context of MrJob of Hadoop, data needs to be serialized/deserialized (i.e. switch input/output formats) in a specific format to be readable for different job steps (mappers, reducers) and to be transmitted from one step to another. For example, MRJob accepts as input text formats raw text and JSON and thus, binary formats first need to be translated into MrJob accepted format.  \n",
    "\n",
    "\n",
    "2) When is it used in these frameworks?  \n",
    "Serialization and deserialization is used at each job step (in case of binary format file, deserialize file as input data before mapper is run, convert into JSON format when and when data is transmitted from one step to another (e.g. mapper to reducer). Also, given that MRJob is an abstraction layer above Hadoop, data structures have to be serialized to text for Hadoop streaming to process and transfer data (e.g. total sorting, data structure will be sorted as strings - a \"serialized\" format).  \n",
    "\n",
    "\n",
    "3) What is the default serialization mode for input and outputs for MrJob?  \n",
    "MrJob uses protocols to translate raw bytes into key, value pairs. The default serialization mode (protocols) for MrJob are:\n",
    "   - as input protocol: RawValueProtocol (output value as a string and discard key - more specifically, key is read in as None).\n",
    "   - as internal and output protocols: JSONProtocol (encode key, value as two JSONs separated by a tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.2  <a name=\"1.2\"></a> Preprocess log file data\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Recall the Microsoft logfiles data from the async lecture. The logfiles are described are located at:\n",
    "\n",
    "https://kdd.ics.uci.edu/databases/msweb/msweb.html\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/anonymous/\n",
    "\n",
    "This dataset captures which areas (Vroots) of www.microsoft.com each user visited in a one-week timeframe in Feburary 1998.\n",
    "\n",
    "\n",
    "#### Data Format\n",
    "<PRE>\n",
    "The data is in an ASCII-based sparse-data format called \"DST\". Each line of the data file starts with a letter which tells the line's type. The three line types of interest are:\n",
    "-- Attribute lines:\n",
    "For example, 'A,1277,1,\"NetShow for PowerPoint\",\"/stream\"'\n",
    "Where:\n",
    "  'A' marks this as an attribute line, \n",
    "  '1277' is the attribute ID number for an area of the website (called a Vroot),\n",
    "  '1' may be ignored, \n",
    "  '\"NetShow for PowerPoint\"' is the title of the Vroot, \n",
    "  '\"/stream\"' is the URL relative to \"http://www.microsoft.com\"\n",
    "\n",
    "Case and Vote Lines:\n",
    "For each user, there is a case line followed by zero or more vote lines.\n",
    "For example:\n",
    "  C,\"10164\",10164\n",
    "  V,1123,1\n",
    "  V,1009,1\n",
    "  V,1052,1\n",
    "Where:\n",
    "  'C' marks this as a case line, \n",
    "  '10164' is the case ID number of a user, \n",
    "  'V' marks the vote lines for this case, \n",
    "  '1123', 1009', 1052' are the attributes ID's of Vroots that a user visited. \n",
    "  '1' may be ignored.\n",
    "</PRE>\n",
    "---\n",
    " Here, you must transform/preprocess the data on a single node (i.e., not on a cluster of nodes) from the following format:\n",
    "\n",
    "- C,\"10001\",10001   #Visitor id 10001\n",
    "- V,1000,1          #Visit by Visitor 10001 to page id 1000\n",
    "- V,1001,1          #Visit by Visitor 10001 to page id 1001\n",
    "- V,1002,1          #Visit by Visitor 10001 to page id 1002\n",
    "- C,\"10002\",10002   #Visitor id 10001\n",
    "- V\n",
    "- Note: #denotes comments\n",
    "\n",
    "\n",
    "to the following format (V, PageID, 1, C, Visitor):\n",
    "\n",
    "- V,1000,1,C, 10001\n",
    "- V,1001,1,C, 10001\n",
    "- V,1002,1,C, 10001\n",
    "\n",
    "Write the python code to accomplish this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#START STUDENT CODE42\n",
    "\n",
    "with open('anonymous-msweb.data', \"r\") as mswebfile, open('anonymous-msweb-preprocessed.data', \"a\") as outputfile:\n",
    "    #for line in mswebfile.readlines():\n",
    "    for line in mswebfile:\n",
    "        line = line.strip()\n",
    "        line = line.split(\",\")\n",
    "    \n",
    "        if line[0].upper() == \"C\":\n",
    "            caseline = line\n",
    "            outputfile.write(','.join(map(str,line)) +'\\n')  # Keep the same case line\n",
    "        \n",
    "        elif line[0].upper() == \"V\":\n",
    "            outputfile.write(','.join(map(str,line)) + ',' + caseline[0] + ',' + caseline[1] +'\\n')  # Append case line info to vroot line\n",
    "        \n",
    "        elif line[0].upper() == \"A\":\n",
    "            outputfile.write(','.join(map(str,line)) +'\\n')  # Keep the same attribute line\n",
    "\n",
    "\n",
    "#END STUDENT CODE42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,1287,1,\"International AutoRoute\",\"/autoroute\"\n",
      "A,1288,1,\"library\",\"/library\"\n",
      "A,1289,1,\"Master Chef Product Information\",\"/masterchef\"\n",
      "A,1297,1,\"Central America\",\"/centroam\"\n",
      "A,1215,1,\"For Developers Only Info\",\"/developer\"\n",
      "A,1279,1,\"Multimedia Golf\",\"/msgolf\"\n",
      "A,1239,1,\"Microsoft Consulting\",\"/msconsult\"\n",
      "A,1282,1,\"home\",\"/home\"\n",
      "A,1251,1,\"Reference Support\",\"/referencesupport\"\n",
      "A,1121,1,\"Microsoft Magazine\",\"/magazine\"\n",
      "  131659 anonymous-msweb-preprocessed.data\n"
     ]
    }
   ],
   "source": [
    "!head -10 anonymous-msweb-preprocessed.data\n",
    "!wc -l anonymous-msweb-preprocessed.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.3  <a name=\"1.3\"></a> Find the most frequent pages\n",
    "\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Find the 5 most frequently visited pages using MrJob from the output of 4.2 (i.e., transfromed log file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MostFrequentVisits.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MostFrequentVisits.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE43\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "\n",
    "class MostFrequentVisits(MRJob):\n",
    "    # Note: To not be run on fake-it mode but to be run in Hadoop mode\n",
    "    \n",
    "    MRJob.SORT_VALUES = True        \n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k2,2nr -k1,1',\n",
    "            'mapred.reduce.tasks': 1\n",
    "        }\n",
    "        return [\n",
    "            MRStep(mapper_init=self.init_get_pages,\n",
    "                      mapper = self.get_pages,\n",
    "                      mapper_final = self.final_get_pages,\n",
    "                      reducer =self.count_pages),\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   reducer = self.reducer_find_frequent\n",
    "                  )\n",
    "        ]\n",
    "    \n",
    "    def init_get_pages(self):\n",
    "        self.pages = {}\n",
    "        \n",
    "    def get_pages(self, _, line):\n",
    "        # using in memory combiner\n",
    "        attribute, page, other = line.strip().split(',',2)\n",
    "        page = str(page)\n",
    "        if attribute == \"V\":\n",
    "            self.pages.setdefault(page, 0)\n",
    "            self.pages[page] = self.pages[page] + 1\n",
    "                \n",
    "    def final_get_pages(self):\n",
    "        for page, visit_counts in self.pages.iteritems():\n",
    "            yield page, visit_counts\n",
    "            \n",
    "    def count_pages(self, page, visit_counts):\n",
    "        yield page, sum(visit_counts)\n",
    "        \n",
    "    def reducer_find_frequent(self, page, visit_counts):\n",
    "        yield page, sum(visit_counts)\n",
    "    \n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MostFrequentVisits.run()\n",
    "    \n",
    "\n",
    "#END STUDENT CODE43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x MostFrequentVisits.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/MostFrequentVisits.root.20170204.051357.678976\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/MostFrequentVisits.root.20170204.051357.678976/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob5303504580915120592.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0092\n",
      "  Submitted application application_1485626579957_0092\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0092/\n",
      "  Running job: job_1485626579957_0092\n",
      "  Job job_1485626579957_0092 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0092 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/MostFrequentVisits.root.20170204.051357.678976/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2413608\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2903\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6991\n",
      "\t\tFILE: Number of bytes written=378124\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2413990\n",
      "\t\tHDFS: Number of bytes written=2903\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=15334400\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4468736\n",
      "\t\tTotal time spent by all map tasks (ms)=14975\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=14975\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4364\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4364\n",
      "\t\tTotal vcore-seconds taken by all map tasks=14975\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4364\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3260\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=231\n",
      "\t\tInput split bytes=382\n",
      "\t\tMap input records=131659\n",
      "\t\tMap output bytes=5909\n",
      "\t\tMap output materialized bytes=6997\n",
      "\t\tMap output records=538\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=714760192\n",
      "\t\tReduce input groups=517\n",
      "\t\tReduce input records=538\n",
      "\t\tReduce output records=285\n",
      "\t\tReduce shuffle bytes=6997\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1076\n",
      "\t\tTotal committed heap usage (bytes)=671088640\n",
      "\t\tVirtual memory (bytes) snapshot=4684779520\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "  mapred.text.key.comparator.options is deprecated. Instead, use mapreduce.partition.keycomparator.options\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob3924594535388981168.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1485626579957_0093\n",
      "  Submitted application application_1485626579957_0093\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1485626579957_0093/\n",
      "  Running job: job_1485626579957_0093\n",
      "  Job job_1485626579957_0093 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1485626579957_0093 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/MostFrequentVisits.root.20170204.051357.678976/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4355\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2903\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3764\n",
      "\t\tFILE: Number of bytes written=372438\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4711\n",
      "\t\tHDFS: Number of bytes written=2903\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=10206208\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4304896\n",
      "\t\tTotal time spent by all map tasks (ms)=9967\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=9967\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4204\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4204\n",
      "\t\tTotal vcore-seconds taken by all map tasks=9967\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4204\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2200\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=164\n",
      "\t\tInput split bytes=356\n",
      "\t\tMap input records=285\n",
      "\t\tMap output bytes=3188\n",
      "\t\tMap output materialized bytes=3770\n",
      "\t\tMap output records=285\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=761253888\n",
      "\t\tReduce input groups=285\n",
      "\t\tReduce input records=285\n",
      "\t\tReduce output records=285\n",
      "\t\tReduce shuffle bytes=3770\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=570\n",
      "\t\tTotal committed heap usage (bytes)=738721792\n",
      "\t\tVirtual memory (bytes) snapshot=4688318464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/MostFrequentVisits.root.20170204.051357.678976/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/MostFrequentVisits.root.20170204.051357.678976...\n",
      "Removing temp directory /tmp/MostFrequentVisits.root.20170204.051357.678976...\n"
     ]
    }
   ],
   "source": [
    "!python MostFrequentVisits.py -r hadoop anonymous-msweb-preprocessed.data > 43_outputs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most frequently visited pages are (page and count):\n",
      "\"1008\"\t10836\r\n",
      "\"1034\"\t9383\r\n",
      "\"1004\"\t8463\r\n",
      "\"1018\"\t5330\r\n",
      "\"1017\"\t5108\r\n"
     ]
    }
   ],
   "source": [
    "print \"The 5 most frequently visited pages are (page and count):\"\n",
    "!head -5 43_outputs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4  <a name=\"1.4\"></a> Find the most frequent visitor\n",
    "\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Find the most frequent visitor of each page using MrJob and the output of 4.2  (i.e., transfromed log file). In this output please include the webpage URL, webpageID and Visitor ID.  You may get a weird result.  HINT: The maximum visits by any visitor to any given webpage is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAADQCAYAAAFdDMvvAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5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\nIAiCOCX/PwD2h+6Lr7Jp0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('ms-data.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To create a file with only URL attributes\n",
    "with open('anonymous-msweb.data', \"r\") as mswebfile, open('anonymous-msweb-URL.data', \"a\") as outputfile:\n",
    "    #for line in mswebfile.readlines():\n",
    "    for line in mswebfile:\n",
    "        line = line.strip()\n",
    "        line = line.split(\",\")\n",
    "    \n",
    "        if line[0].upper() == \"A\":\n",
    "            outputfile.write(','.join(map(str,line)) +'\\n')  # Keep the same attribute line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mostFrequentVisitors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostFrequentVisitors.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE44\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "class mostFrequentVisitors(MRJob):\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1 -k2,2nr',\n",
    "            'mapred.reduce.tasks': 1\n",
    "        }\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init = self.init_get_pages_per_visitor,\n",
    "                mapper = self.get_pages_per_visitor,\n",
    "                mapper_final = self.final_get_pages_per_visitor,\n",
    "                reducer = self.count_pages_per_visitor\n",
    "                )\n",
    "            ,\n",
    "            MRStep(\n",
    "                jobconf=JOBCONF_STEP,\n",
    "                reducer_init = self.init_previous_page,\n",
    "                reducer = self.reducer_find_frequent_visitor\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def init_get_pages_per_visitor(self):\n",
    "        self.pages = {}\n",
    "        self.URLs ={}  # dictionary with key = pageID and value = URLs\n",
    "        with open(\"anonymous-msweb-URL.data\", \"r\") as url_file:\n",
    "            for line in url_file:\n",
    "                line = line.strip()\n",
    "                data = line.split(',')\n",
    "                url_ID = str(data[1])\n",
    "                self.URLs[url_ID] = data[4].strip(\"\\\"\")\n",
    "        \n",
    "    def get_pages_per_visitor(self, _, line):\n",
    "        # using in memory combiner\n",
    "        attribute, pageID, other = line.strip().split(',',2)\n",
    "        pageID = str(pageID)\n",
    "        \n",
    "        if attribute == \"V\":\n",
    "            one, customer, customerID = other.split(',',2)\n",
    "            customerID = str(customerID.strip(\"\\\"\"))\n",
    "            key = pageID + \"___\" + self.URLs[pageID] + \"___\" + customerID\n",
    "            self.pages.setdefault(key, 0)\n",
    "            self.pages[key] = self.pages[key] + 1\n",
    "        self.pages[\"9999___sampleURL___99999\"] = 0\n",
    "                \n",
    "    def final_get_pages_per_visitor(self):\n",
    "        for key, visit_counts_per_customer in self.pages.iteritems():\n",
    "            yield key, visit_counts_per_customer\n",
    "            \n",
    "    def count_pages_per_visitor(self, key, visit_counts_per_customer):\n",
    "        yield key, sum(visit_counts_per_customer)\n",
    "    \n",
    "    def init_previous_page(self):\n",
    "        self.current_page = None\n",
    "        self.current_countmax = 0\n",
    "        self.current_URL = None\n",
    "        self.current_customerID = None\n",
    "    \n",
    "    def reducer_find_frequent_visitor(self, key, visit_counts_per_customer):\n",
    "        page_ID, URL, customerID = key.split(\"___\")\n",
    "        count = sum(visit_counts_per_customer)\n",
    "        \n",
    "        if self.current_page == page_ID:\n",
    "            if count > self.current_countmax:\n",
    "                self.current_page = page_ID\n",
    "                self.current_countmax = count\n",
    "                self.current_URL = URL\n",
    "                self.current_customerID = customerID\n",
    "        else:\n",
    "            if self.current_page:\n",
    "                yield self.current_page, (self.current_countmax, self.current_URL, self.current_customerID)\n",
    "               \n",
    "            self.current_page = page_ID\n",
    "            self.current_countmax = count\n",
    "            self.current_URL = URL\n",
    "            self.current_customerID = customerID\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mostFrequentVisitors.run()\n",
    "    \n",
    "\n",
    "#END STUDENT CODE44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x mostFrequentVisitors.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mostFrequentVisitors import mostFrequentVisitors\n",
    "mr_job = mostFrequentVisitors(args=['-r','hadoop', 'anonymous-msweb-preprocessed.data', \\\n",
    "                                    '--file=anonymous-msweb-URL.data'])\n",
    "\n",
    "with mr_job.make_runner() as runner, open('44_outputs.txt',\"w+\") as outputfile: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output\n",
    "    \n",
    "    for line in runner.stream_output():\n",
    "        page_id, info = mr_job.parse_output_line(line)\n",
    "        URL = info[1]\n",
    "        customer_id = info[2]\n",
    "        outputfile.write('%s\\t%s\\t%s\\n' %(page_id, URL, customer_id))\n",
    "        \n",
    "# Results are saved in the file 44_outputs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.5  <a name=\"1.5\"></a> Clustering Tweet Dataset\n",
    "\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Here you will use a different dataset consisting of word-frequency distributions \n",
    "for 1,000 Twitter users. These Twitter users use language in very different ways,\n",
    "and were classified by hand according to the criteria:\n",
    "\n",
    "0: Human, where only basic human-human communication is observed.\n",
    "\n",
    "1: Cyborg, where language is primarily borrowed from other sources\n",
    "(e.g., jobs listings, classifieds postings, advertisements, etc...).\n",
    "\n",
    "2: Robot, where language is formulaically derived from unrelated sources\n",
    "(e.g., weather/seismology, police/fire event logs, etc...).\n",
    "\n",
    "3: Spammer, where language is replicated to high multiplicity\n",
    "(e.g., celebrity obsessions, personal promotion, etc... )\n",
    "\n",
    "Check out the preprints of  recent research,\n",
    "which spawned this dataset:\n",
    "\n",
    "* http://arxiv.org/abs/1505.04342\n",
    "* http://arxiv.org/abs/1508.01843\n",
    "\n",
    "The main data lie in the accompanying file:\n",
    "\n",
    "* [topUsers_Apr-Jul_2014_1000-words.txt](https://www.dropbox.com/s/6129k2urvbvobkr/topUsers_Apr-Jul_2014_1000-words.txt?dl=0)\n",
    "\n",
    "and are of the form:\n",
    "\n",
    "USERID,CODE,TOTAL,WORD1_COUNT,WORD2_COUNT,...\n",
    ".\n",
    ".\n",
    "\n",
    "where\n",
    "\n",
    "USERID = unique user identifier\n",
    "CODE = 0/1/2/3 class code\n",
    "TOTAL = sum of the word counts\n",
    "\n",
    "Using this data, you will implement a 1000-dimensional K-means algorithm in MrJob on the users\n",
    "by their 1000-dimensional word stripes/vectors using several \n",
    "centroid initializations and values of K.\n",
    "\n",
    "Note that each \"point\" is a user as represented by 1000 words, and that\n",
    "word-frequency distributions are generally heavy-tailed power-laws\n",
    "(often called Zipf distributions), and are very rare in the larger class\n",
    "of discrete, random distributions. For each user you will have to normalize\n",
    "by its \"TOTAL\" column. __Try several parameterizations and initializations__ :\n",
    "\n",
    "* (A) K=4 uniform random centroid-distributions over the 1000 words (generate 1000 random numbers and normalize the vectors)\n",
    "* (B) K=2 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "* (C) K=4 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "* (D) K=4 \"trained\" centroids, determined by the sums across the classes. Use use the \n",
    "(row-normalized) class-level aggregates as 'trained' starting centroids (i.e., the training is already done for you!).\n",
    "Note that you do not have to compute the aggregated distribution or the \n",
    "class-aggregated distributions, which are rows in the auxiliary file:\n",
    "\n",
    "\n",
    "* [topUsers_Apr-Jul_2014_1000-words_summaries.txt](https://www.dropbox.com/s/w4oklbsoqefou3b/topUsers_Apr-Jul_2014_1000-words_summaries.txt?dl=0)\n",
    "\n",
    "Row 1: Words\n",
    "Row 2: Aggregated distribution across all classes\n",
    "Row 3-6 class-aggregated distributions for clases 0-3\n",
    "For (A),  we select 4 users randomly from a uniform distribution [1,...,1,000]\n",
    "For (B), (C), and (D)  you will have to use data from the auxiliary file: \n",
    "\n",
    "* [topUsers_Apr-Jul_2014_1000-words_summaries.txt](https://www.dropbox.com/s/w4oklbsoqefou3b/topUsers_Apr-Jul_2014_1000-words_summaries.txt?dl=0)\n",
    "\n",
    "This file contains 5 special word-frequency distributions:\n",
    "\n",
    "* (1) The 1000-user-wide aggregate, which you will perturb for initializations\n",
    "in parts (B) and (C), and\n",
    "* (2-5) The 4 class-level aggregates for each of the user-type classes (0/1/2/3)\n",
    "\n",
    "\n",
    "In parts (B) and (C), you will have to perturb the 1000-user aggregate \n",
    "(after initially normalizing by its sum, which is also provided).\n",
    "So if in (B) you want to create 2 perturbations of the aggregate, start\n",
    "with (1), normalize, and generate 1000 random numbers uniformly \n",
    "from the unit interval (0,1) twice (for two centroids), using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "numbers = random.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take these 1000 numbers and add them (component-wise) to the 1000-user aggregate,\n",
    "and then renormalize to obtain one of your aggregate-perturbed initial centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "##Geneate random initial centroids around the global aggregate\n",
    "##Part (B) and (C) of this question\n",
    "###################################################################################\n",
    "def startCentroidsBC(k):\n",
    "    counter = 0\n",
    "    for line in open(\"topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter == 1:        \n",
    "            data = re.split(\",\",line)\n",
    "            globalAggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "        counter += 1\n",
    "    #perturb the global aggregate for the four initializations    \n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        rndpoints = random.sample(1000)\n",
    "        peturpoints = [rndpoints[n]/10+globalAggregate[n] for n in range(1000)]\n",
    "        centroids.append(peturpoints)\n",
    "        total = 0\n",
    "        for j in range(len(centroids[i])):\n",
    "            total += centroids[i][j]\n",
    "        for j in range(len(centroids[i])):\n",
    "            centroids[i][j] = centroids[i][j]/total\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For experiments A, B, C and D and iterate until a threshold (try 0.001) is reached.\n",
    "After convergence, print out a summary of the classes present in each cluster.\n",
    "In particular, report the composition as measured by the total\n",
    "portion of each class type (0-3) contained in each cluster,\n",
    "and discuss your findings and any differences in outcomes across parts A-D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K-Means</h2>\n",
    "K-means is a clustering method that aims to find the positions μi,i=1...k of the clusters that minimize the distance from the data points to the cluster. K-means clustering solves:\n",
    "<br><br>\n",
    "$$\\arg\\min_{c} \\sum_{i=1}^k\\sum_{{x}\\in c_i} d({x},\\mu_i) = \\arg\\min_{c} \\sum_{i=1}^k\\sum_{{x}\\in c_i} \\left\\Vert {x}-\\mu_i \\right\\Vert_2^2$$\n",
    "<br><br>\n",
    "where ${c}_i$ is the set of points that belong to cluster i. The K-means clustering uses the square of the Euclidean distance $d({x},\\mu_i) = \\left\\Vert {x}-\\mu_i \\right\\Vert_2^2$. This problem is not trivial (in fact it is NP-hard), so the K-means algorithm only hopes to find the global minimum, possibly getting stuck in a different solution.\n",
    "\n",
    "<h2>K-means algorithm</h2>\n",
    "\n",
    "The Lloyd's algorithm, mostly known as k-means algorithm, is used to solve the k-means clustering problem and works as follows. First, decide the number of clusters k. Then:\n",
    "\n",
    "<table>\n",
    "<tbody><tr><td>1. Initialize the center of the clusters</td>\n",
    "<td>${\\mu}_i = $ some value $, i=1,...,k$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>2. Attribute the closest cluster to each data point</td>\n",
    "<td>${c}_i = \\{j: d({x}_j, \\mu_i) \\le d({x}_j, \\mu_l),  l \\ne i, j=1,...,n\\}$ </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>3. Set the position of each cluster to the mean of all data points belonging to that cluster</td>\n",
    "<td>$\\mu_i = \\frac{1}{|c_i|}\\sum_{j\\in c_i} {x}_j,\\forall i$</td>\n",
    "</tr>\n",
    "<tr><td>4. Repeat steps 2-3 until convergence</td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr><td>Notation</td><td>${|c|} = $ number of elements in  ${c}$</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Calculating purity</h2>\n",
    "![purity illustration](http://www.candpgeneration.com/images/purity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Kmeans.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE45\n",
    "\n",
    "### RE CODED WITHOUT NUMPY SINCE HADOOP DOES NOT SUPPORT NUMPY ######\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "# Find the nearest centroid for each datapoint based on sum of squared distance from each word normalized count of \n",
    "# the datpoint to the corresponding normalized count in centroid \n",
    "def MinDist(datapoint, centroid_points):\n",
    "    n = len(centroid_points)\n",
    "    diff = []\n",
    "    for i in range(n):\n",
    "        diff_sq = sum([(d-c)*(d-c) for c,d in zip(centroid_points[i], datapoint)])\n",
    "        diff.append(diff_sq)\n",
    "    # Get the nearest centroid for each instance\n",
    "    min_dist = min(diff)\n",
    "    minidx = diff.index(min_dist) # Return index of minimum value in the list = centroid number\n",
    "    return minidx\n",
    "\n",
    "\n",
    "#Check whether centroids converge\n",
    "def stop_criterion(centroid_points_old, centroid_points_new,T):\n",
    "    oldvalue = list(chain(*centroid_points_old))\n",
    "    newvalue = list(chain(*centroid_points_new))\n",
    "    Diff = [abs(x-y) for x, y in zip(oldvalue, newvalue)]\n",
    "    Flag = True\n",
    "    for i in Diff:\n",
    "        if(i>T):\n",
    "            Flag = False\n",
    "            break\n",
    "    return Flag\n",
    "\n",
    "\n",
    "class Kmeans(MRJob):\n",
    "    centroid_points =[]\n",
    "    k=4\n",
    "    \n",
    "    def steps(self):\n",
    "        return[\n",
    "            MRStep(mapper_init=self.mapper_init,\n",
    "                   mapper=self.mapper,\n",
    "                   combiner=self.combiner,\n",
    "                   reducer=self.reducer)\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    # Initialization phase: load centroids\n",
    "    def mapper_init(self):\n",
    "        self.centroid_points = []\n",
    "        with open(\"/home/cloudera/mnt/share/Assignments/HW4/Centroids.txt\", \"r\") as centroids_file:\n",
    "            for line in centroids_file:\n",
    "                points = map(float,line.strip().split(','))\n",
    "                self.centroid_points.append(points)\n",
    "        self.k = len(self.centroid_points)\n",
    "    \n",
    "    \n",
    "    # Assignment phase: find closest cluster to each data point (min distance from centroid)\n",
    "    def mapper(self, _, line):\n",
    "        userID, code, datapoints = line.strip().split(',',2)\n",
    "        datapoints = map(float,datapoints.split(','))\n",
    "        idx = int(MinDist(datapoints,self.centroid_points))  # Return the cluster index number (0 to 3)\n",
    "        yield idx, datapoints + [1]\n",
    "\n",
    "        \n",
    "    # Combine sum of data points locally\n",
    "    def combiner(self, idx, inputdata):\n",
    "        num = 0\n",
    "        datapoints_sum = [0.0]*1000\n",
    "        \n",
    "        for item in inputdata:\n",
    "            for i in range(1000):\n",
    "                datapoints_sum[i] = datapoints_sum[i] + item[i]\n",
    "            num = num + item[1000]\n",
    "\n",
    "        yield idx, datapoints_sum + [num]  \n",
    "    \n",
    "    \n",
    "    # Update phase: Aggregate sum for each cluster and calculate the new centroids\n",
    "    def reducer(self, idx, inputdata): \n",
    "        centroids = []\n",
    "        num = [0]*self.k\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            centroids.append([0]*1000)\n",
    "            \n",
    "        for item in inputdata:\n",
    "            for i in range(1000):\n",
    "                centroids[idx][i] = centroids[idx][i] + item[i]\n",
    "            num[idx] = num[idx] + item[1000]\n",
    "        \n",
    "        for i in range(1000):\n",
    "            centroids[idx][i] = centroids[idx][i]/num[idx]\n",
    "            \n",
    "        yield idx, centroids[idx]\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    Kmeans.run()\n",
    "\n",
    "\n",
    "#END STUDENT CODE45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x KMeans.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod 777 Centroids.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To create a normalized tweet counts file\n",
    "\n",
    "with open('topUsers_Apr-Jul_2014_1000-words.txt', \"r\") as tweetfile, \\\n",
    "     open('topUsers_Apr-Jul_2014_1000-words-normalized.txt', \"w+\") as outputfile:\n",
    "    for line in tweetfile:\n",
    "        userID, code, total, wordcount = line.strip().split(',',3)\n",
    "        total = float(total)\n",
    "        wordcount = map(float,wordcount.split(','))\n",
    "        wordcount_normalized = [count/total for count in wordcount]\n",
    "        wordcount_string = ','.join(map(str, wordcount_normalized))\n",
    "        outputfile.writelines(userID + \",\" + code + \",\" + wordcount_string + '\\n' )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmeans_runner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmeans_runner.py\n",
    "#!/usr/bin/env python\n",
    "#START STUDENT CODE45_RUNNER\n",
    "\n",
    "from numpy import random\n",
    "from Kmeans import Kmeans, stop_criterion, MinDist\n",
    "import re\n",
    "import operator\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "#1. Geneate initial centroids\n",
    "\n",
    "# Generate uniform random initial centroids (random numbers and normalized vectors)\n",
    "# Part (A)\n",
    "def startCentroidsA(k):\n",
    "    centroid_points = []\n",
    "\n",
    "    for i in range(k):\n",
    "        points = random.uniform(0,1,1000).tolist()  # random points between 0 and 1\n",
    "        #points = random.randint(0,1000,1000).tolist()\n",
    "        total_points = float(sum(points))\n",
    "        normalized_points = [point/total_points for point in points]  # normalized points\n",
    "        centroid_points.append(normalized_points)\n",
    "    \n",
    "    return centroid_points\n",
    "\n",
    "# Generate random initial centroids around the global aggregate\n",
    "# Part (B) and (C)\n",
    "def startCentroidsBC(k):\n",
    "    counter = 0\n",
    "    for line in open(\"topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter == 1:        \n",
    "            data = re.split(\",\",line)\n",
    "            globalAggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "        counter += 1\n",
    "    #perturb the global aggregate for the four initializations    \n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        rndpoints = random.sample(1000)\n",
    "        peturpoints = [rndpoints[n]/10+globalAggregate[n] for n in range(1000)]\n",
    "        centroids.append(peturpoints)\n",
    "        total = 0\n",
    "        for j in range(len(centroids[i])):\n",
    "            total += centroids[i][j]\n",
    "        for j in range(len(centroids[i])):\n",
    "            centroids[i][j] = centroids[i][j]/total\n",
    "    return centroids\n",
    "\n",
    "# Generate uniform random initial centroids (random numbers and normalized vectors)\n",
    "# Part (D)\n",
    "def startCentroidsD(k):\n",
    "    centroids = []\n",
    "    counter = 0\n",
    "    for line in open(\"topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter == 2:        \n",
    "            data = re.split(\",\",line)\n",
    "            class0_aggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "            centroids.append(class0_aggregate)\n",
    "        elif counter == 3:\n",
    "            data = re.split(\",\",line)\n",
    "            class1_aggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "            centroids.append(class1_aggregate)\n",
    "        elif counter == 4:\n",
    "            data = re.split(\",\",line)\n",
    "            class2_aggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "            centroids.append(class2_aggregate)\n",
    "        elif counter == 5:\n",
    "            data = re.split(\",\",line)\n",
    "            class3_aggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "            centroids.append(class3_aggregate)\n",
    "        counter += 1\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#2. Loop through 4 initialization scenarios A,B,C and D\n",
    "\n",
    "k_list = [4,2,4,4]  # k values for each initialization parts A, B, C and D\n",
    "\n",
    "for part in range(4):  # Iterate for 4 differents initialization of centroids\n",
    "    init_letters = [\"A\",\"B\",\"C\",\"D\"]\n",
    "    k = k_list[part]\n",
    "    if part == 0:\n",
    "        centroid_points = startCentroidsA(k)\n",
    "    elif part == 1:\n",
    "        centroid_points = startCentroidsBC(k)\n",
    "    elif part == 2:\n",
    "        centroid_points = startCentroidsBC(k)\n",
    "    elif part == 3:\n",
    "        centroid_points = startCentroidsD(k)\n",
    "    \n",
    "    # A. Create file with initialized centroids\n",
    "    with open('Centroids.txt', 'w+') as f:\n",
    "        f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "\n",
    "        \n",
    "    # B. K-means: Update centroids iteratively\n",
    "    \n",
    "    mr_job = Kmeans(args=['-r','hadoop','topUsers_Apr-Jul_2014_1000-words-normalized.txt', '--file=Centroids.txt'])\n",
    "    \n",
    "    print \"\\nPart %s: Updating centroids...\" %(init_letters[part])\n",
    "    iteration = 0\n",
    "    while (1):\n",
    "        # save previous centoids to check convergency\n",
    "        centroid_points_old = centroid_points[:]\n",
    "        print \"Iteration\"+str(iteration)+\" in process...\"\n",
    "        with mr_job.make_runner() as runner: \n",
    "            runner.run()\n",
    "            # stream_output: get access of the output \n",
    "            for line in runner.stream_output():\n",
    "                key,value =  mr_job.parse_output_line(line)\n",
    "                #print key, value\n",
    "                centroid_points[key] = value\n",
    "\n",
    "        with open('Centroids.txt', 'w+') as f:\n",
    "            f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "\n",
    "        iteration = iteration + 1\n",
    "        if(stop_criterion(centroid_points_old,centroid_points,0.001)):\n",
    "            break\n",
    "\n",
    "    print \"Centroids ready!\\n\"\n",
    "    #print centroid_points \n",
    "\n",
    "    \n",
    "    # C. Calculate purity\n",
    "    purity_data = []\n",
    "    with open ('topUsers_Apr-Jul_2014_1000-words-normalized.txt', 'r') as datafile:\n",
    "        for line in datafile:\n",
    "            userID, code, datapoints = line.strip().split(',', 2)\n",
    "            datapoints = map(float,datapoints.split(','))\n",
    "            kmean_cluster = MinDist(datapoints, centroid_points)\n",
    "            purity_data.append([str(code), str(kmean_cluster)])\n",
    "\n",
    "    purity_counts = []\n",
    "    for i in range(k):\n",
    "        purity_counts.append({})\n",
    "\n",
    "    for code, kmean_cluster in purity_data: \n",
    "        purity_counts[int(kmean_cluster)][code] = purity_counts[int(kmean_cluster)].get(code,0) + 1\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = float(len(purity_data))\n",
    "    for i in range(k):\n",
    "        numerator += max(purity_counts[i].iteritems(), key=operator.itemgetter(1))[1]\n",
    "\n",
    "    purity = numerator / denominator\n",
    "\n",
    "    with open(\"puritytest\", \"w+\") as purityfile:\n",
    "        for data in purity_data:\n",
    "            purityfile.write(str(data[0]) + \",\" + str(data[1]) + \"\\n\")\n",
    "    \n",
    "\n",
    "    code_list = ['Human', 'Cyborg', 'Robot', 'Spammer']\n",
    "    \n",
    "    report_title = \"Part \" + init_letters[part]        \n",
    "    print report_title\n",
    "    print \"-\"*len(report_title)\n",
    "    print \"- Number of clusters: %s\" %(k)\n",
    "    print \"- Convergence criteria threshold: 0.001\"\n",
    "    print \"- Number of iterations: %s\" %(iteration-1)\n",
    "    print \"- Purity: %.4f\" %(purity)\n",
    "    print \"- Clusters Composition Details:\"\n",
    "\n",
    "\n",
    "    for i in range(k):\n",
    "        print \"Cluster %s:\" %(i)\n",
    "        total = float(sum([count for count in purity_counts[i].values()]))\n",
    "        for code in range(4):\n",
    "            count_per_code = purity_counts[i].get(str(code),0)\n",
    "            print \"Code %s:\\t%d\\t%.4f\" %(code_list[code], count_per_code, count_per_code/total)\n",
    "        print \"\"\n",
    "\n",
    "#END STUDENT CODE45_RUNNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x kmeans_runner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part A: Updating centroids...\n",
      "Iteration0 in process...\n",
      "Iteration1 in process...\n",
      "Iteration2 in process...\n",
      "Iteration3 in process...\n",
      "Iteration4 in process...\n",
      "Iteration5 in process...\n",
      "Iteration6 in process...\n",
      "Iteration7 in process...\n",
      "Centroids ready!\n",
      "\n",
      "Part A\n",
      "------\n",
      "- Number of clusters: 4\n",
      "- Convergence criteria threshold: 0.001\n",
      "- Number of iterations: 7\n",
      "- Purity: 0.8990\n",
      "- Clusters Composition Details:\n",
      "Cluster 0:\n",
      "Code Human:\t2\t0.0312\n",
      "Code Cyborg:\t0\t0.0000\n",
      "Code Robot:\t1\t0.0156\n",
      "Code Spammer:\t61\t0.9531\n",
      "\n",
      "Cluster 1:\n",
      "Code Human:\t0\t0.0000\n",
      "Code Cyborg:\t51\t0.9623\n",
      "Code Robot:\t2\t0.0377\n",
      "Code Spammer:\t0\t0.0000\n",
      "\n",
      "Cluster 2:\n",
      "Code Human:\t1\t0.0125\n",
      "Code Cyborg:\t37\t0.4625\n",
      "Code Robot:\t38\t0.4750\n",
      "Code Spammer:\t4\t0.0500\n",
      "\n",
      "Cluster 3:\n",
      "Code Human:\t749\t0.9328\n",
      "Code Cyborg:\t3\t0.0037\n",
      "Code Robot:\t13\t0.0162\n",
      "Code Spammer:\t38\t0.0473\n",
      "\n",
      "\n",
      "Part B: Updating centroids...\n",
      "Iteration0 in process...\n",
      "Iteration1 in process...\n",
      "Iteration2 in process...\n",
      "Iteration3 in process...\n",
      "Iteration4 in process...\n",
      "Iteration5 in process...\n",
      "Iteration6 in process...\n",
      "Centroids ready!\n",
      "\n",
      "Part B\n",
      "------\n",
      "- Number of clusters: 2\n",
      "- Convergence criteria threshold: 0.001\n",
      "- Number of iterations: 6\n",
      "- Purity: 0.8390\n",
      "- Clusters Composition Details:\n",
      "Cluster 0:\n",
      "Code Human:\t1\t0.0075\n",
      "Code Cyborg:\t88\t0.6617\n",
      "Code Robot:\t40\t0.3008\n",
      "Code Spammer:\t4\t0.0301\n",
      "\n",
      "Cluster 1:\n",
      "Code Human:\t751\t0.8662\n",
      "Code Cyborg:\t3\t0.0035\n",
      "Code Robot:\t14\t0.0161\n",
      "Code Spammer:\t99\t0.1142\n",
      "\n",
      "\n",
      "Part C: Updating centroids...\n",
      "Iteration0 in process...\n",
      "Iteration1 in process...\n",
      "Iteration2 in process...\n",
      "Iteration3 in process...\n",
      "Iteration4 in process...\n",
      "Centroids ready!\n",
      "\n",
      "Part C\n",
      "------\n",
      "- Number of clusters: 4\n",
      "- Convergence criteria threshold: 0.001\n",
      "- Number of iterations: 4\n",
      "- Purity: 0.8980\n",
      "- Clusters Composition Details:\n",
      "Cluster 0:\n",
      "Code Human:\t749\t0.9316\n",
      "Code Cyborg:\t3\t0.0037\n",
      "Code Robot:\t13\t0.0162\n",
      "Code Spammer:\t39\t0.0485\n",
      "\n",
      "Cluster 1:\n",
      "Code Human:\t1\t0.0125\n",
      "Code Cyborg:\t37\t0.4625\n",
      "Code Robot:\t38\t0.4750\n",
      "Code Spammer:\t4\t0.0500\n",
      "\n",
      "Cluster 2:\n",
      "Code Human:\t2\t0.0317\n",
      "Code Cyborg:\t0\t0.0000\n",
      "Code Robot:\t1\t0.0159\n",
      "Code Spammer:\t60\t0.9524\n",
      "\n",
      "Cluster 3:\n",
      "Code Human:\t0\t0.0000\n",
      "Code Cyborg:\t51\t0.9623\n",
      "Code Robot:\t2\t0.0377\n",
      "Code Spammer:\t0\t0.0000\n",
      "\n",
      "\n",
      "Part D: Updating centroids...\n",
      "Iteration0 in process...\n",
      "Iteration1 in process...\n",
      "Iteration2 in process...\n",
      "Iteration3 in process...\n",
      "Iteration4 in process...\n",
      "Centroids ready!\n",
      "\n",
      "Part D\n",
      "------\n",
      "- Number of clusters: 4\n",
      "- Convergence criteria threshold: 0.001\n",
      "- Number of iterations: 4\n",
      "- Purity: 0.9010\n",
      "- Clusters Composition Details:\n",
      "Cluster 0:\n",
      "Code Human:\t749\t0.9316\n",
      "Code Cyborg:\t3\t0.0037\n",
      "Code Robot:\t14\t0.0174\n",
      "Code Spammer:\t38\t0.0473\n",
      "\n",
      "Cluster 1:\n",
      "Code Human:\t0\t0.0000\n",
      "Code Cyborg:\t51\t1.0000\n",
      "Code Robot:\t0\t0.0000\n",
      "Code Spammer:\t0\t0.0000\n",
      "\n",
      "Cluster 2:\n",
      "Code Human:\t1\t0.0122\n",
      "Code Cyborg:\t37\t0.4512\n",
      "Code Robot:\t40\t0.4878\n",
      "Code Spammer:\t4\t0.0488\n",
      "\n",
      "Cluster 3:\n",
      "Code Human:\t2\t0.0317\n",
      "Code Cyborg:\t0\t0.0000\n",
      "Code Robot:\t0\t0.0000\n",
      "Code Spammer:\t61\t0.9683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python kmeans_runner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 4.5 Findings\n",
    "\n",
    "In overall, in all 4 methods of parametrization and initialization of centroids, the kMeans algorithm performed well to cluster the class \"Human\" into one cluster. However the class \"Cyborg\" is being split into 2 clusters: one cluster more \"pure\" with mostly Cyborg data, and one cluster more chaotic with both classes \"Cyborg\" and \"Robot\" (about 50%/50%).\n",
    "\n",
    "The parametrization of number of clusters \"k\" is also important in determining the performance of k-means and purity. The steps with k=4 (part A) in the dataset have better grouping of the data and higher purity than the steps with k=2 (part B) since the former has the same number of clusters than the number of classes in the dataset.\n",
    "\n",
    "The initialization of centroids also affected the purity and results of k-Means:\n",
    "- In part A, the centroids are initialized randomly and thus will take more iterations for the algorithm to converge since the initial centroids do not represent the dataset and may be far from it. Also when k-means is run several times with the part A initialization, the results will not be as consistent as other methods of initialization since the randomness of the initial centroids (each initialization will provide very different centroids).  \n",
    "- In part C, the centroids are initialized based on the aggregated distribution of the dataset with added random noise. Thus, even if the centroids may seem to be more representative of the dataset than just random points, there are still based on the aggregated distributions of all classes with added random noise, so the centroids are not actually very close to the center of same class datapoints. Thus, the k-means results such as purity, the number of iterations to converge and the consistency of results are very similar to the ones in part A. Note that for part B, even if it has the same initialization method as C, k is different from the number of classes in the dataset and will not have the same purity (lower than A and C), consistency and number of iterations as part C.  \n",
    "- In part D, the centroids of each cluster are initialized based on the aggregated distribution dataset of one class. Thus, the initial centroids of each cluster is closer to and more representative of the dataset of one particular class from which they were calculated. This results in less iterations. Also, since the initial centroids will always be the same, the results of k-Means such as the purity will always remain the same.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
